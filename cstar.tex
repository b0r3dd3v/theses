\documentclass[a]{subfiles}
\begin{document}
\chapter{$C^*$-algebras}
As an appetizer
we redevelop the essentials of the theory of (unital) $C^*$-algebras
in this chapter.
Since we are ultimately interested
in von Neumann algebras
(a special type of $C^*$-algebras)
we have evaded
delicate
topics such as tensor products (of $C^*$-algebras), 
quotients, approximate identities,
and $C^*$-algebras without a unit.
Our end goal
for this chapter
is \emph{Gelfand's representation theorem} (see~\sref{gelfand}),
the fact that every commutative $C^*$-algebra
is isomorphic
to the $C^*$-algebra
$C(X)$ of continuous functions on some compact Hausdorff space~$X$
--- it yields a duality
between the category~$\CH$ of compact hausdorff spaces (and continuous maps)
and the category~$\cCstar{miu}$ of commutative $C^*$-algebras (and
unital $*$-homomorphisms,
the appropriate structure preservering maps), see~\sref{gelfand-equivalence}.

As the road to Gelfand's representation theorem 
is a bit winding ---
involving intricate relations between technical concepts --- 
we have put emphasis on the invertible and  positive elements
so that the important
theorems about them may serve as landmarks along the way:
\begin{enumerate}
\item
first we show that the norm
on a $C^*$-algebra
is determined by the invertible elements
(via the \emph{spectral radius}), see~\sref{norm-spectrum};

\item
then we construct a \emph{square root} of a positive element in~\sref{sqrt};

\item
and finally we
show that an element of a commutative $C^*$-algebra
is not invertible iff it is mapped to~$0$
by some multiplicative state, see~\sref{inv-mult-state}.
\end{enumerate}
At every step along the way
the positive and invertible elements 
(and the norm, multiplicative states, multiplication
and other structure on a $C^*$-algebra)
are bound more tightly together
until Gelfand's representation theorem emerges.

To make this chapter
more accessible
we have removed
much material
from the ordinary development
of $C^*$-algebras
such as the more general theory of Banach algebras
(and its pathology).
This forces us
to take a slightly different path than is usual in the literature 
(see e.g.~\sref{gelfand-mazur-predicament}).

\section{Definition and examples}
Let us begin with the definition
and examples.
\begin{parsec}%
\begin{point}{Definition}%
A \Define{$C^*$-algebra}
is a complex vector space~$\scrA$
endowed with
\begin{enumerate}
\item
a binary operation,
called \Define{multiplication}
(and denoted as such),
which is associative, and linear in both coordinates;
\item
an element~$1$, called \Define{unit},
such that $1\cdot a = a = a\cdot 1$
for all~$a\in \scrA$;
\item
a unary operation $(\,\cdot\,)^*$,
called \Define{involution},
such that $(a^*)^*=a$,
$(ab)^*=b^*a^*$,
$(\lambda a)^* = \bar\lambda a^*$,
and $(a+b)^* = a^*+b^*$
for all~$a,b\in\scrA$ and~$\lambda\in \C$;
\item
a complete \Define{norm} $\|\,\cdot\,\|$
such that
$\|ab\|\leq\|a\|\|b\|$
for all~$a,b\in\scrA$,
and 
\begin{equation*}
\label{eq:Cstar-identity}
\|a^*a\|\ =\ \|a\|^2
\end{equation*}
holds; this equality is called the \Define{$C^*$-identity}.
\end{enumerate}
The $C^*$-algebra $\scrA$ is called \Define{commutative}
if $ab=ba$ for all~$a,b\in\scrA$.
\begin{point}{Warning}%
In the literature it is usually not
required that a $C^*$-algebra
possesses a unit; but when it does it is called
a \Define{unital $C^*$-algebra}.
\end{point}
\end{point}
\begin{point}{Example}%
The vector space~$\C$ of \Define{complex numbers}
forms a commutative  $C^*$-algebra
in which
multiplication and~$1$
have their usual meaning.
Involution is given by conjugation ($z^*=\bar{z}$),
and norm by modulus ($\|z\|=|z|$).
\end{point}
\begin{point}{Example}%
A \Define{$C^*$-subalgebra}
of a $C^*$-algebra~$\scrA$
is a subset~$\scrB$ of~$\scrA$,
which is a linear subspace of~$\scrA$,
contains the unit, $1$, is closed under multiplication
and involution, 
and is closed with respect to the norm of~$\scrA$;
such a $C^*$-subalgebra of~$\scrA$
is itself a $C^*$-algebra
when endowed with the operations and norm
of~$\scrA$.
\end{point}
\begin{point}[cstar-product]{Example}%
One can form products (in the categorical sense,
see~\sref{cstar-categorical-product}) of $C^*$-algebras as follows.
Let~$\scrA_i$ be a $C^*$-algebra
for every element~$i$ of some index set~$I$.
The \Define{direct product}
of the family $(\scrA_i)_i$
is the $C^*$-algebra
denoted by \Define{$\bigoplus_{i\in I}\scrA_i$} on the set
\begin{equation*}
\textstyle
\{\  a\in \prod_{i\in I}\scrA_i\colon\  \sup_{i \in I} \|a(i)\|< \infty \ \}
\end{equation*}
whose operations are defined pointwise,
and whose norm is a \Define{sup-norm} given by $\|a\|=\sup_{i}\|a(i)\|$.
If each~$\scrA_i$ is commutative,
then~$\bigoplus_{i\in I}\scrA_i$
is commutative.

In particular,
taking~$\scrA_i\equiv \C$,
we see that
the vector space~\Define{$\ell^\infty(X)$} of bounded complex-valued functions
on a set~$X$ forms a commutative $C^*$-algebra
with pointwise operations and sup-norm.
\end{point}
\begin{point}{Example}%
The \Define{bounded continuous functions
on a topological space}~$X$
form a commutative $C^*$-subalgebra~\Define{$BC(X)$}
of~$\ell^\infty(X)$ (see above).
In particular,
since a continuous function on a compact Hausdorff space is 
automatically bounded,
we see that the \Define{continuous functions
on a compact Hausdorff space} $X$
form a commutative $C^*$-algebra~\Define{$C(X)$}
with pointwise operations and sup-norm.
We'll see that every commutative $C^*$-algebra
is isomorphic to a~$C(X)$
in~\sref{gelfand}.
\end{point}
\begin{point}{Example}%
An example of a non-commutative
$C^*$-algebra
is
the vector space~\Define{$M_n$}
of \Define{$n\times n$-matrices} ($n>1$) over~$\C$
with the usual (matrix) multiplication,
the identity matrix as unit,
and conjugate transpose
as involution
(so~$(A^*)_{ij} = \overline{A_{ji}}$).
The norm~$\|A\|$ of a matrix~$A$ in~$M_n$
is less obvious,
being
the \emph{operator norm}
(cf.~\sref{bounded-linear-maps})
of the associated linear map~$v\mapsto Av,\ \C^n\to\C^n$,
that is,
$\|A\|$ is
the least number~$r\geq 0$
with $\|Av\|_2\leq r\|v\|_2$
for all~$v\in \C^n$
(where $\|w\|_2=(\sum_i \left|w_i\right|^2)^{\nicefrac{1}{2}}$
denotes the $2$-norm
of~$w\in \C^n$).

It is not entirely obvious that~$\|A^*A\|=\|A\|^2$
holds
and that $M_n$ is complete.
We will prove these facts in the more general setting
of bounded operators between Hilbert spaces, 
see~\sref{adjointables-cstar-algebra}.
Suffice it to say, $\C^n$ is a Hilbert space
with~$\left<v,w\right>=\sum_i \overline{v}_iw_i$
as inner product,
each matrix gives a (bounded) linear map $v\mapsto Av,\C^n\to \C^n$,
and the conjugate transpose $A^*$ is \emph{adjoint} to~$A$
in the sense that $\left<v,Aw\right> = \left<vA^*,w\right>$
for all~$v,w\in\C^n$.
\end{point}
\begin{point}{Example}%
\TODO{Write about finite dimensional $C^*$-algebras,
$CP^*$, and the Artin--Wedderburn theorem.}
\end{point}
\end{parsec}
\begin{parsec}[hilb]%
\begin{point}[example-hilb]{Example}%
Let us now turn to perhaps the most important
and difficult example:
we'll show that the vector space~\Define{$\scrB(\scrH)$} 
of \Define{bounded operators
on a Hilbert space}~$\scrH$ forms a $C^*$-algebra
when endowed with the operator 
norm.
Multiplication is given by composition,
involution by taking the \emph{adjoint} (see~\sref{hilb-def}),
and unit by the identity operator.
A \Define{concrete $C^*$-algebra} or
a \Define{$C^*$-algebra of bounded operators} 
refers to a $C^*$-subalgebra of~$\scrB(\scrH)$.
We will see that every $C^*$-algebra is isomorphic to a $C^*$-algebra
of bounded operators in~\sref{gelfand-naimark}.
\end{point}
\begin{point}[bounded-linear-maps]{Definition}%
	\TODO{Treat bounded operators between \emph{semi-}normed spaces
		because we'll encounter them in the context
	of the ultrastrong topology.}

Let~$\scrX$ and~$\scrY$ be normed
vector spaces.
We say that~$r\in [0,\infty)$
is a \Define{bound} for a linear map (=\Define{operator}) 
$T\colon \scrX\to\scrY$
when  $\|Tx\|\leq r\|x\|$ for all~$x\in \scrX$,
and we say that~$T$ is \Define{bounded}
when there is such a bound.
In that case~$T$ has a least bound,
which is called the \Define{operator norm} of~$T$,
and is denoted by~$\Define{\|T\|}$.
The vector space of bounded operators
from~$\scrX$ to~$\scrY$
is denoted by~$\scrB(\scrX,\scrY)$,
and the vector space of bounded operators
from~$\scrX$ to itself is denoted by~$\scrB(\scrX)$.
\end{point}
\begin{point}[bounded-operators-basic]{Exercise}%
Let~$\scrX$, $\scrY$ and~$\scrZ$ be normed complex vector spaces.
\begin{enumerate}
\item
Show that the operator norm on~$\scrB(\scrX,\scrY)$
is, indeed, a norm.
\item
Let~$T\colon \scrX\to \scrY$ and~$S\colon \scrY\to\scrZ$
be bounded operators.
Show that $ST$ is bounded by~$\|S\|\|T\|$,
so that~$\|ST\|\leq\|S\|\|T\|$.
\item
Show that the identity operator $\id\colon \scrX\to \scrX$
is bounded by~$1$.
\end{enumerate}
\end{point}
\begin{point}[operator-norm-ball]{Exercise}%
Let $T\colon \scrX\to\scrY$
be a bounded operator between normed vector spaces.
Show that $\|T\|=\sup_{x\in (\scrX)_1} \|Tx\|$,
where $\Define{(\scrX)_1}=\{x\in \scrX\colon \|x\|=1\}$.
\end{point}
\begin{point}[operator-norm-complete]{Lemma}%
The operator norm on~$\scrB(\scrX,\scrY)$ is complete
when~$\scrY$ is a complete normed vector space.
\begin{point}{Proof}%
Let~$(T_n)_n$ be a Cauchy sequence in~$\scrB(\scrX,\scrY)$.
We must show that~$(T_n)_n$ converges to some
bounded operator $T\colon \scrX\to\scrY$.
Let~$x\in \scrX$ be given.
Since 
\begin{equation*}
\|\,T_nx - T_mx\,\|\ =\ \|\,(T_n-T_m)\,x\,\|\ \leq\  \|T_n-T_m\|\,\|x\|
\end{equation*}
and~$\|T_n-T_m\|\to 0$ as~$n,m\to \infty$ 
(because~$(T_k)_k$ is Cauchy),
we see that $\|\,T_nx-T_mx\,\|\to 0$ as $n,m\to \infty$,
and so $(T_nx)_n$ is a Cauchy sequence in~$\scrY$.
Since~$\scrY$ is complete,
 $(T_nx)_n$ converges,
and  we may define $Tx:=\lim_n T_nx$,
giving a map $T\colon \scrX\to \scrY$,
which is easily seen to be linear
(by continuity of addition and scalar multiplication).

It remains to be shown that~$T$ is bounded,
and that~$(T_n)_n$ converges to~$T$ with respect to the operator norm.
Let~$\varepsilon>0$ be given, and pick~$N$ be such that
$\|T_n-T_m\|\leq \frac{1}{2}\varepsilon$ for all~$n,m\geq N$.
Then for every~$x\in \scrX$
we can find~$M\geq N$ with 
$\|T x - T_m x\|\leq \frac{1}{2}\varepsilon\|x\|$ for all $m\geq M$,
and so,
for $n\geq N$, $m\geq M$,
\begin{equation*}
\|(T - T_n) x\| \ \leq\ \|T x - T_mx\|\,+\,\|T_m x - T_n x\|
\ \leq\  \varepsilon\|x\|
\end{equation*}
giving that~$T-T_n$ is bounded
and $\|T-T_n\|\leq \varepsilon$ for all~$n\geq N$.
Whence~$T$ is bounded too,
and $(T_n)_n$ converges to~$T$.\qed
\end{point}
\end{point}
\begin{point}[bounded-operators-banach-algebra]%
From~\sref{bounded-operators-basic}
and~\sref{operator-norm-complete}
it is clear that the complex vector space
of bounded operators~$\scrB(\scrX)$
on a complete normed vector space~$\scrX$
with composition as multiplication
and the identity operator as unit
satisfies all the requirements
to be $C^*$-algebra that do not involve the involution, $(\,\cdot\,)^*$
(that is, $\scrB(\scrX)$ is a \Define{Banach algebra}).
To get an involution,
we need the additional structure
provided by a Hilbert space as follows.
\end{point}
\begin{point}[hilb-def]{Definition}%
An \Define{inner product}
on a complex vector space~$V$ 
is a map $\left<\,\cdot\,,\,\cdot\,\right>\colon V\times V\to \C$
such that,
for all~$x,y\in V$,
$\left<x,\,\cdot\,\right>\colon V\to V$ is linear;
$\left<x,x\right>\geq 0$;
and
$\left<x,y\right>=\overline{\left<y,x\right>}$.
We say that the inner product is \Define{definite}
when~$\left<x,x\right>=0\implies x=0$ for~$x\in V$.
A \Define{pre-Hilbert space}~$\scrH$
is a complex vector space endowed with a definite inner product.
We'll shortly see that every such~$\scrH$
carries a norm
given by
 $\|x\|:= \left<x,x\right>^{\nicefrac{1}{2}}$;
if~$\scrH$ is complete with respect to this norm,
we say that~$\scrH$ is a \Define{Hilbert space}.

Let~$\scrH$ and~$\scrK$ be pre-Hilbert spaces.
We say that a operator~$T\colon \scrH\to \scrK$
is \Define{adjoint}
to a operator
$S\colon \scrK\to \scrH$ 
when
\begin{equation*}
\left<Tx,y\right> \ = \ \left<x,Sy\right>
\qquad\text{for all $x\in \scrH$ and $y\in \scrK$.}
\end{equation*}
In that case, we call~$T$ \Define{adjointable}.
We'll see (in~\sref{uniqueness-adjoint})
that such adjointable~$T$ is adjoint to exactly one~$S$,
which we denote by~\Define{$T^*$}.
\end{point}
\begin{point}[hilb-basic-examples]{Example}%
We endow $\C^N$
(where~$N$ is a natural number)
with the inner product
given by
$\left<x,y\right>=\sum_i \overline{x}_iy_i$,
making it a Hilbert space.

(We'll shortly see infinite dimensional examples of Hilbert spaces,
in~\sref{}.)
\end{point}

\begin{point}[uniqueness-adjoint]{Exercise}%
Let~$x$ and~$x'$ be elements of a pre-Hilbert space~$\scrH$
with $\left<y,x\right>=\left<y,x'\right>$
for all~$y\in\scrH$.
Show that~$x=x'$ (by taking $y=x-x'$).
Conclude that every operator between pre-Hilbert spaces
has at most one adjoint.
\end{point}
\begin{point}%
Note that we did not require that
an adjointable operator $T\colon \scrH\to\scrK$
between pre-Hilbert spaces is bounded,
and in fact, it might not be.

\TODO{Is the adjoint of a bounded operator bounded?}


\end{point}
\begin{point}{Exercise}%
Let~$S$ and~$T$ be adjointable operators on a pre-Hilbert space.
\begin{enumerate}
\item
Show that~$T^*$ is adjoint to~$T$ (and so $T^{**}=T$).
\item
Show that~$(T+S)^*=T^*+S^*$
and $(\lambda S)^*=\overline{\lambda}S^*$
for every~$\lambda\in \C$.
\item
Show that~$ST$ is adjoint to $T^*S^*$ (and so $(ST)^*=T^*S^*$).
\end{enumerate}
We will, of course, show
that every bounded operator on a Hilbert space is adjointable,
see~\sref{bounded-operator-adjointable}.
But let us first show that~$\|\,\cdot\,\|$
defined in~\sref{hilb-def} is a norm,
which boils down to the following fact
about  $2\times 2$-matrices.
\end{point}
\begin{point}[positive-2x2matrix]{Lemma}%
For a positive matrix $A\equiv 
\left(\begin{smallmatrix}p & \overline{c} \\ c & q\end{smallmatrix}\right)$
(i.e.~$\left(
\begin{smallmatrix}\overline{u}&\overline{v}\end{smallmatrix}\right)
A
\left(\begin{smallmatrix}u \\ v \end{smallmatrix}\right) \,\geq \, 0$
for all~$u,v\in \C$),
we have
$p,q\geq 0$, and $\left|c\right|^2 \leq pq$.
\begin{point}{Proof}%
Let~$u,v\in\C$ be given.
We have
\begin{equation*}
0\ \leq\ 
\left(\begin{smallmatrix}\overline{u}&\overline{v}\end{smallmatrix}\right)
A
\left(\begin{smallmatrix}u \\ v \end{smallmatrix}\right)
\ = \ 
\left|u\right|^2 p\,+\, 
\overline{u}v\,\overline{c} \,+\,
u\overline{v}\,c \,+\,
\left|v\right|^2 q.
\end{equation*}
By taking~$u=1$ and $v=0$, we see that~$p\geq 0$,
and similarly $q\geq 0$.

The trick to see that~$\left|c\right|^2\leq pq$
is to
take~$v=1$ and $u=t\overline{c}$ with~$t\in \R$:
\begin{equation*}
0 \ \leq\ p\left|c\right|^2t^2
\,+\,2\left|c\right|^2t 
\,+\, q.
\end{equation*}
If~$p=0$, then~$-2\left|c\right|^2t \leq q $
for all~$t\in \R$,
which implies that~$\left|c\right|^2=0=pq$.

Suppose that~$p>0$.
Then taking~$t=-p^{-1}$ we see that
\begin{equation*}
0 \ \leq\ \left|c\right|^2p^{-1}
\,-\,2\left|c\right|^2p^{-1} 
\,+\, q \ = \ -\left|c\right|^2p^{-1}\,+\,q.
\end{equation*}
Rewriting gives us
 $\left|c\right|^2\leq pq$.\qed
\end{point}
\end{point}
\begin{point}[inner-product-basic]{Exercise}%
Let~$\left<\,\cdot\,,\,\cdot\,\right>$
be an inner product on a vector space~$V$.
Show that
the formula~$\Define{\|x\|}=\smash{\sqrt{\left<x,x\right>}}$
defines a seminorm on~$V$,
that is,
$\|x\|\geq 0$,
$\|\lambda x\|=\left|\lambda\right|\|x\|$,
and---the \Define{triangle inequality}---$\|x+y\|\leq \|x\|+\|y\|$
for all~$\lambda\in \C$ and~$x,y\in V$.

Moreover, prove that~$\|\,\cdot\,\|$
is a norm when~$\left<\,\cdot\,,\,\cdot\,\right>$
is definite,
and for~$x,y\in V$:
\begin{enumerate}
\item
The \Define{Cauchy--Schwarz inequality}:
$\left|\left<x,y\right>\right|^2\,\leq\, \left<x,x\right>
\,\left<y,y\right>$;
\item
\Define{Pythagoras' theorem}:
$\|x\|^2+\|y\|^2\,=\,\|x+y\|^2$ when~$\left<x,y\right>=0$;
\item
The \Define{parallelogram law}:
$\|x\|^2\,+\,
\|y\|^2
\,= \,
\frac{1}{2}(\,\|x+y\|^2\,+\,\|x-y\|^2\,)$;
\item
The \Define{polarization identity}:
$\left<x,y\right> \,=\, \frac{1}{4}\sum_{n=0}^3i^n\|i^nx+y\|^2$.
\end{enumerate}

(Hint: prove the Cauchy--Schwarz inequality
before the triangle inequality
by applying~\sref{positive-2x2matrix} to the matrix
$\smash{\bigl(\begin{smallmatrix}
\smash{\left<x,x\right>} & \smash{\left<x,y\right>} \\
\smash{\left<y,x\right>} & \smash{\left<y,y\right>}
\end{smallmatrix}\bigr)}$.
Then prove $\|x+y\|^2\leq (\|x\|+\|y\|)^2$
using the inequalities~$\left<x,y\right>+\left<y,x\right>
\leq 2\left|\left<x,y\right>\right| \leq 2\|x\|\|y\|$.)
\end{point}
\begin{point}[operators-cstar-identity]{Lemma}%
For an adjointable operator~$T$ on a pre-Hilbert space~$\scrH$
\begin{equation*}
\|T^*T\|\ =\ \|T\|^2\qquad\text{and}\qquad\|T^*\|\ =\ \|T\|.
\end{equation*}
\begin{point}{Proof}%
If~$T=0$, then~$T^*=0$, and the statements are surely true.

Suppose~$T\neq 0$ (and so~$T^*\neq 0$).
Since $\|Tx\|^2=\left<Tx,Tx\right>=\left<x,T^*Tx\right>
\leq \|x\|\,\|T^*Tx\|\leq \|x\|^2\|T^*T\|$
for every~$x\in \scrH$
by Cauchy--Schwarz,
we have $\|T\|^2\leq \|T^*T\|$.
Since~$\|T^*T\|\leq \|T^*\|\|T\|$
and $\|T\|\neq 0$,
it follows that~$\|T\|\leq \|T^*\|$.
Since by a similar reasoning $\|T^*\|\leq \|T\|$,
we get~$\|T\|=\|T^*\|$.
But then $\|T\|^2\leq \|T^*T\|\leq \|T^*\|\|T\|=\|T\|^2$,
and so $\|T\|^2=\|T^*T\|$.\qed
\end{point}
\end{point}
\begin{point}[hilb-examples]{Exercise}%
Verify the following examples of Hilbert spaces.
\begin{enumerate}
\item
	Given a set~$X$,
	\TODO{define $\ell^2(X)$ and $\bigoplus_i \scrH_i$.}
\end{enumerate}
\end{point}
\end{parsec}
\begin{parsec}[hilb-adjoint]%
\begin{point}[adjointables-cstar-algebra]%
At this point
it is clear that the vector space of adjointable operators
on a Hilbert space forms a $C^*$-algebra.
So to prove that $\scrB(\scrH)$
is a $C^*$-algebra,
it remains to be shown that every bounded operator
is adjointable (which we'll do in~\sref{bounded-operator-adjointable}).
We first show that each bounded functional $f\colon \scrH\to \C$
has an adjoint, see~\sref{riesz-representation-theorem},
for which we need the (existence and) properties of ``projections''
on (closed) linear subspaces:
\end{point}
\begin{point}{Definition}
Let~$x$ be an element of a pre-Hilbert space~$\scrH$.
We say that an element~$y$ of a linear subspace~$C$
of~$\scrH$ is a \Define{projection of~$x$ on~$C$}
if
\begin{equation*}
\|x-y\|\,=\,\min\{\,\|x-y'\|\colon \,y'\in C\,\}.
\end{equation*}
(In other words,~$y$ is one of the elements of~$C$ closest to~$x$.)
\end{point}
\begin{point}{Lemma}%
Let~$\scrH$ be a pre-Hilbert space,
and let $x,e\in\scrH$ with
$\|e\|=1$.

Then~$y=\left<e,x\right>e$ is the unique projection of~$x$ on~$e\C$.
\begin{point}{Proof}%
Let~$y'\in e\C$
with~$y'\neq y$
be given.
To prove that~$y$
is the unique projection of~$x$ on $e\C$
it suffices to show that $\|x-y\|<\|x-y'\|$.
Since~$y'\neq y\equiv \left<e,x\right>e$,
there is~$\lambda\in \C$, $\lambda\neq 0$ 
with $y'=(\lambda+\left<e,x\right>)e$.

Note that $\left<e,y\right>=\left<e,\left<e,x\right>e\right>=
\left<e,x\right>\left<e,e\right>
= \left<e,x\right>$,
and so~$\left<e,x-y\right>=0$.
Then~$y'-y\equiv \lambda e$ and~$x-y$ are orthogonal too,
and thus, by Pythagoras'~theorem (see~\sref{inner-product-basic}),
we have $\|y'-x\|^2
=\|y'-y\|^2+\|y-x\|^2\equiv \left|\lambda\right|^2+\|x-y\|^2
>\|x-y\|^2$, because~$\lambda\neq 0$.
Hence~$\|y'-x\|>\|y-x\|$.\qed
\end{point}
\end{point}
\begin{point}[hilb-projection-basic]{Exercise}%
Let~$y$ be a projection of an element~$x$ of a pre-Hilbert space~$\scrH$
on a linear subspace~$C$.
Show that~$y$ is a projection of~$x$ on $y\C$.
Conclude that~$y$ is the unique projection of~$x$ on~$C$,
and that~$\left<y,x-y\right>=0$.
Show that~$y+c$ is the projection of~$x+c$ on~$C$
for every~$c\in C$.
Conclude that~$\left<y',x-y\right>\equiv\left<y',(x+y'-y)-y'\right>=0$ 
for every~$y'\in C$.
\end{point}
\begin{point}[projection-theorem]{Projection Theorem}%
Let~$C$ be a closed linear subspace
of a Hilbert space~$\scrH$.
Each~$x\in \scrH$
has a unique projection~$y$ on~$C$,
and $\left<y',y\right>=\left<y',x\right>$ for~$y'\in C$.
\begin{point}{Proof}%
We only need to show that there is a projection~$y$
of~$x$ on~$C$,
because~\sref{hilb-projection-basic}
gives us that such~$y$ is unique and satisfies
$\left<y',y\right> = \left<y',x\right>$ for all~$y'\in C$.

Write~$r:=\inf\{\,\|x-y'\|\colon\, y'\in C\,\}$,
and pick a sequence $y_1,y_2,\dotsc \in C$
such that $\|x-y_n\|\rightarrow r$.
We will show that~$y_1,y_2,\dotsc$ is Cauchy.
Let~$\varepsilon >0$
be given,
and pick~$N$ such that $\|y_n-x\|^2\leq r^2+\frac{1}{4}\varepsilon$
for all~$n\geq N$.
Let~$n,m\geq N$ be given.
Then since $\frac{1}{2}(y_n+y_m)$
is in~$C$, we have
$\frac{1}{2}\|y_n+y_m-2x\|\equiv 
\|\frac{1}{2}(y_n+y_m)-x\|\geq r$,
and so by the parallelogram law (see \sref{inner-product-basic}),
\begin{alignat*}{3}
\|y_n-y_m\|^2
\ &\equiv\ 
\|(y_n-x)-(y_m-x)\|^2\\
\ &=\ 
2\|y_n-x\|^2 + 2\|y_m-x\|^2
- \|y_n+y_m-x\|^2\\
\ &\leq\ 
4r^2 + \varepsilon - 4r^2 \ \leq \ \varepsilon.
\end{alignat*}
Hence~$y_1,y_2,\dotsc$ is Cauchy,
and converges to some~$y\in C$,
because~$\scrH$ is complete and~$C$ is closed.
It follows easily that~$\|x-y\|=r$,
and thus~$y$ is the projection of~$x$ on~$C$.\qed
\end{point}
\end{point}
\begin{point}[riesz-representation-theorem]{Riesz'~Representation Theorem}%
Let~$\scrH$ be a Hilbert space.
For every bounded linear map~$f\colon \scrH\to\C$
there is a unique vector~$x\in \scrH$
with $\left<x,\,\cdot\,\right>=f$.
\begin{point}{Proof}%
If~$f=0$, then $x=0$ does the job.
Suppose that~$f\neq 0$.
There is~$x'\in\scrH$ with~$f(x')\neq 0$.
Note that~$\ker(f)$ is closed, because~$f$
is bounded.
So by~\sref{projection-theorem},
we know that~$x'$
has a projection~$y$ on~$\ker(f)$,
and $\left<x',z\right>=\left<y,z\right>$
for all~$z\in \ker(f)$.
Then for~$x'':=f(x'-y)^{-1}(x'-y)$,
we have $f(x'')=1$ and~$\left<x'',y'\right>=0$
for all~$y'\in \ker(f)$.

Let~$z\in \scrH$. 
Then $f(\,z-f(z)x''\,)=0$,
so~$z-f(z)x''\in \ker(f)$,
and thus~$0=\left<x'',z-f(z)x''\right>\equiv \left<x'',z\right>-f(z)\|x''\|^2$.
Hence with $x:=x''\|x''\|^{-2}$
we have~$f(z)=\left<x''\|x''\|^{-2},z\right>$
for all~$z\in \scrH$.

Uniqueness follows from~\sref{uniqueness-adjoint}.\qed
\end{point}
\end{point}
\begin{point}[bounded-operator-adjointable]{Exercise}%
Prove that every bounded operator~$T$ on a Hilbert space~$\scrH$
is adjointable, as follows.
Let~$x\in \scrH$ be given.
Prove that~$\left<x,T(\,\cdot\,)\right>\colon \scrH\to \C$
is a bounded linear map.
Let~$Sx$ be the unique vector with $\left<Sx,\,\cdot\,\right>
=\left<x,T(\,\cdot\,)\right>$,
which exists by~\sref{riesz-representation-theorem}.
Show that~$x\mapsto Sx$
gives a bounded linear map $S$, which is adjoint to~$T$.
\end{point}
\begin{point}%
Thus the bounded operators
on a Hilbert space~$\scrH$
form a $C^*$-algebra~$\scrB(\scrH)$
as described in~\sref{example-hilb}.
We will return to Hilbert spaces
in~\sref{gelfand-naimark},
where we show that every $C^*$-algebra
is isomorphic to a $C^*$-subalgebra of
a $\scrB(\scrH)$.
\end{point}
\end{parsec}

\section{The basics}

\begin{parsec}%
\begin{point}%
Now that we have seen the most important examples
of $C^*$-algebras,
we can begin developing the theory.
We'll start easy with the self-adjoint elements:
\end{point}
\begin{point}{Definition}%
Given an element $a$ of a $C^*$-algebra $\scrA$, 
\begin{enumerate}
\item we say that $a$ is \Define{self-adjoint} if $a^* =a$, and
\item we write $\Define{\Real{a}}:= \frac{1}{2}(a+a^*)$
and $\Define{\Imag{a}}:=\frac{1}{2i}(a-a^*)$.
\end{enumerate}
The set of self-adjoint elements of~$\scrA$
is denoted by~\Define{$\sa{\scrA}$}.
\end{point}
\begin{point}[cstar-involution-basic]{Exercise}%
Let~$a$ be an element of a $C^*$-algebra.
\begin{enumerate}
\item 
Show that $\Real{a}$ and $\Imag{a}$ are self-adjoint,
and  $a= \Real{a}+i\Imag{a}$.
\item
Show that if $a\equiv b+ic$ for self-adjoint elements $b$, $c$ of~$\scrA$,
then $b=\Real{a}$ and~$c=\Imag{a}$.
\item
Show that $\Real{(a^*)}=\Real{a}$ and $\Imag{(a^*)}=-\Imag{a}$.
\item 
Show that~$a$ is self-adjoint iff $\Real{a}=a$ iff $\Imag{a}=0$.
\item
Show that $a\mapsto \Real{a}$ and $a\mapsto \Imag{a}$
give $\R$-linear maps $\scrA\to\scrA$.
\item
Show that $\Imag{a} = -\Real{(ia)}$ and $\Real{a}=\Imag{(ia)}$.
\item
Show that $a^*a$ is self-adjoint,
and  $a^*a=\Real{a}^2+\Imag{a}^2+i(\Real{a}\Imag{a}-\Imag{a}\Real{a})$.
\item
Give an example of~$\scrA$ and~$a$ 
with  $\Real{a}\Imag{a} \neq \Imag{a}\Real{a}$.

(This simple observation is the source of many technical difficulties.)
\item
Show that $a^*a+aa^* = 2(\Real{a}^2+\Imag{a}^2)$.
\item
The product of self-adjoint elements $b$, $c$ need not be self-adjoint;
show that, in fact, $bc$ is self-adjoint iff $bc=cb$.
\item
Show that $\|a^*\| = \|a\|$. (Hint:  $\|a\|^2=\|a^*a\|\leq \|a^*\|\|a\|$.)

\item
Show that $\|\Real{a}\|\leq \|a\|$ and $\|\Imag{a}\|\leq \|a\|$.
\item
Show that $\|a^2\|=\|a\|^2$ when~$a$ is self-adjoint.

However,
show that $\|a^2\|\neq \|a\|^2$ might occur
when~$a$ is not self-adjoint.
(Hint: $\bigl(
\begin{smallmatrix}
	0&1\\
	0&0
\end{smallmatrix}
\bigr)$.)

\end{enumerate}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}{Notation}%
Recall that (in this text) every $C^*$-algebra~$\scrA$ has a unit, $1$.
Thus, for every scalar $\lambda\in \C$,
we have an element $\lambda\cdot 1$ of~$\scrA$,
which we will simply denote by~$\lambda$.
This should hardly cause any confusion,
for while an expression of an element of~$\scrA$
such as $i+2+5a$ (where $a\in \scrA$) 
may be interpretted in several ways,
the result is always the same.
\end{point}
\begin{point}{Exercise}%
There is, however, one subtle point regarding
the interpretation
of the norm~$\|\lambda\|$ of a
scalar~$\lambda\in \C$ inside a $C^*$-algebra~$\scrA$.
\begin{enumerate}
\item 
Show that $\|\lambda\|\leq \left| \lambda\right|$ (in~$\C$).
\item
Show that $\|1\|=0\neq 1$ when~$\scrA=\{0\}$ is the trivial $C^*$-algebra.
\item
Show that~$\|\lambda\|=\left|\lambda\right|$
when~$\|\lambda\|$ and~$\left|\lambda\right|$
are interpretted as elements of~$\scrA$.
\end{enumerate}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
Let us now generalize the notion of a positive function
in~$C(X)$
to a positive element of a $C^*$-algebra.
There are several descriptions of
positive functions in~$C(X)$ in terms of the $C^*$-algebra structure
(see~\sref{cx-positive}) on which we can base such a  generalization,
and while we will eventually see that these all yield the same notion
of positive element of a $C^*$-algebra (see~\sref{cstar-positive-final})
we base our definition of positive element (\sref{cstar-positive})
on the description that is perhaps
not most familiar,
but does give us the richest structure at this stage.
\end{point}
\begin{point}[cx-positive]{Exercise}%
Let~$X$ be a compact Hausdorff space.
Show that for self-adjoint $f\in C(X)$, the following are equivalent.
\begin{enumerate}
\item \label{cx-positive-1}
$f(X)\subseteq [0,\infty)$;
\item
$f\equiv g^2$ for some $g\in \sa{C(X)}$;
\item
$f\equiv g^* g$ for some~$g\in C(X)$;
\item
$\|f-t\|\leq t$ for some $t\geq \frac{1}{2}\|f\|$.

\TODO{add picture?}
\end{enumerate}
\begin{point}{Exercise}%
To see how condition~\ref{cx-positive-1}
can be expressed in terms of the $C^*$-algebra structure of~$C(X)$,
prove that  $\lambda\in f(X)$ iff $f-\lambda$
is not invertible.
\end{point}
\end{point}
\begin{point}[cstar-positive-def]{Definition}%
A self-adjoint element~$a$ of a $C^*$-algebra~$\scrA$ is called
\Define{positive} if $\|a-t\|\leq t$
for some~$t\geq \frac{1}{2}\|a\|$.
We write $a\leq b$ for $a,b\in\scrA$ when $b-a$ is positive,
and we denote the set of positive elements of~$\scrA$
by~$\pos{\scrA}$.
\begin{point}{Example}%
We'll see in~\sref{hilb-positive-operators},
that a bounded operator~$T$ on a Hilbert space~$\scrH$
is positive when~$\left<x,Tx\right>\geq 0$ for all~$x\in\scrH$.
\end{point}
\end{point}
\begin{point}{Lemma}%
Let~$a,b$ be positive elements of a $C^*$-algebra.
Then $a+b$ is positive.
\begin{point}{Proof}
Since~$t\geq 0$,
there is~$t\geq \frac{1}{2}\|a\|$ with $\|a-t\|\leq t$.
Similarly, there is~$s\geq \frac{1}{2}\|b\|$
with $\|b-s\|\leq s$.
Then $\|a+b-(t+s)\|\leq \|a-t\|+\|b-s\|\leq t+s$
and $t+s\geq \frac{1}{2}(\|a\|+\|b\|) \geq \frac{1}{2}\|a+b\|$,
so~$a+b\geq 0$.\qed
\end{point}
\end{point}
\begin{point}[cstar-positive]{Exercise}%
Let~$\scrA$ be a $C^*$-algebra.
\begin{enumerate}
\item
Show that~$\pos{\scrA}$ is a \emph{cone}:
$0\in \pos{\scrA}$,
$a+b\in \pos{\scrA}$ for all $a,b\in\pos{\scrA}$,
and
$\lambda a\in \pos{\scrA}$  
for all $a\in \pos{\scrA}$ and $\lambda\in [0,\infty)$.
Conclude that~$\leq$ is a partial order on~$\scrA$,
and that~$\sa{\scrA}$ is an ordered vector space.
\item
Show that~$1$ is positive, and  $-\|a\|\leq a \leq \|a\|$
for every self-adjoint element~$a$ of~$\scrA$.
(Thus $1$ is an \emph{order unit} of~$\sa{\scrA}$.)
\item
The behaviour of positive elements may be surprising:
give an example of positive elements $a$ and~$b$
from a $C^*$-algebra
such that $ab$ is not positive.
\item
Given a self-adjoint element~$a$ of~$\scrA$ define
\begin{equation*}
\|a\|_o \ = \ \inf\{\ \lambda\in[0,\infty)\colon \ 
-\lambda\leq a\leq \lambda\ \}.
\end{equation*}
Show that $\|-\|_o$ is a seminorm on~$\sa{\scrA}$,
and that~$\|a\|_o\leq \|a\|$
for all~$a\in\sa{\scrA}$.

Prove that $0\leq a\leq b$ implies that~$\|a\|_o\leq\|b\|_o$
for $a,b\in\sa{\scrA}$.

\item
There is not much more that can easily be
proven about positive elements, at this point,
but don't take my word for it:
try to prove the following facts
about a self-adjoint element~$a$ of~$\scrA$ directly.
\begin{enumerate}
\item $a^2$ is positive;
\item if $a$ is the limit of positive $a_n\in\scrA$,
then $a$ is positive;
\item if $a\geq -\frac{1}{n}$ for all~$n\in \N$, then $a\geq 0$;
\item  $\|a\|=\|a\|_o$.
\end{enumerate}
We will prove these facts
when we return to the positive elements in~\sref{cstar-positive-2}.
\end{enumerate}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
Let us spend some words
on the morphisms between $C^*$-algebras.
\end{point}
\begin{point}[maps]{Definition}
A linear map $f\colon \scrA \to \scrB$
between $C^*$-algebras
is called
\begin{enumerate}
\item
\Define{\textbf{m}ultiplicative}
if $f(ab)=f(a)f(b)$ for all $a,b\in\scrA$;
\item
\Define{\textbf{i}nvolution preserving}
if $f(a^*)=f(a)^*$ for all~$a\in\scrA$;
\item
\Define{\textbf{u}nital}
if $f(1)=1$;
\item
\Define{\textbf{s}ub \textbf{u}nital}
if $f(1)\leq 1$;
\item
\Define{\textbf{p}ositive}
if $f(a)$ is positive
for every positive $a\in\scrA$, and
\item
\Define{\textbf{c}ompletely \textbf{p}ositive}
if $\sum_{i,j} b_i^*\,f(\,a_i^*a_j\,)\,b_j$ is positive
for all~$a_1,\dotsc,a_n\in \scrA$, and $b_1,\dotsc,b_n\in\scrB$.
\end{enumerate}
\begin{point}%
We use the bold letters as abbreviations,
so for instance,
$f$ is \Define{pu} if it is positive and unital,
and a \Define{miu-map}
is a multiplicative, involution preserving,
unital linear map between $C^*$-algebras,
(which is usually called a \Define{unital $*$-homomorphism}.)
\end{point}
\end{point}
\begin{point}[cstar-p-implies-i]{Lemma (``p$\Rightarrow$i'')}
A positive map $f\colon \scrA\to\scrB$ between
$C^*$-algebras is involution preserving.
\begin{point}{Proof}%
Let~$a\in \scrA$ be given. We must show that~$f(a^*)=f(a)^*$.

But first we'll show that if~$a$ is self-adjoint,
then so is~$f(a)$.
Indeed, since $\|a\|$ and $\|a\|-a$ are positive (see~\sref{cstar-positive}),
we see that $f(\|a\|)$ and $f(\|a\|-a)$ are positive,
and so~$f(a)=f(\|a\|)-f(\|a\|-a)$ is self-adjoint.

It follows that $\Real{f(a)}=f(\Real{a})$
and $\Imag{f(a)}=f(\Imag{a})$ (for~$a\in\scrA$),
because $f(a)\equiv f(\Real{a})+if(\Imag{a})$,
and~$f(\Real{a})$ and~$f(\Imag{a})$
are self-adjoint
(see~\sref{cstar-involution-basic}).

Hence $f(a^*)\equiv f(\Real{a}-i\Imag{a})
=\Real{f(a)}-i\Imag{f(a)}\equiv f(a)^*$.\qed
\end{point}
\end{point}
\begin{point}{Remark}%
Other important relations between these types of morphisms
can only be established later on
once we have a firmer grasp on the positive elements.
We will then see
that every mi-map is positive (in~\sref{}),
and in fact completely positive (in~\sref{}),
and that every completely positive map is positive (in~\sref{}).
\end{point}
\begin{point}%
The miu-maps between $C^*$-algebras
form a category which we denote by~$\Cstar{miu}$.
The full subcategory of commutative $C^*$-algebras
is denoted by~$\cCstar{miu}$.
\end{point}
\begin{point}[cstar-categorical-product]{Exercise}%
Show that the direct product of $C^*$-algebras
defined in~\sref{cstar-product}
provides products in the categories~$\Cstar{miu}$
and~$\cCstar{miu}$.
\end{point}

\TODO{equalizers}
\end{parsec}

%
% geometric series 
%
\begin{parsec}%
\begin{point}%
Let us explore our second landmark,
the  invertible elements
of a $C^*$-algebra,
whose role 
is as important as it is technical.
This paragraph culminates in what is essentially
 \emph{spectral permanence} (\sref{spectral-permanence}):
the fact that if an element $a$ of a $C^*$-subalgebra $\scrB$
is invertible in~$\scrA$,
then~$a$ is already invertible in~$\scrB$,
see~\sref{inverse-permanence}.
\end{point}
\begin{point}[geometric]{Lemma}%
Let~$a$ be an element of a $C^*$-algebra~$\scrA$ with~$\|a\|<1$.
Then~$a^\perp=1-a$ has an inverse,
namely~$(a^\perp)^{-1}= \sum_{n=0}^\infty\, a^n$.
Moreover, this series converges absolutely,
that is,
$\sum_{n=0}^\infty \|a^n\|<\infty$.
\begin{point}{Proof}%
Note that
$(1-\|a\|)\,(1+\|a\|+\|a\|^2+\dotsb+\|a\|^N) \,=\, 1-\|a\|^{N+1}$,
and so 
\begin{equation*}
\sum_{n=0}^N \|a\|^n \ =\  \frac{1-\|a\|^{N+1}}{1-\|a\|}
\end{equation*}
for every~$N$.
Thus,
since $\|a\|^N$ converges to~$0$
(by~\TODO{} because $\|a\|<1$),
we  get $\sum_{n=0}^\infty \|a\|^n = (1-\|a\|)^{-1}$.

\begin{point}%
Note that $a^N$ norm converges to~$0$,
because $\|a\|^N$ converges to~$0$.
Also (but slightly less obvious),
$\sum_n a^n$ norm converges,
because~$\sum_n \|a\|^n$ converges.
\end{point}
\begin{point}%
Thus, taking the norm limit
on both sides of $(1-a)(1+a+a^2+\dotsb a^N) = 1-a^{N+1}$,
gives us $(1-a)(\sum_n a^n) = 1$.
Since we can derive $(\sum_n a^n)(1-a) = 1$
in a similar manner, 
we see that $\sum_n a^n$ is the inverse of~$1-a$.
\end{point}
\end{point}
\end{point}
\begin{point}[spectrum-bounded]{Exercise}
Let~$a$ be an element of a $C^*$-algebra~$\scrA$.
\begin{enumerate}
\item
Show that $a-\lambda$ is invertible
for every~$\lambda\in\C$ with~$\|a\|< \left|\lambda\right|$.
\item
Show that $a-b$ is invertible
when~$b\in\scrA$ is invertible and $\|a\| < \|b\|$.
\item
Show that $U:=\{\ b\in\scrA\colon\ \text{$b$ is invertible}\ \}$
is an open subset of~$\scrA$.
\end{enumerate}
\end{point}
\begin{point}[geometric-convergence]{Lemma}%
For a self-adjoint element~$a$ of~$\scrA$
the series $\sum_n a^n$ 
converges (absolutely) iff~$\|a\|<1$.
\begin{point}{Proof}%
We have already seen in~\sref{geometric}
that~$\sum_n a^n$
converges absolutely when~$\|a\|<1$.
Now, if $\sum_n a^n$ converges,
then~$\|a^{2^n}\|\equiv \|a\|^{2^n}$
(being the norm of the difference
between consecutive partial sums of~$\sum_n a^n$)
converges to~$0$,
which only happens when~$\|a\|<1$.\qed
\end{point}
\begin{point}{Remark}%
For non-self-adjoint elements~$a$ of~$\scrA$,
the convergence of~$\sum_n a^n$
is a more delicate matter.
Take for example
the matrix $A:=\bigl(\begin{smallmatrix}0&2\\0&0\end{smallmatrix}\bigr)$
for which the series $\sum_n A^n$ converges (to~$A$),
while~$\|A\|=2$ --- the problem being that
$\|A^2\|^{\nicefrac{1}{2}}$ differs from $\|A\|$.
In fact,
we'll see from~\sref{hadamard}
(although we won't need it)
that~$\sum_n a^n$
converges absolutely when $1>\limsup_n \|a^n\|^{\nicefrac{1}{n}}$,
and diverges when $1<\limsup_n \|a^n\|^{\nicefrac{1}{n}}$.
This begs the question
what happens when $1=\limsup_n \|a^n\|^{\nicefrac{1}{n}}$
--- which I do not know.
\end{point}
\end{point}
\begin{point}[cstar-inv-continuous]{Lemma}%
Let~$\scrA$ be a $C^*$-algebra.
The assignment $a\mapsto a^{-1}$
gives a  continuous map
(from $\{\,b\in \scrA\colon\, \text{$b$ is invertible}\,\}$
to~$\scrA$.)
\begin{point}[cstar-inv-continuous-1]{Proof}
First we establish continuity at~$1$:
let~$a\in\scrA$ with $\|1-a\|\leq \frac{1}{2}$ be given;
we claim that~$a$ is invertible,
and~$\|1-a^{-1}\| \leq 2\|1-a\|$.

Indeed, since~$\|1-a\|\leq \frac{1}{2}<1$,
$a$ is invertible by~\sref{geometric},
and $a^{-1}=\sum_{n=0}^\infty (1-a)^n$.
Then~$\|1-a^{-1}\|=\|\sum_{n=1}^\infty (1-a)^n\|\leq \sum_{n=1}^\infty \|1-a\|^n
= \|1-a\|\, (1-\|1-a\|)^{-1}$.
Thus, as $\|1-a\|\leq\frac{1}{2}$,
we get $(1-\|1-a\|)^{-1}\leq 2$,
and so $\|1-a^{-1}\|\leq 2\|1-a\|$.
\begin{point}%
Let~$a$ be an invertible element of~$\scrA$,
and let~$b\in\scrA$ with~$\|a-b\|\leq\frac{1}{2}\|a^{-1}\|$.
We claim that~$b$ is invertible,
and~$\|a^{-1}-b^{-1}\|\leq 2\|a-b\|\,\|a^{-1}\|^2$.

Since $\|a-b\|\leq \frac{1}{2}\|a^{-1}\|$
we have
$\|1-a^{-1}b\|\leq \|a^{-1}\|\,\|a-b\|\leq \frac{1}{2}$.
By~\sref{cstar-inv-continuous-1}, $a^{-1}b$ is invertible,
and $\|1-(a^{-1}b)^{-1}\|\leq 2\|1-a^{-1}b\|\leq 2\|a-b\|\,\|a^{-1}\|$.
Hence $\|a^{-1}-b^{-1}\| = \|(1-(a^{-1}b)^{-1})a^{-1}\|
\leq \|1-(a^{-1}b)^{-1}\|\,\|a^{-1}\|\leq 2 \|a-b\|\,\|a^{-1}\|^2$.

(Based on Kadison--Ringrose Proposition 3.1.6.)
\end{point}
\end{point}
\end{point}
%
%	Towards spectral permanence
%
\begin{point}{Lemma}%
For a self-adjoint element~$a$ from a $C^*$-algebra,
$a-i$ is invertible.
\begin{point}{Proof}%
The trick
is to 
write~$a-i\equiv (a+ni)\,-\,(n+1)i$
for sufficiently large~$n$,
because  
then
$a-i$
is invertible provided that~$n+1 > \|a+ni\|$
by~\sref{spectrum-bounded}.
Indeed, for~$n$ such that~$\|a\|<2n+1$,
we have $\|a+ni\|^2 = \|(a+ni)^*(a+ni)\|
= \|a^2+n^2\|
\leq \|a\|^2+n^2 < 2n+1+n^2 = (n+1)^2$,
and so $\|a+ni\| < n+1$.

(Based on Kadison--Ringrose Proposition 4.1.1(ii).)
\end{point}
\begin{point}[spectrum-self-adjoint-real]{Exercise}%
Let~$a$ be a self-adjoint element of a $C^*$-algebra.
\begin{enumerate}
\item
Show that~$a-\lambda$ is invertible for all $\lambda\in \C\backslash \R$.
\item
Show that $a^2-\lambda$ is invertible for all 
$\lambda\in \C\backslash[0,\infty)$.\\
(Hint: first prove that
 $a^2+1 \equiv (a+i)(a-i)$ is invertible.)

Conclude that $a^n-\lambda$ is invertible for all 
$\lambda\in\C\backslash[0,\infty)$ and \emph{even} $n\in\N$.
\item
Let~$n\in \N$ be \emph{odd}.
Show that $a^n-\lambda$ is invertible
for all~$\lambda\in \C\backslash[0,\infty)$
if and only if $a-\lambda$ is invertible
for all~$\lambda\in \C\backslash[0,\infty)$.\\
(Hint: show that
$a^n+1= \prod_{k=1}^n a+\zeta^{2k+1}$
where $\zeta=e^{\frac{\pi i}{n}}$.)
\end{enumerate}
\end{point}
\end{point}
\begin{point}{Proposition}%
Let~$\scrA$ be a $C^*$-subalgebra
of a $C^*$-algebra $\scrB$.
Let~$a$ be a self-adjoint element of~$\scrA$,
which has an inverse, $a^{-1}$, in~$\scrB$.
Then~$a^{-1}\in\scrA$.
\begin{point}{Proof}%
While we do not know yet that~$a$ is invertible in~$\scrA$,
we do know that~$a+\nicefrac{i}{n}$ 
has an inverse $(a+\nicefrac{i}{n})^{-1}$ in~$\scrA$
by~\sref{spectrum-self-adjoint-real}
for each~$n$
(using that $a$ is self-adjoint.)
Since~$a+\nicefrac{i}{n}$ converges to~$a$ in~$\scrB$ as~$n$ increases,
we see that $(a+\nicefrac{i}{n})^{-1}$ converges to~$a^{-1}$
in~$\scrB$ by~\sref{cstar-inv-continuous}.
Thus, as all~$(a+\nicefrac{1}{n}i)^{-1}$ are in~$\scrA$,
and~$\scrA$ is closed in~$\scrB$,
we see that~$a^{-1}$ is in~$\scrA$.
\end{point}
\begin{point}[inverse-permanence]{Exercise}%
Show that the assumption that~$a$ is self-adjoint
can be dropped. 

(Hint: consider $a^*a$; c.f.~Conway Proposition VIII.1.14.)
\end{point}
\end{point}
\begin{point}{Definition}%
The \Define{spectrum} of an element $a$
of a $C^*$-algebra
is the set \Define{$\spec(a)$}
of complex numbers~$\lambda$
for which~$a-\lambda$ is not invertible.
\begin{point}{Exercise}%
Verify the following examples.
\begin{enumerate}
\item
The spectrum of a continuous function~$f\colon X\to \R$
on a compact Hausdorff space~$X$
being an element of the $C^*$-algebra $C(X)$
is the image of~$f$, that is,
$\spec(f) = \{f(x)\colon x\in X\}$.
\item
The spectrum of a square matrix~$A$
from the $C^*$-algebra $M_n$
is the set of eigenvalues of~$A$.
\end{enumerate}
\end{point}
\begin{point}[spectrum-basic]{Exercise}%
Let~$a$ be an element of a $C^*$-algebra $\scrA$.
\begin{enumerate}
\item
Prove that $\spec(a)\subseteq \R$ when $a$ is self-adjoint
(see~\sref{spectrum-self-adjoint-real}).

The reverse implication also holds,
as we'll see later on in \TODO{}.
\item
Show that $\spec(a^2)\subseteq [0,\infty)$ when $a$ is self-adjoint
(see~\sref{spectrum-self-adjoint-real}).

\item
Show that $|\lambda|\leq \|a\|$ for all~$\lambda\in\spec(a)$
using~\sref{spectrum-bounded}.

In fact, we will see in~\sref{norm-spectrum},
that $\|a\|=\sup\{\left|\lambda\right|\colon \lambda\in \spec(a)\}$.
\item
Show that $\spec(a)$ is closed (using~\sref{spectrum-bounded}).\\
Conclude that~$\spec(a)$ is compact.
\item
Show that $\spec(a+z)=\{\lambda+z\colon \lambda\in\spec(a)\}$
for all~$z\in \C$.
\item
Prove that~$\spec(a^{-1})=\{\lambda^{-1}\colon \lambda\in \spec(a)\}$
if~$a$ is invertible (and~$0\notin \spec(a)$).
\end{enumerate}
\end{point}
\end{point}
\begin{point}%
On first sight,
the spectrum $\spec(a)$
of an element~$a$ of a $C^*$-algebra~$\scrA$ 
depends not only on~$a$,
but also on the surrounding $C^*$-algebra~$\scrA$ for it determines
for which~$\lambda\in\C$ the operator $a-\lambda$ is invertible.
Thus we should perhaps write $\spec_\scrA(a)$ instead
of~$\spec(a)$.
However, such careful bookkeeping turns out 
be unnecessary
by the following result.
\end{point}
\begin{point}[spectral-permanence]{Theorem (Spectral Permanence)}%
Let~$\scrB$ be a $C^*$-subalgebra of a $C^*$-algebra $\scrA$.
Then~$\spec_{\scrA}(a)=\spec_\scrB(a)$
for every element~$a$ of~$\scrB$.
\begin{point}{Proof}%
Let~$a$ be an element of~$\scrB$,
and let~$\lambda\in \C$.
We must show that $a-\lambda$ is invertible in~$\scrA$
iff $a-\lambda$ is invertible in~$\scrB$.
Surely,
if $a-\lambda$ has an inverse $(a-\lambda)^{-1}$ in~$\scrB$,
then~$(a-\lambda)^{-1}$ is also an inverse of~$a-\lambda$ in~$\scrA$,
since~$\scrB\subseteq \scrA$.
The other, non-trivial, direction follows
directly from~\sref{inverse-permanence}.\qed%
\end{point}
\end{point}
\end{parsec}
\section{Positive elements}
\subsection{Holomorphic functions}
\begin{parsec}%
\begin{point}%
The next order of business
is to show that the spectrum~$\spec(a)$ of an element~$a$
of a $C^*$-algebra contains enough points, so to speak.
One incarnation of this idea that you might have heard
is that~$\spec(a)$ is non-empty
(see~\sref{spectrum-non-empty}), but
we will need more,
and prove that  $\|a\|=\left|\lambda\right|$
for some~$\lambda\in\spec(a)$.
Somewhat baffling,
the canonical and seemingly
easiest way to derive this fact is by considering the power series
expansion of a cleverly chosen $\scrA$-valued function
(see~\sref{norm-spectrum}).
To this end,
we'll first quickly redevelop some complex analysis
for~$\scrA$-valued functions
(instead of $\C$-valued functions).
\end{point}
\begin{point}{Setting}%
Fix a $C^*$-algebra~$\scrA$ for the remainder of this paragraph.
For brevity,
we'll say that a \Define{function}
is a partially defined map $f\colon \C\to \mathscr{A}$
whose domain of definition $\dom(f)$ is an open subset of~$\C$.
Such a function is called \Define{holomorphic} at a point~$z\in \C$
if $f$ is defined on~$z$ (that is, $z\in \dom(f)$),
and 
\begin{equation*}
\frac{f(x)-f(y)}{x-y}
\end{equation*}
converges (with respect to the norm on~$\scrA$)
to some element~$f'(x)$ of~$\scrA$
as $y\in \dom(f)\backslash\{x\}$
converges to~$x$.

We say that~$f$ is \Define{holomorphic}
if~$f$ is holomorphic at~$x$ for all~$x\in \dom(f)$,
and the function $z\mapsto f'(z)$
with $\dom(f')=\dom(f)$
is its \Define{derivative}.
\end{point}
\begin{point}{Exercise}%
Verify the following examples of holomorphic functions.
\begin{enumerate}
\item
If~$f$ and $g$ are holomorphic functions with $\dom(f)=\dom(g)$,
then $f+g$ and $f\cdot g$ are holomorphic,
and $(f+g)'=f'+g'$ and $(f\cdot g)' = f'g+g'f$.

\item
The function~$f$ given by $f(z)=z$ and~$\dom(f)=\C$
is holomorphic, and $f'(z)=1$ for all $z\in\C$.

\item
Let~$a\in \scrA$. The constant function $f$ given by $f(z)=a$
for all~$z\in \C$ is holomorphic, and $f'(z)=0$ for all~$z\in \scrA$.

\item
Any polynomial,
that is, function~$f$ of the form $f(z)\equiv a_n z^n+\dotsb+a_1 z+a_0$
is holomorphic with $f'(z)=na_nz^{n-1}+\dotsb+2a_2z+a_1$.
\end{enumerate}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
We now turn
to perhaps the most important example
of a holomorphic $\scrA$-valued function ---
or at the very least the very source from
which (as we'll see) all holomorphic functions
draw their interesting and desirable
properties:
the holomorphic $\scrA$-valued function
given by a power series  $\sum_n a_n z^n$.
\end{point}
\begin{point}[hadamard]{Theorem}%
Let~$a_1,a_2,\dotsc\in\scrA$
be given,
and write~$R:=(\limsup_n \|a_n\|^{\nicefrac{1}{n}})^{-1}$.
Then for every~$z\in\C$,
\begin{enumerate}
\item
$\sum_n a_n z^n$
converges absolutely
when~$\left|z\right| < R$, and 
\item
if~$\sum_n a_n z^n$ converges,
then~$\left|z\right|\leq R$.
\end{enumerate}
(The number~$R$ is called the \Define{radius of convergence}
of the series $\sum_n a_n z^n$.)
\begin{point}{Proof}%
Suppose that $\left|z\right|<R$.
To show that the series 
$\sum_n a_nz^n$ converges absolutely,
we must show that $\sum_n \left\|a_n\right\|\left|z\right|^n
\equiv \sum_n (\,\left\|a_n\right\|^{\nicefrac{1}{n}}\left|z\right|\,)^n
<\infty$.
If~$z=0$, this is obvious,
so we'll assume that~$\left|z\right| > 0$.
Then, since~$\left|z\right|<R$,
we have~$R^{-1}\left|z\right|<1$
(and $R^{-1}<\infty$).
Note that
there is $\varepsilon>0$ with $(R^{-1}+\varepsilon)\left|z\right|<1$.
The point of this~$\varepsilon$
is that~$\limsup_n \|a_n\|^{\nicefrac{1}{n}} 
< R^{-1}+\varepsilon$,
so that we can find~$N$ 
with $\|a_n\|^{\nicefrac{1}{n}} \leq R^{-1}+\varepsilon$
for all~$n\geq N$.
Then $\|a_n\|^{\nicefrac{1}{n}}\left|z\right|
\leq (R^{-1}+\varepsilon)\left|z\right|<1$
for all~$n\geq N$,
and so
$\sum_n \|a_n\|\left|z\right|^n 
\leq\sum_{n=0}^{N-1} \|a_n\|\left|z\right|^n+ \sum_{n=N}^\infty 
(\,(R^{-1}+\varepsilon)\left|z\right|\,)^n < \infty$
by  convergence
of the geometric series (c.f.~\sref{geometric}).

Suppose now instead that $\sum_n a_n z^n$ converges.
Then~$\|a_n\|\left|z\right|^n$
converges to~$0$.
In particular,
there is~$N$ with $\|a_n\|\left|z\right|^n \leq  1$
for all~$n\geq N$.
Then~$\|a_n\|^{\nicefrac{1}{n}} \left|z\right| \leq 1$,
and $\|a_n\|^{\nicefrac{1}{n}} \leq \left|z\right|^{-1}$
for all~$n\geq N$,
so that $R^{-1}\equiv \limsup_n \|a_n\|^{\nicefrac{1}{n}}
\leq \left|z\right|^{-1}$,
giving $\left|z\right|\leq R$.\qed
\end{point}
\end{point}
\begin{point}{Proposition}%
The $\scrA$-valued function~$f$
given by a series $\sum_n a_n z^n$
with radius of convergence~$\smash{R:=(\,\limsup_n \|a_n\|^{\nicefrac{1}{n}}\,)^{-1}}$
is holomorphic
when defined
on the disk $\dom(f)=\{z\in\C\colon \left|z\right|<R\}$,
and $f'(z)=\sum_{n=1}^\infty n a_n z^{n-1}$
for all~$z\in \dom(f)$.
\begin{point}{Proof}%
If~$R=0$,
the statement is rather dull, but clearly true,
so we assume that~$R\neq 0$,
that is, $\smash{\limsup_n \|a_n\|^{\nicefrac{1}{n}}}<\infty$.

Note
that the radius of convergence
of~$\sum_{n=1}^\infty na_n z^{n-1}
\equiv \sum_{n=0}^\infty (n+1)a_{n+1}z^n$
is also~$R$,
because
\begin{equation*}
	\smash{\bigl\|\,(n+1)\, a_{n+1}\,\bigr\|^{\nicefrac{1}{n}}}
\ =\  \smash{(n+1)^{\nicefrac{1}{n}}}
\ \smash{\|a_{n+1}\|^{\frac{1}{n+1}}}
\ \smash{\bigl(\|a_{n+1}\|^{\frac{1}{n+1}}\bigr)^{\nicefrac{1}{n}}},
\end{equation*}
and
$R^{-1}=\limsup_n \|a_{n+1}\|^{\frac{1}{n+1}}$,
and both 
$(n+1)^{\nicefrac{1}{n}}$
and  $\bigl(\|a_{n+1}\|^{\frac{1}{n+1}}\bigr)^{\nicefrac{1}{n}}$
converge to~$1$ as~$n\to\infty$
(using here that $\smash{\limsup_n\|a_n\|^{\nicefrac{1}{n}}}<\infty$).

Hence~$\sum_{n=1}^\infty n a_n z^{n-1}$
converges absolutely for every~$z\in\C$ with $\left|z\right|<R$.
Let~$z\in \C$ with $\left|z\right|<R$
be given. We must show that~$f$
is holomorphic at~$z$ with~$f'(z)=\sum_n na_nz^{n-1}$.
For this it suffices to show that
the sum of the series
\begin{equation}
\label{power-series-derivative-0}
\sum_{n=0}^\infty
\|a_n\|\left|\,\frac{(z+h)^n-z^n}{h}-nz^{n-1}\,\right|
\end{equation}
converges to~$0$
as $h\in\C$ (with $h\neq 0$ and $\left|z+h\right|<R$)
tends to~$0$.

Pick~$r>0$ with $\left|z\right| < r < R$.
With the appropriate algebraic gymnastics
(involving the identity
$a^n-b^n=(a-b)\sum_{k=1}^n a^{n-k}b^{k-1}$
and the inequalities $\left|z+h\right| \leq r$
and $\left|z\right|\leq r$)
we get, for every~$n$
and~$h\in \C$ with
$h\neq 0$ and~$\left|z+h\right|<r$,
\begin{align}
\left|\  \frac{(z+h)^n-z^n}{h}-nz^{n-1}\ \right|
\ &= \ 
\biggl|\ \sum_{k=1}^n \bigl(\,(z+h)^{n-k}-z^{n-k}\,\bigr)z^{k-1} \ \biggr|
\label{power-series-derivative-1}
\\ 
\label{power-series-derivative-2}
\ &\leq\ 
2nr^{n-1}.
\end{align}
On the one hand,
we see from~\eqref{power-series-derivative-1}
that any term
--- and thus any partial sum ---
of the series from~\eqref{power-series-derivative-0}
converges to~$0$ as~$h$ tends to~$0$.
On the other hand,
we see from~\eqref{power-series-derivative-2}
that the series 
from~\eqref{power-series-derivative-0}
is dominated by~$2\sum_n \|a_n\|nr^{n-1}$
(which converges
because the radius of convergence of $\sum_n a_n nz^{n-1}$
is $R>r$),
so that the tails of the series in~\eqref{power-series-derivative-0}
vanish uniformly in~$h$.
All in all, the sum of the infinite series
from~\eqref{power-series-derivative-0}
converges to~$0$ as~$h$ tends to~$0$.\qed
\end{point}
\end{point}

\TODO{Definition of polygonal paths}
\TODO{Definition of integration along these}
\begin{point}[goursat]{Goursat's Theorem}%
Let~$f$ be a holomorphic function,
and let~$T$ be a triangle whose interior
is entirely contained in~$\dom(f)$.
Then~$\int_T f = 0$.
\begin{point}[goursat-1]{Proof}%
Note that if~$f$ has a primitive,
that is, $f\equiv g'$ for some holomorphic function~$g$,
then it is clear that~$\int_T f=0$
by \TODO{the fundamental theorem of calculus}.
Although it is true that every holomorphic function
with simply connected domain has a primitive,
this result is not yet available 
(and in fact depends on this very theorem).
Instead we will approximate~$f$
by an affine function
(which does have a primitive)
using the derivative of~$f$.
But since such an approximation only
concerns a single point,
we first need to zoom in.
\begin{point}[goursat-2]%
If we split~$T$ into four similar triangles
$T^\text{i}$, $T^\text{ii}$,
$T^\text{iii}$, $T^\text{iv}$
(see picture~\TODO{})
we have $\smash{\int_Tf = \sum_{n={\text{i}}}^{\text{iv}} \int_{T^n}f}$.
There is $T'$ among
$T^\text{i}$, $T^\text{ii}$,
$T^\text{iii}$, $T^\text{iv}$
with 
 $\|\int_Tf\|\leq 4 \|\int_{T'} f\|$.
Clearly, $\length(T)=2\length(T')$.
Write~$T_0 := T$ and $T_1 := T'$. 

From this it is clear how to
 get a sequence of similar triangles $T_0, T_1, T_2, \dotsc$
with $\|\int_Tf\|\leq 4^n \|\int_{T_n} f\|$,
and $\length(T)=2^n\length(T_n)$.
\end{point}
\begin{point}%
If we pick a point on each triangle~$T_n$ 
we get a Cauchy sequence
that converges to some point~$z_0\in\C$
which lies in (or on) each of the triangles~$T_1,T_2,\dotsc$.
We can approximate $f$ by an affine
function at~$z_0$ as follows.
For $z\in \dom(f)$,
\begin{equation*}
f(z)\ = \ f(z_0)\,+\,f'(z_0)\,(z-z_0)\,+\,r(z)\,(z-z_0),
\end{equation*}
where~$r\colon \dom(f)\to \C$
is given by $r(z)=f'(z_0)-(f(z)-f(z_0))(z-z_0)^{-1}$ for $z\neq z_0$
and $r(z_0)=0$.
We see that~$r(z)$ converges to~$0$ as~$z\to z_0$.

Let~$\varepsilon >0$ be given.
There is~$\delta>0$
such that $z\in\dom(f)$
and $\|r(z)\|\leq \varepsilon$
for all~$z\in \C$ with $\|z-z_0\|<\delta$.
There is~$n$ such that the triangle~$T_n$ is contained
in the ball around~$z_0$ of radius~$\delta$.
Note that $\int_{T_n} f(z_0)+f'(z_0)(z-z_0)\,dz=0$
by the discussion in~\sref{goursat-1}, because
the integrated function is affine.
Thus
\begin{equation*}
\textstyle
\int_{T_n} f \  = \ \int_{T_n}r(z)\,(z-z_0)\,dz.
\end{equation*}
Note that for $z\in T_n$,
we have  $\|z-z_0\|\leq \length(T_n)$,
and $\|r(z)\|\leq \varepsilon$ (because $\|z-z_0\|\leq \delta$),
and so $\|r(z)(z-z_0)\|\leq \varepsilon\,\length(T_n)$.
Thus:
\begin{equation*}
\textstyle
\|\int_{T_n} f\| \  = \ \|\int_{T_n}r(z)\,(z-z_0)\,dz\|
\ \leq\ \varepsilon\length(T_n)^2.
\end{equation*}
Using the inequalities from~\sref{goursat-2},
we get
\begin{equation*}
\textstyle
\|\int_T f\|\ \leq\ 4^n\, \|\int_{T_n} f\|
\ \leq\ \varepsilon \,4^n\,\length(T_n)^2 
\ \equiv\ \varepsilon \length(T)^2.
\end{equation*}
Since~$\varepsilon>0$ was arbitrary,
we see that~$\int_T f=0$.\qed
\end{point}
\end{point}


(Proof is based on~\cite{moore1900}.)
\end{point}%
\begin{point}[cauchy-formula]{Theorem (Cauchy's Integral Formula)}%
Let~$f$ be a holomorphic $\scrA$-valued function.
Let~$p$ be a simple positively oriented 
polygon with $\interior(p)\subseteq\dom(f)$.
Then for $z_0\in \interior(p)$,
\begin{equation*}
f(z_0)\ = \ \frac{1}{2\pi i}\,\int_p \frac{f(z)}{z-z_0}\,dz
\end{equation*}
\begin{point}{Proof}%
Since~$\int_p \frac{f(z_0)}{z-z_0}\,dz
= 2\pi i f(z_0)$ by~\TODO{reason},
it suffices to show that
\begin{equation}
\label{eq:cauchy-formula-1}
\int_p \frac{f(z)-f(z_0)}{z-z_0}\,dz \ = \ 0.
\end{equation}
\begin{point}[cauchy-formula-1]%
Let~$\varepsilon>0$ be given.
Since~$f$ is holomorphic at~$z_0$
we can find $\delta>0$ with
$\|f(z)-f(z_0)\|\leq \|z-z_0\|$
for all~$z\in\dom(f)$ with $\|z-z_0\|\leq \delta$. 
\end{point}
\begin{point}%
To use~\sref{cauchy-formula-1},
we must restrict our attention to a smaller polygon.
Let~$q$ be a simple positively oriented polygon 
with $z_0\in \interior(q)$,  $\overline{q}\subseteq \interior(p)$,
$\length(q)\leq \varepsilon$,
and $\|z_0-z\|\leq \delta$ for all~$z\in \partial q$.
By~\sref{goursat}, we have
\begin{equation}
\label{eq:cauchy-formula-2}
\int_p \frac{f(z)-f(z_0)}{z-z_0}
\ = \ 
\int_q \frac{f(z)-f(z_0)}{z-z_0}.
\end{equation}
By~\sref{cauchy-formula-1}
we have
\begin{equation*}
\left\|\,\int_q \frac{f(z)-f(z_0)}{z-z_0}\,dz\,\right\|
\ \leq \ \length(q)\,\cdot\,
\sup_{z\in\partial q} \,\left\|\,\frac{f(z)-f(z_0)}{z-z_0}\,\right\|
\ \leq \ \varepsilon.
\end{equation*}
Since~$\varepsilon>0$ was arbitrary,
we get Eq.~\eqref{eq:cauchy-formula-1}
from Eq.~\eqref{eq:cauchy-formula-2}.\qed
\end{point}
\end{point}
\end{point}
\begin{point}[taylor]{Proposition}%
Let~$f$ be a holomorphic $\scrA$-valued function.
Let~$p$ be a simple positively oriented polygon 
with $\interior(p) \subseteq \dom(f)$.
Then for all~$w,z\in \interior(p)$
with $\|z-w\|<\inf_{u\in \partial p} \left| u-w \right|$,
we have:
\begin{equation*}
f(z)\ = \ 
\sum_{n=0}^\infty \ \frac{1}{2\pi i}\int_p \frac{f(u)}{(u-w)^{n+1}}\,du
\ (z-w)^n.
\end{equation*} 
\begin{point}{Proof}%
By~\sref{cauchy-formula} we have
\begin{alignat*}{3}
2\pi if(z)\ &=\  \int_p \frac{f(u)}{u-z}\,du
\ =\ 
  \int_p  \frac{f(u)}{u-w}\,\frac{1}{1-\frac{z-w}{u-w}}\,du
\end{alignat*}
Since~$\left|z-w\right|<\left|u-w\right|$
for~$u\in \partial p$,
we get, by~\sref{geometric},
\begin{equation*}
2\pi if(z) \ = \ 
  \int_p \frac{f(u)}{u-w}\, \sum_{n=0}^\infty 
\frac{(z-w)^n}{(u-w)^n}
 \,du\ = \ 
  \sum_{n=0}^\infty \ \int_p   \frac{f(u)}{(u-w)^{n+1}}du \ (z-w)^n,
\end{equation*}
where the interchange of ``$\sum$'' and ``$\int$''
was allowed by~\TODO{to add}.\qed
\end{point}
\end{point}
\begin{point}[rigid-expansion]{Exercise}%
Let~$f$ be a holomorphic function with domain~$G$.
We will show that if~$f$ has a power series expansion on a disk around~$0$,
then this power series expansion is also valid on any larger disk
that still fits in~$G$, the domain of~$f$.

Let $S>0$ and $a_1,a_2,\dotsc \in\scrA$ be
such that $z\in G$ and  $f(z)\equiv \sum_n a_nz^n$
for all~$z\in \C$ with $\left|z\right|< S$.
Let~$R\in [0,\infty]$ be the distance of~$0$ to the border of~$G$,
that is,
$R:=\inf\{\left|z\right|\in \C\colon z\notin G\}$.

Show that~$f(z)=\sum_n a_n z^n$
for all~$z\in \C$ with $\left|z\right|< R$.
\TODO{add hints}
\end{point}
\end{parsec}
\subsection{Spectral radius}
\begin{parsec}%
\begin{point}[norm-spectrum]{Proposition}%
For a self-adjoint element~$a$ of a $C^*$-algebra~$\scrA$,
we have
\begin{equation*}
\|a\|\,=\,\sup\{\,\left|\lambda\right|\colon 
\,\lambda\in \spec(a)\,\}.
\end{equation*}
(The quantity on the right hand-side above
is called the \Define{spectral radius} of~$a$.)
\begin{point}{Proof}%
Write~$r=
\sup\{\left|\,\lambda\right|\colon\, \lambda\in \spec(a)\backslash\{0\}\,\}$.
Since~$\left|\lambda\right| \leq \|a\|$
for all~$\lambda\in\spec(a)$
(\sref{spectrum-bounded})
we see that~$r\leq \|a\|$,
and so we only need to show that~$\|a\|\leq r$. 
Note that this is clearly true if~$\|a\|=0$,
so we may assume that~$\|a\|\neq 0$.

The trick is to consider
the power series expansion
around~$0$ of the holomorphic function~$f$ defined
on~$G:=\{\,z\in \C\colon 1-az\text{ is invertible}\,\}$ 
by  $f(z)=z(1-az)^{-1}$.
More specifically,
we are interested in the distance~$R$
of~$0$ to the complement of~$G$,
viz.~$R= \inf\{\left|\lambda\right|\in \C\colon \lambda\notin G\}$,
because since $0\in G$
and $z\notin G\iff z^{-1}\in \spec(a)$,
we have~$R=r^{-1}$
(using the convention $0^{-1}=\infty$).

Note that $f$ has the power series expansion
$f(z) = \sum_n a^nz^{n+1}$
for all~$z\in \C$ with $\|z\|<\|a\|^{-1}$,
because for such~$z$
we have $\sum_n (az)^n=(1-az)^{-1}$
by~\sref{geometric},
and thus~$f(z)=z(1-az)^{-1}=z\sum_n (az)^n = \sum_n a^nz^{n+1}$.

By~\sref{rigid-expansion}
we know that~$f(z)=\sum_n a^nz^{n+1}$
is valid not only for~$z\in \C$ with $\|z\|\leq \|a\|^{-1}$,
but for all~$z$ with $\|z\|\leq R$.

However, $R$ cannot be strictly larger than~$\|a\|^{-1}$,
because for every $z\in\C$ with $\left|z\right|>\|a\|^{-1}$
the series $\sum_n(az)^n$ 
and thus $\sum_n a^n{z}^{n+1}$ diverges (see~\sref{geometric-convergence})
--- using here that~$a$ is self-adjoint.
Hence~$R=\|a\|^{-1}$, and so~$r=\|a\|$.\qed
\end{point}
\end{point}
\begin{point}[spectrum-non-empty]{Exercise}%
Show that $\spec(a)\neq \varnothing$ for an element of a $C^*$-algebra
$\scrA$.
\end{point}
\begin{point}
Given an element~$a$ of a $C^*$-algebra show that
\begin{enumerate}
\item $\spec(a)\neq \varnothing$;
\item $\spec(a) =\{\lambda\}$ iff $a=\lambda$ for every $\lambda \in\C$.
\end{enumerate}
\end{point}
\begin{point}{Exercise (Gelfand--Mazur's Theorem for $C^*$-algebras)}%
Prove that if every non-zero element of a $C^*$-algebra~$\scrA$
is invertible, then~$\scrA=\C$ or~$\scrA=\{0\}$.
\end{point}
\begin{point}[gelfand-mazur-predicament]%
A logical next step
towards Gelfand's representation theorem
is to show that if~$\lambda\in\spec(a)$
for some element~$a$ of a \emph{commutative} $C^*$-algebra~$\scrA$,
then there is a miu-map $f\colon \scrA\to \C$
with~$f(a)=\lambda$.
Here we have moved ourselves in a tight spot
by evading Banach algebras,
because the mentioned result is usually obtained
by finding a maximal ideal~$I$ of~$\scrA$
(by Zorn's Lemma) that contains~$\lambda-a$,
and then forming the \emph{Banach algebra} quotient~$\scrA/I$.
One then applies Gelfand--Mazur's Theorem for \emph{Banach algebras}, 
to see that
$\scrA/I= \C$,
and thereby obtain a miu-map~$f\colon \scrA\to C$ with~$f(a-\lambda)=0$.
The problem here is that while $\scrA/I$
will turn out to be a $C^*$-algebra (indeed, be $\C$)
the formation of the $C^*$-algebra quotient
is non-trivial and depends on Gelfand's representation theorem
(see e.g.~\TODO{conway})
which is the very theorem we are working towards.
The way out of this predicament
is to avoid ideals and quotients of $C^*$- and Banach algebras
altogether,
and instead work 
with order ideals (and what are essentially
 quotients of Riesz and order unit spaces).
To this end,
we develop the theory
of the positive elements of a $C^*$-algebra
farther than is usually done
before Gelfand's representation theorem.
\end{point}
\end{parsec}


\begin{parsec}[cstar-positive-2]%
\begin{point}%
We return to the positive elements 
in a $C^*$-algebra (see~\sref{cstar-positive}).
We'll see that the connection we have establised
between the norm and invertible elements
of a $C^*$-algebra
via the spectral radius (\sref{norm-spectrum})
affects the positive elements as well, see~\sref{cstar-positive-1}.
\end{point}
\begin{point}[real-pos-ineq]{Exercise}%
Show that 
$\left|\,\lambda-t\,\right| \,\leq\, t$ iff  $\lambda \in[0,2t]$,
where $\lambda,t\in\R$.
\end{point}
\begin{point}[pos-spectrum]{Proposition}%
For a self-adjoint element $a$ from a $C^*$-algebra,
and $t\in [0,\infty]$, 
\begin{equation*}
\|a-t\|\,\leq\, t\qquad\iff\qquad \spec(a)\subseteq [0,2t].
\end{equation*}%
\begin{point}{Proof}%
To begin, note that~$\spec(a-t)=\spec(a)-t\subseteq \R$ 
by~\sref{spectrum-basic},
because~$a$ is self-adjoint.
Thus $\|a-t\|=\sup\{\,\left|\lambda-t\right|\colon \lambda\in \spec(a)\,\}$
by~\sref{norm-spectrum}.
Hence $\|a-t\|\leq t$
iff $\left|\lambda-t\right|\leq t$ for all~$\lambda\in\spec(a)$
iff $\spec(a)\subseteq [0,2t]$ (by \sref{real-pos-ineq}).\qed
\end{point}
\begin{point}[cstar-positive-1]{Exercise}%
Show
(using~\sref{pos-spectrum} and~\sref{spectrum-basic})
that
for any self-adjoint element $a$ of a $C^*$-algebra~$\scrA$,
the following are equivalent.
\begin{enumerate}
\item 
\label{cstar-pos-1}
$\|a-t\|\leq t$
for some $t\geq \frac{1}{2}\|a\|$;
\item 
\label{cstar-pos-2}
$\|a-t\|\leq t$
for all $t\geq \frac{1}{2}\|a\|$;
\item 
\label{cstar-pos-3}
$\spec(a)\subseteq[0,\infty)$;
\item
$a$ is positive.
\end{enumerate}
We will complete this list in~\sref{cstar-positive-final}.
\end{point}
\end{point}
\begin{point}[positive-basic-2]{Exercise}%
Let~$\scrA$ be a $C^*$-algebra.
\begin{enumerate}
\item
Show that~$\pos{\scrA}$ is closed.
\item
Let~$a$ be a self-adjoint element of~$\scrA$.
Show that
 $-\lambda \leq a\leq \lambda$
iff $\|a\|\leq \lambda$,
for $\lambda\in [0,\infty)$.
Conclude that $\|a\| = \inf\{ \lambda \in \R\colon 
-\lambda \leq a\leq \lambda\}$.
(Thus $\sa{\scrA}$ is a \emph{complete Archimedean order unit space},
see \TODO{}.)

Show that $0\leq a \leq b$ entails $\|a\|\leq \|b\|$
for $a,b\in\sa{\scrA}$.

\item 
Recall that $ab$ need not be positive if~$a,b\geq 0$. However:

Show that $a^2$ is positive for every self-adjoint element~$a$ of~$\scrA$.

Show that $a^n$ is positive for \emph{even} $n\in \N$ and~$a\in\sa{\scrA}$.

Show that $a^n$ is positive iff $a$ is positive for \emph{odd} $n\in \N$
and $a\in\sa{\scrA}$.

Show that $a^n$ is positive
for every positive $a$ from~$\scrA$ and~$n\in \N$.
\item
Let~$a$ be an invertible element of~$\scrA$.
Show that $a\geq 0$ iff $a^{-1}\geq 0$.

\item
Show that a positive element~$a$ of~$\scrA$ is invertible
iff $a\geq \frac{1}{n}$ for some~$n\in \N$.
\end{enumerate}
\end{point}
\begin{point}[prod-spec]{Lemma}%
For elements $a$ and $b$ from a $C^*$-algebra,
we have
\begin{equation*}
\spec(ab)\backslash\{0\}\ =\ \spec(ba)\backslash\{0\}.
\end{equation*}
\begin{point}{Proof}%
Let~$\lambda\in \C$ with $\lambda\neq 0$ be given.
We must show that $\lambda - ab$ is invertible
iff $\lambda - ba$ is invertible.
Suppose that $\lambda-ab$ is invertible.
Then using the equality$a(\lambda-ba)=(\lambda-ab)a$
one sees that $(1+b(\lambda-ab)^{-1}a)(\lambda-ba)=\lambda$.
Since similarly $(\lambda-ba)(1+b(\lambda-ab)^{-1}a)=\lambda$,
we see that $\lambda^{-1}(1+b(\lambda-ab)a)$
is the inverse of~$\lambda-ba$.\qed
\end{point}
\end{point}
\begin{point}[astara-non-neggative]{Lemma}%
We have $a^*a  \leq 0\implies a=0$
for every element~$a$ of a $C^*$-algebra.
\begin{point}{Proof}%
Suppose that $a^*a\leq 0$.
Then~$\spec(a^*a)\subseteq (-\infty,0]$, almost by definition,
and so $\spec(aa^*)\subseteq (-\infty,0]$ by~\sref{prod-spec},
giving $aa^*\leq 0$.
Thus $a^*a+aa^*\leq 0$.

But on the other hand, 
$a^*a+aa^* = 2(\Real{a}^2 + \Imag{a}^2) \geq 0$,
and so~$a^*a+aa^*=0$.
Then $0\geq a^*a=-aa^*\geq 0$ gives $a^*a=0$,
and $a=0$.\qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
Observe that the norm and order on 
(the self-adjoint elements of a) $C^*$-algebra~$\scrA$
completely determine one another (using the unit):
on the one hand
$\|a\|=\inf\{\lambda\geq 0\colon -\lambda\leq a\leq \lambda\}$
by~\sref{positive-basic-2},
and on the other hand
$a\geq 0$ iff $\|a-s\|\leq s$ for some $s\geq \frac{1}{2}\|a\|$
by definition (\sref{cstar-positive-def}).
This has some useful consequences.
\end{point}
\begin{point}[weak-russo-dye]{Lemma}%
A positive map~$f\colon \scrA\to\scrB$
between $C^*$-algebras
is bounded.
More specifically,
we have
$\|f(a)\|\leq \|f(1)\|\,\|a\|$
for all self-adjoint~$a\in\sa{\scrA}$,
and we have $\|f(a)\|\leq 2\|f(1)\|\,\|a\|$
for arbitrary $a\in \scrA$.
\begin{point}{Proof}%
Given~$a\in\sa{\scrA}$
we have~$-\|a\|\leq a \leq \|a\|$,
and $-\|a\|\,f(1)\leq f(a)\leq \|a\|\,f(1)$
(because $f$ is positive),
and thus~$\|f(a)\|\leq f(1)\,\|a\|\leq \|f(1)\|\,\|a\|$ 
by~\sref{positive-basic-2}.

For an arbitrary element $a\equiv \Real{a}+i\Imag{a}$
of~$\scrA$
we have 
$\|f(a)\|\leq \|f(\Real{a})\|+\|f(\Imag{a})\|\leq 2\|f(1)\|\,\|a\|$.\qed
\end{point}
\begin{point}{Remark}%
It is a non-trivial theorem (known as \Define{Russo--Dye}
in \cite{paulsen}),
that the factor ``2'' in statement above
can be dropped, i.e.~$\|f\|=\|f(1)\|$
(c.f.~Corollary~1 of~\cite{russodye}).
Fortunately for us,
we only use
this improved bound
for completely positive maps
for which it's much easier to obtain (see~\sref{cp-russo-dye}).
\end{point}
\end{point}
\begin{point}[cstar-isometry]{Lemma}%
Show that for a pu-map $f\colon \scrA\to\scrB$
between $C^*$-algebras,
the following are equivalent.
\begin{enumerate}
\item\label{cstar-isometry-1}
	$f$ is \Define{bipositive}, that is, $f(a)\geq 0$ iff $a\geq 0$
	for all~$a\in\scrA$;
\item\label{cstar-isometry-2}
	$f$ is an isometry on~$\sa{\scrA}$, 
	that is, $\|f(a)\|=\|a\|$ for all~$\in \sa{\scrA}$;
\item\label{cstar-isometry-3}
	$f$ is an isometry on~$\pos{\scrA}$.
\end{enumerate}
\begin{point}{Proof}%
It is clear that \ref{cstar-isometry-2} implies~\ref{cstar-isometry-3}.
\begin{point}{\ref{cstar-isometry-1}$\Longrightarrow$\ref{cstar-isometry-2}}%
Let~$a\in \sa{\scrA}$ be given.
Note that $-\lambda \leq a\leq \lambda$
iff $-\lambda \leq f(a) \leq \lambda$
for all~$\lambda \geq 0$,
because~$f$ is bipositive and unital.
In particular,
since~$-\|a\|\leq a\leq \|a\|$,
we have $-\|a\|\leq f(a)\leq \|a\|$,
and so~$\|f(a)\|\leq \|a\|$.
On the other hand,
$-\|f(a)\|\leq f(a)\leq \|f(a)\|$
implies $-\|f(a)\|\leq a\leq \|f(a)\|$,
and so $\|a\|\leq \|f(a)\|$.
Thus $\|a\|=\|f(a)\|$,
and $f$ is an isometry on~$\sa{\scrA}$.
\end{point}
\begin{point}{\ref{cstar-isometry-3}$\Longrightarrow$\ref{cstar-isometry-1}}%
Let~$a\in \scrA$ be given.
We must show that~$f(a)\geq 0$ iff $a\geq 0$.
Since~$f$ is involution preserving (\sref{cstar-p-implies-i})
$a$ is self-adjoint iff $f(a)$ is self-adjoint,
and so we might as well assume that~$a$ is self-adjoint
to start with.
Since~$f$ is an isometry on~$\scrA_+$,
$\|a\|-a$ is positive,
and $f$ is unital,
we have $\|\,\|a\|-a\,\|=\|f(\|a\|-a)\|=\|\,\|a\|-f(a)\,\|$.
Now,
observe that
$0\leq a$
iff
$ \|\,\|a\|-a\,\|\leq \|a\|$,
and that
$\|\,\|a\|-f(a)\,\|\leq \|a\|$ 
iff $0\leq f(a)$,
by~\sref{positive-basic-2},
because $\frac{1}{2}\|a\|\leq \|a\|$
and $\frac{1}{2}\|f(a)\|\leq  \|a\|$
(by~\sref{weak-russo-dye}).\qed
\end{point}
\end{point}
\begin{point}{Warning}%
Such a map~$f$ need not preserve the norm of arbitrary elements:
the map $A\mapsto \frac{1}{2}A+\frac{1}{2}A^T\colon M_2\to M_2$
is bipositive and unital,
but
\begin{equation*}
\left\|\left(\begin{matrix}0&1\\0&0\end{matrix}
\right)\right\|
\ = \ 1 \ \neq \ \frac{1}{2}\ = \ 
\left\|\,\left(\begin{matrix}0 & \nicefrac{1}{2} \\ 0 & 0
\end{matrix}\right)
\,+\,\left(\begin{matrix}0 & 0\\ \nicefrac{1}{2} & 0
\end{matrix}\right)\,\right\|.
\end{equation*}
We'll see later in~\TODO{}
even if~$f$ is completely positive (see~\sref{cp})
$f$ might still only preserve the norm of self-adjoint elements.
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[separating]{Definition}%
A collection~$\Omega$ of maps on a $C^*$-algebra~$\scrA$
will be called
\begin{enumerate}
\item
\Define{separating} if an element~$a$ of~$\scrA$
is zero iff $\omega(a)=0$ for all~$\omega\in\Omega$;
\item
\Define{order separating} if an element~$a$ of~$\scrA$
is positive iff $0\leq \omega(a)$
for all~$\omega\in \Omega$.
\end{enumerate}
\end{point}
\begin{point}{Remark}%
It is clear that an order-separating collection
is separating as well,
and that order separation is the more desirable property.
We'll see an example
of a separating but not order-separating collection
in~\TODO{}.

Examples of order-separating
collections will include
\begin{enumerate}
\item
on a $C^*$-algebra~$\scrA$:
the set of all pu-maps $\omega\colon \scrA\to\C$
(see~\sref{states-order-separating});
\item
on a commutative $C^*$-algebra~$\scrA$:
the set of all miu-maps $\omega\colon \scrA\to\C$
(see \TODO{});
\item
on the $C^*$-algebra~$\scrB(\scrH)$
of bounded operators on some Hilbert space~$\scrH$:
the collection of maps  $\left<x,(\,\cdot\,)x\right>
\colon \scrB(\scrH)\to\C$ where $x\in \scrH$
(see~\sref{hilb-vector-states-order-separating});
\item
on a $C^*$-algebra $\scrA$:
the collection of all miu-maps $\varrho\colon \scrA\to\scrB(\scrH)$
where~$\scrH$ is some Hilbert space (see \TODO{}).
\end{enumerate}
\end{point}
\begin{point}[separating-self-adjoint]{Exercise}%
Let~$\Omega$ be a separating collection of maps on a $C^*$-algebra~$\scrA$.
\begin{enumerate}
\item
Assuming that each~$\omega\in\Omega$ is involution preserving,
show that $a\in\scrA$ is self-adjoint
iff $\omega(a)$ is self-adjoint for all~$\omega\in\Omega$.
\end{enumerate}
\end{point}
\begin{point}[order-separating-norm]{Proposition}%
For a collection~$\Omega$ of pu-maps on a $C^*$-algebra~$\scrA$
the following are equivalent.
\begin{enumerate}
\item 
	$\Omega$ is order separating;
\item
	$\|a\|= \sup_{\omega\in\Omega} \left\|\omega(a)\right\|$
	for all $a\in \sa{\scrA}$;
\item
	$\|a\| = \sup_{\omega\in\Omega} \left\|\omega(a)\right\|$
	for all~$a\in \pos{\scrA}$.
\end{enumerate}
\begin{point}{Proof}%
Denoting the codomain of~$\omega\in\Omega$
by~$\scrB_\omega$
(so that $\omega\colon \scrA\to\scrB_\omega$),
apply~\sref{cstar-isometry}
to the pu-map $\left<\omega\right>_{\omega\in\Omega}\colon 
\scrA\to\bigoplus_{\omega\in\Omega}
\scrB_\omega$.~\TODO{tupling of pu-maps}\qed
\end{point}
\begin{point}{Warning}%
The formula
$\|a\|=\sup_{\omega\in\Omega} \|\omega(a)\|$
need not be correct
for an arbitrary (not necessarily self-adjoint)
element~$a$.
Indeed,
consider the matrix $A:=\smash{%
\bigl(\begin{smallmatrix}0&1\\0&0\end{smallmatrix}\bigr)}$,
and the collection $\Omega=\{\,\left<x,(\,\cdot\,)x\right>\colon 
x\in \C^2,\,\|x\|=1\,\}$,
which will turn out to be order separating.
We have $\|A\|=1$,
while $\left| \left<x,\omega(A)x\right>\right|
 =\left|x_1\right|\left|x_2\right|$
 never exceeds~$\nicefrac{1}{2}$
for $x\equiv (x_1,x_2)\in \scrH$ with $1=\|x\|$.
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
Let us prove
that the pu-maps $\omega\colon \scrA\to\C$
on a $C^*$-algebra~$\scrA$
(called \Define{states} of~$\scrA$ for short)
are order separating.
To this end, we'll show that 
for every self-adjoint element~$a\in \scrA$
there is a state~$\omega$ of~$\scrA$ with $\omega(a)=\|a\|$ or 
$\omega(a)=-\|a\|$.
To obtain such a state
we first find its kernel,
which leads us to the following definitions.
\end{point}
\begin{point}{Definition}%
An \Define{order ideal}
of a $C^*$-algebra~$\scrA$
is a linear subspace~$I$ of~$\scrA$
with $b\in I\implies b^*\in I$
and $b\in I\cap\pos{\scrA}\implies [-b,b]\subseteq I$.
It is called \Define{proper} if~$1\notin I$,
and \Define{maximal} if it is maximal among all proper order ideals.
\end{point}
\begin{point}[order-ideal-basic]{Exercise}%
Let~$\scrA$ be a $C^*$-algebra.
\begin{enumerate}
\item
Show that the kernel of a state is a maximal order ideal.
\item
Let~$I$ be a proper order ideal of~$\scrA$.
Show that there is a maximal 
order ideal~$J$ of~$\scrA$ with $I\subseteq J$.
(Hint: Zorn's Lemma may be useful.)
\item
Let~$a\in \sa{\scrA}$.
Show that 
\begin{equation*}
(a)\ := \ \{\, b\in \scrA\colon\, \exists n,m\in \Z\,
[\ na \,\leq\, \Real{b},\Imag{b}\,\leq\, ma\ ]\,\}
\end{equation*}
is the least order ideal that contains~$a$.

Show that~$1\in (a)$ if and only if $a$ is invertible
and either $0\leq a$ or $a\leq 0$.

\item
Let~$a$ be a self-adjoint element of~$\scrA$ which
is not invertible.
Show that there is a maximal order ideal~$J$
of~$\scrA$
with $a\in J$.

\item
Let~$a$ be a self-adjoint element of~$\scrA$.
Show that  $\|a\|-a$
or $\|a\|+a$ is not invertible.
\end{enumerate}
\end{point}
\begin{point}[maximal-ideal-state]{Lemma}%
For every maximal ideal~$I$ of a $C^*$-algebra~$\scrA$,
 there is a state $\omega \colon \scrA\to \C$
with $\ker(\omega)=I$.
\begin{point}{Proof}%
Form the quotient vector space $\scrA/I$
with quotient map $q\colon \scrA\to \scrA/I$.
Note that since~$1\notin I$
we have $q(1)\neq 0$
and so we may regard~$\C$ 
to be a linear subspace of~$\scrA/I$
via $\lambda\mapsto q(\lambda)$.
We will, in fact, show that~$\C=\scrA/I$.

But let us first put an order on~$\scrA/I$:
we say that $\mathfrak{a}\in \scrA/I$ is positive
if $\mathfrak{a}\equiv q(a)$ for some~$a\in\pos{\scrA}$,
and write $\mathfrak{a}\leq \mathfrak{b}$ 
if $\mathfrak{b}-\mathfrak{a}$ is positive
for $\mathfrak{a},\mathfrak{b}\in\scrA/I$.
Note that the definition of ``order ideal'' is such
that if both~$\mathfrak{a}$ and $-\mathfrak{a}$ are positive,
then~$\mathfrak{a}=0$.
We leave it to the reader to verify 
that~$\scrA/I$ becomes a partially ordered vector space
with the order defined above.
There is, however,
one detail to which I want to draw you attention,
namely that a scalar $\lambda$ is positive in~$\scrA/I$
iff $\lambda$ is positive in~$\C$.
Indeed, if~$\lambda\geq 0$ in~$\C$,
then $\lambda\geq 0$ in~$\scrA$, and so~$\lambda \geq 0$ in~$\scrA/I$.
On the other hand,
if~$\lambda\geq 0$ in~$\scrA/I$, but~$\lambda\leq 0$ in~$\C$,
then $\lambda\leq 0$ in~$\scrA/I$,
and so $\lambda=0$.
This detail
has the desirable consequence
that once we have shown that~$\scrA/I=\C$,
we automatically get that~$q\colon \scrA\to\C$ is positive.

\begin{point}[pos-hahn-banach-1]%
Let~$a\in \sa{\scrA}$ be given.
Define~$\alpha := \inf\{\,\lambda\in\R\colon\, q(a)\leq \lambda\,\}$.
Note that $-\|a\| \leq \alpha\leq \|a\|$.
We will prove that~$q(a)=\alpha$
by considering the order ideal
\TODO{Double check this proof,
because it is simpler than the one given by Kadison---he first 
shows that $\scrA/I$ is total and Archimedean.}
\begin{equation*}
J\ := \ \{\,b\in \scrA\colon\, \exists m,n\in \Z\,[\ 
m(\alpha-q(a)) \,\leq\, q(\Real{b}),q(\Imag{b})\,\leq\, n(\alpha-q(a))\ ]\,\}.
\end{equation*}
We claim that $1\notin I$.
Indeed, suppose not---towards a contradiction.
Then there is~$n\in \Z$
with $1\leq n(\alpha-q(a))$.
What can we say about~$n$?
If~$n<0$,
then $0\geq \frac{1}{n}\geq \alpha-q(a)$,
so~$\alpha-\frac{1}{n} \leq q(a)$,
but $q(a)\leq \alpha+\varepsilon$
for every~$\varepsilon>0$,
and so~$\alpha-\frac{1}{n}\leq q(a)\leq \alpha-\frac{1}{2n}
\leq \alpha-\frac{1}{n}$,
which implies $\frac{1}{2n}=0$,
which is absurd.
If $n=0$,
then we get $1\leq n(\alpha-q(a))\equiv 0$, which is absurd.
If $n> 0$,
then $\frac{1}{n}\leq \alpha-q(a)$,
or in other words,
 $q(a) \leq \alpha - \nicefrac{1}{n}$,
giving $\alpha \leq \alpha-\nicefrac{1}{n}$
by definition of~$\alpha$,
which is absurd.
Hence~$1\notin J$.

But then since~$I\subseteq J$,
we get~$I=J$, by maximality of~$I$.
Thus, as $\alpha-a\in J$, we have $\alpha-a\in I$,
and so $q(a)=\alpha$, as desired.
\end{point}
\begin{point}%
Let~$a\in \scrA$ be given.
Then~$a=\Real{a}+i\Imag{a}$.
By~\sref{pos-hahn-banach-1},
there are $\alpha,\beta\in \R$ with $q(\Real{a})=\alpha$,
and $q(\Imag{a})=\beta$.
Thus~$q(a)=\alpha+i\beta$.
Hence~$\scrA/I=\C$.
Since the quotient map $q\colon \scrA\to \scrA/I\equiv \C$
is pu, and $\ker(q)=I$, we are done.\qed
\end{point}
\end{point}
\begin{point}[states-order-separating]{Exercise}%
Show that given a self-adjoint element~$a$
of a $C^*$-algebra~$\scrA$
there is a state~$\omega$ with $\left|\omega (a)\right| = \|a\|$.
Conclude that the set of states of a $C^*$-algebra
is order separating (see~\sref{separating}).
\end{point}
\end{point}
\end{parsec}
\subsection{The square root}
\begin{parsec}%
\begin{point}%
The key that unlocks the remaining basic facts 
about the (positive) elements of a  $C^*$-algebra
is the existence of the square root~$\sqrt{a}$ of a positive element~$a$,
and its properties.
For technical reasons,
we will assume $\|a\|\leq 1$,
and construct
 $1-\sqrt{1-a}$ instead of~$\sqrt{a}$.
\end{point}
\begin{point}{Lemma}%
Let $a$ be an element of a $C^*$-algebra $\scrA$
with $0\leq a\leq 1$.
Then there is a unique element~$b\in\scrA$ 
with, $0\leq b\leq 1$,
$ab=ba$,
and~$(1-b)^2 = 1-a$.
To be more specific,
$b$ is the limit of
the sequence $b_0\leq b_1\leq \dotsb$
given by $b_0=0$ and $b_{n+1} = \frac{1}{2}(a+b_n^2)$.
Moreover,
if~$c\in\scrA$ commutes with~$a$, then~$c$ commutes with~$b$,
and if in addition $a\leq 1-c^2$ and $c^*=c$,
we have $b\leq 1-c$.
\begin{point}{Proof}%
When discussing $b_n$ it 
is convenient to write~$b_n \equiv q_n(a)$
where~$q_0,q_1,\dotsc$ are the polynomials over~$\R$ given by
$q_0=0$ and $q_{n+1}=\frac{1}{2}(x + q_n^2)$.
For example,
we have~$b_n\geq 0$, 
because all coefficients of~$q_n$ are all positive,
and $a,a^2,a^3,\dotsc$ are positive by~\sref{positive-basic-2}.
With a similar argument we can see that
 $b_0 \leq b_1\leq b_2\leq \dotsb$.
Indeed, 
the coefficients of~$q_{n+1}-q_n$
are positive,
by induction,
because
\begin{alignat*}{3}
q_{n+2}-q_{n+1} \ &=\ \textstyle \frac{1}{2}(x+ q_{n+1}^2)
\,-\, \textstyle\frac{1}{2}(x+q_n^2) \\
&=\ \textstyle\frac{1}{2}(q_{n+1}^2- q_n^2) \\
&=\ \textstyle\frac{1}{2}(q_{n+1}+q_n)(q_{n+1}-q_n) \\
&=\ (q_n+\textstyle\frac{1}{2}(q_{n+1}-q_n))(q_{n+1}-q_n),
\end{alignat*}
has positive coefficients
if~$q_{n+1}-q_n$ has positive coefficients,
and $q_1-q_0\equiv \frac{1}{2}x$ clearly has positive coefficients.
Hence~$b_{n+1}-b_{n} = q_{n+1}(a)- q_n(a)$ is positive.
(Note that we have carefully avoided
using the fact here that the product of positive 
commuting elements is positive,
which is not available to us until~\sref{ineq-square-root}.)

Let us now show that~$b_1\leq b_2\leq \dotsb$ converges.
Let~$n\geq N$ from~$\N$ be given.
Since the coefficients of $q_n-q_N$ are positive,
and $\|a\|\leq 1$,
the triangle inequality gives us
$\|b_n-b_N\|\equiv \|(q_n-q_N)(a)\|\leq q_n(1)-q_N(1)$,
and
so it suffices to 
show that the ascending sequence
 $q_0(1)\leq q_1(1)\leq \dotsb$
of real numbers
converges,
c.q.~is bounded.
Indeed,
we have $q_n(1)\leq 1$,
by induction,
because $q_{n+1}(1)\equiv \frac{1}{2}(1+q_n(1)^2)
\leq 1$ if $q_n(1)\leq 1$,
and clearly $0\equiv q_0(1)\leq 1$.

Let~$b$ be the limit of $b_0\leq b_1\leq\dotsb$.
Then~$b$ being the limit of positive elements
is positive
(see~\sref{positive-basic-2}),
and if $c\in \scrA$ commutes with~$a$,
then $c$ commutes with all powers of~$a$,
and therefore with all~$b_n$,
and thus with~$b$.
Further, 
from the recurrence relation $q_{n+1} = \frac{1}{2}(a+q_n^2)$
we get $b=\frac{1}{2}(a+b^2)$,
and so $-a = -2b+b^2$, 
giving us  $(1-b)^2 = 1-2b+b^2 = 1-a$.

Let us prove that~$b\leq 1$.
To begin, note that~$\|b_n\|\leq 1$ for all~$n$, by induction,
because, $0\equiv \|b_0\|\leq 1$,
and if $\|b_n\|\leq 1$, then $\|b_{n+1}\|\leq \frac{1}{2}(\|a\|+\|b_n\|^2)
\leq 1$, since $\|a\|\leq 1$.
Since~$b_n\geq 0$, we get $-1\leq b_n\leq 1$ for all~$n$,
and so $b\leq 1$.

\begin{point}[square-commuting-monotone]%
Let us take a step back for the moment.
From what we have proven so far
we see that each positive $c\in\scrA$
is of the form $c\equiv d^2$ for some positive~$d\in\scrA$
which commutes with all~$e\in \scrA$ that commute with~$c$.

From this we can see that $c_1c_2\geq 0$
for  
 $c_1,c_2 \in\pos{\scrA}$
with $c_1c_2 = c_2c_1$.
Indeed, writing $c_i\equiv d_i^2$ with $d_i$ as above,
we have $d_1c_2=c_2d_1$ (because $c_1c_2=c_2c_1$), and thus 
$d_1d_2=d_2d_1$. It follows that $d_1d_2$ is self-adjoint,
and $c_1c_2 = (d_1d_2)^2$. Hence $c_1c_2\geq 0$.

We will also need the following corollary.
For~$c,d\in\pos{\scrA}$ with $c\leq d$ and $cd=dc$,
we have $c^2\leq d^2$.
Indeed, $d^2-c^2 \equiv d(d-c)+c(d-c)$
is positive by the previous paragraph.
\end{point}
\begin{point}[ineq-square-root]%
Let~$c\in\sa{\scrA}$ be such that~$ca=ac$ and  $a\leq 1-c^2$.
We must show that $b\leq 1-c$.
Of course,
since~$b$ is the limit of $b_1,b_2,\dotsc$,
it suffices to show that~$b_n\leq 1-c$,
and we'll do this by induction.
Since $0\leq c^2 \leq 1-a$,
 we have $\|c\|^2\leq \|1-a\|\leq 1$,
and so $-1\leq c\leq 1$.
Thus $b_0\equiv 0\leq 1-c$.
Now, suppose that~$b_n\leq 1-c$ for some~$n$.
Then $b_{n+1} = \frac{1}{2}(a+b_n^2)
\leq \frac{1}{2}( (1-c^2)+(1-c)^2) = 1-c$,
where we have used that $b_n^2 \leq (1-c)^2$,
because $b_n\leq 1-c$
by~\sref{square-commuting-monotone}.
\begin{point}%
We can now show that~$b$ is unique.
Let~$b'\in \scrA$ with $0\leq b'\leq 1$,
 $b'a=ab'$ and $(1-b')^2=1-a$ be given;
we must prove that $b'=b$.
Note that $b'\leq 1$,
because $\|1-b'\|^2=\|1-a\|\leq 1$,

From $a=1-(1-b')^2$,
we immediately get $b \leq 1-(1-b')=b'$ by~\sref{ineq-square-root}.
For the other direction,
note that
$(1-b')^2= (1-b)^2 \equiv (1-b'+(b'-b))^2 = (1-b')^2+2(1-b')(b'-b)+(b'-b)^2$,
which gives $0=2(1-b')(b'-b)+(b'-b)^2$.
Now, since~$1-b'$ and $b'-b$ are positive,
and commute, we see that $(1-b')(b'-b)$ is positive 
by~\sref{ineq-square-root}, and so 
 $0=2(1-b')(b'-b)+(b'-b)^2\geq (b'-b)^2 \geq 0$,
which entails $(b'-b)^2=0$, and so $\|(b'-b)^2\|=\|b'-b\|^2=0$,
yielding $b=b'$.\qed
\end{point}
\end{point}
\TODO{Thank Sander}
\end{point}
\end{point}
\begin{point}[sqrt]{Exercise}%
Let~$a$ be a positive element of a $C^*$-algebra~$\scrA$.
Show that there is a unique 
positive element of~$\scrA$
denoted by $\Define{\sqrt{a}}$ with $\smash{\sqrt{a}^2}=a$
and $a\sqrt{a}=\sqrt{a}a$.
Show that if~$c\in\scrA$ commutes with~$a$,
then $c\sqrt{a}=\sqrt{a}c$,
and if in addition $c^*=c$ and $c^2\leq a$,
then $c\leq \sqrt{a}$.
Using this, verify the following facts.
\begin{enumerate}
\item
If~$a,b\in \scrA$ are positive,
and~$ab=ba$,
then $ab\geq 0$.

\item
Let~$a\in\pos{\scrA}$.
If $b,c\in \sa{\scrA}$ commute with~$a$,
then $b\leq c$ implies $ab\leq ac$.

\item
If~$a,b\in\Real{\scrA}$ commute, and~$a\leq b$, then~$a^2\leq b^2$.

\item
The requirement in the previous item  that~$a$ and~$b$ commute is essential:
there are possitive elements $a$, $b$ of a $C^*$-algebra~$\scrA$
with $a\leq b$, but $a^2 \nleq b^2$.

In other words, the square $a\mapsto a^2$
on the possitive elements of a $C^*$-algebra
need not be monotone,
(but $a\mapsto \sqrt{a}$ \emph{is} monotone, see~\sref{sqrt-monotone}).

(Hint: take $a=(\begin{smallmatrix}1&0\\0&0\end{smallmatrix})$
and $b=a+\frac{1}{2}(\begin{smallmatrix}1&1\\1&1\end{smallmatrix})$
from~$M_2$.)
\end{enumerate}
\end{point}
\begin{point}{Definition}
Given a self-adjoint element~$a$ of a $C^*$-algebra $\scrA$,
we write
\begin{equation*}
\textstyle
\Define{\left|a\right|}\ :=\ \sqrt{a^2}
\qquad
\Define{\pos{a}}\ :=\ \frac{1}{2}(\left|a\right| + a)
\qquad
\Define{a_{-}}\ :=\ \frac{1}{2}(\left|a\right| - a).
\end{equation*}
We call $a_+$ the \Define{positive part} of~$a$,
and $a_-$ the \Define{negative part}.
\end{point}
\begin{point}[cstar-pos-neg-part]{Exercise}%
Let~$a$ be a self-adjoint element of a
 $C^*$-algebra $\scrA$.
\begin{enumerate}
\item
Show that $-\left|a\right| \leq a \leq \left| a \right|$,
and $\|\,\left|a\right|\,\|= \|a\|$.
\item
Prove that $a_+$ and $a_-$ are positive,  $a=a_+-a_-$
and $a_+a_-=a_-a_+=0$.
\item
One should not read too much into the notation
$\left|\,\cdot\,\right|$
in the non-commutative case:
give an example of
self-adjoint elements~$a$ and~$b$ of a $C^*$-algebra with
 $\left|a+b\right|\nleq \left|a\right|+ \left|b\right|$.

(Hint: one may take  
$a=\frac{1}{2}\left(\begin{smallmatrix}1 & 1 \\ 1 & 1\end{smallmatrix}\right)$
and $b=-\left(\begin{smallmatrix}1 & 0 \\ 0 & 0 \end{smallmatrix}\right)$.)
\end{enumerate}
\end{point}
\begin{point}%
The existence of positive and negative parts
in a $C^*$-algebra
has many pleasant and subtle consequences
of which we'll now show one (\sref{astara-positive}).
\end{point}
\begin{point}[astara-positive]{Lemma}%
Given an element $a$ of a $C^*$-algebra $\scrA$,
we have $a^*a\geq 0$.
\begin{point}{Proof}%
Writing $b:=a((a^*a)_-)^{\nicefrac{1}{2}}$,
we have $b^*b=-((a^*a)_-)^2\leq 0$,
and so $b=0$ by~\sref{astara-non-neggative}.
Hence~$a^*a_-=0$ giving us $a^*a=(a^*a)_+\geq 0$.\qed
\end{point}
\end{point}
\begin{point}[cstar-positive-final]{Exercise}%
Round up our results regarding positive elements
to 
prove that
the following are equivalent
for a self-adjoint element $a$ of a $C^*$-algebra.
\begin{enumerate}
\item 
$a$ is positive, that is,  $\|a-t\|\leq t$
for some $t\geq \frac{1}{2}\|a\|$;
\item
$\|a-t\|\leq t$ for all~$t\geq \frac{1}{2}\|a\|$;
\item
$a\equiv b^2$ for some self-adjoint $b\in\scrA$;
\item
$a\equiv c^* c$ for some $c\in\scrA$;
\item
$\spec(a)\subseteq [0,\infty)$.
\end{enumerate}
\end{point}
\begin{point}{Exercise}%
The fact that $a^*a$ is positive
for an element~$a$ of a $C^*$-algebra~$\scrA$
has some desirable consequences
we need later on.
\begin{enumerate}
\item
Show that $b\leq c\implies a^*ba \leq a^*ca$
for all~$b,c\in\sa{\scrA}$ and~$a\in\scrA$.
\item
Show that~$a\leq b^{-1}$ 
iff $\sqrt{b}a\sqrt{b}\leq 1$
iff $\|\sqrt{a}\sqrt{b}\|\leq 1$
iff $b^{-1}\leq a$
for positive invertible elements $a$, $b$ of~$\scrA$
(and so $a\leq b$ entails $b^{-1}\leq a^{-1}$).
\TODO{add relevant refs}
\item
Prove that $(1+a)^{-1}a\leq (1+b)^{-1}b$
for $0\leq a\leq b$ from~$\scrA$.\\
(Hint: add $(1+a)^{-1} + (1+b)^{-1}$
to both sides of the inequality.)
\end{enumerate}
\end{point}
\begin{point}[hilb-vector-states-order-separating]{Proposition}%
The vector states
of~$\scrB(\scrH)$
are order separating (see~\sref{separating})
for every Hilbert space~$\scrH$.
\begin{point}{Proof}%
We must show
that~$\|T\|=  \sup_{x\in (\scrH)_1} 
\left|\left< x,Tx\right>\right|$
for given~$T\in\scrB(\scrH)_+$
(see~\sref{operator-norm-ball} and~\sref{order-separating-norm}).
Since $\left|\left<x,Tx\right>\right|
=\left<T^{\nicefrac{1}{2}}x,T^{\nicefrac{1}{2}}x\right>
=\|T^{\nicefrac{1}{2}}x\|^2$
for all~$x\in \scrH$, 
we have $
\|T\| = \|T^{\nicefrac{1}{2}}\|^2
=(\,\sup_{x\in (\scrH)_1}\left\|T^{\nicefrac{1}{2}}x\right\|\,)^2
=\sup_{x\in (\scrH)_1} \left|\left<x,Tx\right>\right|$.\qed
\end{point}
\end{point}
\begin{point}[hilb-positive-operators]{Corollary}%
For a bounded operator~$T$
on a Hilbert space~$\scrH$, we have
\begin{enumerate}
\item
$T$ is self-adjoint iff $\left<x,Tx\right>$
is self-adjoint for all~$x\in (\scrH)_1$;
\item
$0\leq T$ iff $0\leq\left<x,Tx\right>$
for all~$x\in (\scrH)_1$;
\item
	$\|T\|=\sup_{x\in (\scrH)_1}\|\left<x,Tx\right>\|$
when~$T$ is self-adjoint.
\end{enumerate}
\begin{point}{Proof}%
This follows from~\sref{separating-self-adjoint} 
and~\sref{order-separating-norm}
because the vector states on~$\scrB(\scrH)$
are order separating 
by~\sref{hilb-vector-states-order-separating}.\qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
The interaction between the multiplication and order
on a $C^*$-algebra can be subtle
as we have seen in~\TODO{}.  However,
when the $C^*$-algebra is commutative
almost all peculiarities disappear,
as we see in this paragraph.
This is to be expected
as we will see that any commutative $C^*$-algebra
is isomorphic to a $C^*$-algebra
of functions on a compact Hausdorff space.
\end{point}
\begin{point}{Exercise}%
Let~$\scrA$ be a \emph{commutative} $C^*$-algebra.
Let~$a,b,c\in\sa{\scrA}$.
\begin{enumerate}
\item
Show that $\left| a\right|$ is the supremum of~$a$ and~$-a$
in~$\sa{\scrA}$.
\item
Show that if~$a$ and $b$ have a supremum, $a\vee b$, in $\sa{\scrA}$,
then~$c+a\vee b$ is the supremum of~$a+c$ and $b+c$.
\item
Show that~$\sa{\scrA}$ is a \Define{Riesz space},
that is,  a lattice ordered vector space.\\
(Hint: prove that $\frac{1}{2}(a+b+\left|a-b\right|)$
is the supremum of~$a$ and~$b$ in~$\sa{\scrA}$.)
\end{enumerate}
\end{point}
\begin{point}[riesz-decomposition-lemma]{Exercise}%
Prove the \Define{Riesz decomposition lemma}:\\
For positive elements~$a,b,c$ of a commutative $C^*$-algebra~$\scrA$
with~$c\leq a+b$
we have $c\equiv a'+b'$
where  $0\leq a'\leq a$ and $0\leq b'\leq b$.
\end{point}
\end{parsec}
\section{Representation}
\subsection{\dots by Continuous Functions}
\begin{parsec}%
\begin{point}%
Now that we have have a firm grip
on the positive elements of a $C^*$-algebra
we turn to what is perhaps the most important
fact about commutative $C^*$-algebras:
that they are isomorphic to $C^*$-algebras
of continous functions on a compact Hausdorff space,
via the \emph{Gelfand representation}.

\TODO{Show that $\spec(\scrA)$ is a compact Hausdorff space.}
\end{point}
\begin{point}{Setting}%
In this paragraph,
$\scrA$ is a commutative $C^*$-algebra.
\end{point}
\begin{point}[gelfand-representation]{Definition}%
The \Define{spectrum} of~$\scrA$,
denoted by \Define{$\spec(\scrA)$},
is the set of all miu-maps $f\colon \scrA\to \C$.
We endow~$\spec(\scrA)$
with the topology of pointwise convergence.

The \Define{Gelfand representation}
of~$\scrA$
is the miu-map~$\gamma\colon \scrA\to C(\spec(\scrA))$
given by $\gamma(a)(f)=f(a)$.
\begin{point}[gelfand-representation-basic]{Exercise}%
Verify that 
 the map $\spec(\scrA)\to \C,\ f\mapsto f(a)$ is indeed
continuous for every~$a\in\scrA$,
and that~$\gamma$ is miu.
\end{point}
\end{point}
\begin{point}%
Our program for this paragraph is to show that
the Gelfand representation~$\gamma$ is 
a miu-isomorphism.
In fact,
we will show that it gives the unit
of an equivalence between the category of commutative $C^*$-algebras
and the opposite of the category of compact Hausdorff spaces.
The first hurdle we take is the injectivity of~$\gamma$
--- that there are sufficiently many
points in the spectrum of a commutative $C^*$-algebra,
so to speak ---,
and involves Zorn's Lemma,
naturally,
but also the following special type of order ideal.
\end{point}
\begin{point}{Definition}%
A \Define{Riesz ideal} of~$\scrA$
is an order ideal~$I$
such that $a\in I\cap\sa{\scrA}\implies \left|a\right|\in I$.
A \Define{maximal Riesz ideal}
is a proper Riesz ideal which is maximal among
proper Riesz ideals.
\begin{point}{Remark}%
\TODO{Make remark on why Riesz ideals instead of $*$-ring ideals.}
\end{point}
\end{point}
\begin{point}[riesz-ideal-ring-ideal]{Lemma}%
Let~$I$ be a Riesz ideal of~$\scrA$.
For all~$a\in \scrA$ and $x\in I$ we have $ax\in I$.
\begin{point}{Proof}%
Since~$x=\Real{x}+i\Imag{x}$,
it suffices to show that~$a\Real{x}\in I$ and $a\Imag{x}\in I$.
Note that~$\Real{x},\Imag{x}\in I$,
so we might as well assume that~$x$ is self-adjoint to begin with.
Similarly, using that
 $\pos{x}\in I$ (because $\pos{x}=\frac{1}{2}(\left|x\right|+x)$
and~$\left|x\right|\in I$) and $x_-\in I$,
we can reduce the problem to the case that~$x$ is positive.
We may also assume that~$a$ is self-adjoint.
Now, since~$x\geq 0$ and $-\|a\|\leq a\leq \|a\|$,
we have $-\|a\|x \leq ax\leq \|a\|x$
by~\sref{sqrt},
and so~$ax\in I$,
because $\|a\|x\in I$.\qed
\end{point}
\end{point}
\begin{point}[riesz-ideal-basic]{Exercise}%
Verify the following facts about Riesz ideals.
\begin{enumerate}
\item
The least Riesz ideal that contains a self-adjoint element~$a$
of~$\scrA$ is
\begin{equation*}
(a)_m\ :=\ \{\,b\in \scrA\colon\, 
\exists n\in \N\,[\ \left|\Real{b}\right|,\,\left|\Imag{b}\right|
\,\leq\, n\left|a\right| \ ]\,\}.
\end{equation*}
Moreover,  $(a)_m=\scrA$ iff $a$ is invertible,
and we have~$(a)=(a)_m$ when~$a\geq 0$
(where $(a)$ is the least order ideal that contains~$a$,
see~\sref{order-ideal-basic}).
For non-positive~$a$, however, we may have~$(a)\neq (a)_m$.
\item
$I+J$ is a Riesz ideal of~$\scrA$
when $I$ and~$J$ are Riesz ideals. (Hint: use~\sref{riesz-decomposition-lemma}.)
But~$I+J$ might not be an order ideal
when~$I$ and~$J$ are order ideals.

\item
Each proper Riesz ideal is contained in a maximal Riesz ideal.
\end{enumerate}
\end{point}
\begin{point}[maximal-riesz-ideal-maximal-order-ideal]{Lemma}%
A maximal Riesz ideal~$I$ of~$\scrA$
is a maximal order ideal.
\begin{point}{Proof}%
Let~$J$ be a proper order ideal with $I\subseteq J$.
We must show that $J=I$.
Let~$a\in J$ be given;
we must show that $a\in I$.
Since~$\Real{a},\Imag{a}\in J$,
it suffices to show that~$\Real{a},\Imag{a}\in I$,
and so we might as well assume that~$a$ is self-adjoint
to begin with.
Similarly,
since~$\left|a\right|\in J$,
and it suffices to show that~$\left|a\right|\in I$,
because then $-\left|a\right|\leq a\leq \left|a\right|$
entails $a\in I$,
we might as well assume that~$a$ is positive.

Note that the least ideal~$(a)$ that contains~$a$
is also a Riesz ideal by~\sref{riesz-ideal-basic}.
Hence  $I+(a)$ is a Riesz ideal by~\sref{riesz-ideal-basic}
Since~$a\in J$, we have $(a)\subseteq J$,
and so~$I+(a)\subseteq J$ is proper.
It follows that $a\in I+(a)=I$ by maximality of~$I$.\qed
\end{point}
\end{point}
\begin{point}[riesz-ideal-miu-map]{Lemma}%
Let~$I$ be a maximal Riesz ideal of~$\scrA$.
Then there is a miu-map $f\colon \scrA\to \C$
with $\ker(f)=I$.
\begin{point}{Proof}%
Since~$I$ is a maximal order ideal 
by~\sref{maximal-riesz-ideal-maximal-order-ideal},
there is a pu-map $f\colon \scrA\to \C$
with~$\ker(f)=I$ by~\sref{maximal-ideal-state}.
It remains to be shown that~$f$ is multiplicative.
Let~$a,b\in \scrA$ be given;
we must show that $f(ab)=f(a)f(b)$.
Surely, since~$f$ is unital,
we have $f(b-f(b))=f(b)-f(b)=0$,
an so $b-f(b)\in \ker(f)\equiv I$.
Now, since~$I$ is a Riesz ideal,
we have $a(b-f(b))\in I\equiv \ker(f)$ by~\sref{riesz-ideal-ring-ideal},
and so~$0=f(\,a(b-f(b))\,)=f(ab)-f(a)f(b)$.
Hence~$f$ is multiplicative.\qed
\end{point}
\end{point}
\begin{point}[inv-mult-state]{Proposition}%
Let~$a$ be a self-adjoint element of a $C^*$-algebra.
Then~$a$ is not invertible
iff there is $f\in\spec(\scrA)$ 
with~$f(a)=0$.
\begin{point}{Proof}%
\TODO{Move the proof below here.}
\end{point}
\end{point}
\begin{point}[spectrum-miu]{Lemma}%
For each self-adjoint~$a\in\scrA$ 
we have $\spec(a)=\{f(a)\colon f\in\spec(\scrA)\}$.
\begin{point}{Proof}%
Let~$f\in \spec(\scrA)$,
and~$a\in\sa{\scrA}$.
If~$a-f(a)$ would have had an inverse~$b$ in~$\scrA$,
then~$f(b)$ would be an inverse
of~$f(\,a-f(a)\,)=0$ in~$\C$,
which does not exist. Thus~$a-f(a)$ is not invertible,
that is, $f(a)\in \spec(a)$.

Let~$\lambda\in\spec(a)$.
We must find~$f\in \spec(\scrA)$ with~$f(a)=\lambda$.
Since~$a-\lambda$ is not invertible
and self-adjoint	,
the Riesz ideal $(a-\lambda)_m$ is proper
and so there is a maximal Riesz ideal~$I$ that contains~$a-\lambda$
(see~\sref{riesz-ideal-basic}).
By~\sref{riesz-ideal-miu-map}
there is a miu-map $f\in \spec(\scrA)$ with~$\ker(f)=I$.
For this~$f$,
we have, $f(\lambda-a)=0$
(since $\lambda-a\in I$),
and so~$f(a)=\lambda$.\qed

\TODO{What about non-self-adjoint~$a$?}
\end{point}
\end{point}
\begin{point}[gelfand-representation-isometry]{Exercise}%
Prove that $\|\gamma(a)\|=\|a\|$
for each~$a\in\scrA$.
(Hint: first assume that~$a$ is self-adjoint,
and use \sref{spectrum-miu} and~\sref{norm-spectrum}.
For the general case,
use the $C^*$-identity.)

Conclude that the Gelfand representation $\gamma\colon \scrA\to C(\spec(\scrA))$
is injective,
and that its range $\{\gamma(a)\colon a\in\scrA\}$
is a $C^*$-subalgebra of~$C(\spec(\scrA))$.
\end{point}
\begin{point}%
To show that~$\gamma$ is surjective,
we use the following special case of
the Stone--Weierstra\ss{} theorem. 
\end{point}
\begin{point}[stone-weierstrass]{Theorem}%
Let~$X$ be a compact Hausdorff space,
and let~$\scrS$ be a $C^*$-subalgebra of~$C(X)$
which `separates the points of~$X$',
that is, for all~$x,y\in X$
there is~$f\in \scrS$ with $f(x)\neq f(y)$.
Then~$\scrS=C(X)$.
\begin{point}{Proof}%
Let~$g\in \pos{C(X)}$ and $\varepsilon >0$.
To prove that~$\scrS=C(X)$,
it suffices to show that~$g\in \scrS$,
and for this,
it suffices to find~$f\in \scrS$ with $\|f-g\|\leq \varepsilon$,
because~$\scrS$ is closed.
It is convenient to assume that~$g(x)> 0$ for all~$x\in X$,
which we may, without loss of generality,
by replacing~$g$ by~$1+g$.

\begin{point}[stone-weierstrass-1]%
Let~$x,y\in X$.
We know there is~$f\in \scrS$ with $f(x)\neq f(y)$.
Note that we can assume that~$f(x)=0$ (by replacing~$f$ by~$f-f(x)$),
and that~$f$ is self-adjoint (by replacing~$f$
by either~$\Real{f}$ or~$\Imag{f}$),
and that~$f$ is positive
(by replacing~$f$ by~$f_+$ or~$f_-$),
and that~$f(y)=g(y)>0$
(by replacing $f$ by $\frac{g(y)}{f(y)} f$),
and that~$f\leq g(y)$
(by replacing $f$ by $f\wedge g(y)$).
\end{point}
\begin{point}%
Let~$y\in X$ be given.
We will show that there is~$f\in\scrS$
with $0\leq f\leq g+\varepsilon$
and~$f(y)=g(y)$.
Indeed,
since~$g$ is continuous
there is an open neighbourhood~$V$ of~$y$
with~$g(y) \leq  g(x)+\varepsilon$
for all~$x\in V$.
For each~$x\in X\backslash V$ there is $f_x \in [0,f(y)]_{\scrS}$
with $f_x(x)=0$ and~$f_x(y)=g(y)$ by~\sref{stone-weierstrass-1}.
Since the open subsets
$U_x := \{\,z\in X\colon f_x(z)\leq \varepsilon\,\}$
with~$x\in X\backslash V$
form an open cover of the closed (and thus compact) subset $X\backslash V$,
there are $x_1,\dotsc,x_N\in X\backslash U$
with $U_{x_1}\cup\dotsb\cup U_{x_N}=X$.
Define $f:=f_{x_1}\wedge \dotsb \wedge f_{x_N}$.
Then~$f\in \scrS$, $0\leq f\leq g(y)$, $f(y)=g(y)$,
and $f(x)\leq \varepsilon$
for every~$x\in X\backslash U$.

We claim that $f\leq g+\varepsilon$.
Indeed,
if~$x\in X\backslash U$,
then $f(x)\leq \varepsilon\leq g(x)+\varepsilon$.
If~$x\in U$,
then $f(x)\leq g(y)\leq g(x)+\varepsilon$
(by definition of~$U$).
Hence $f\leq g+\varepsilon$.
\end{point}
\begin{point}%
Thus for each~$y\in X$
there is $f_y\in \scrS$ with $0\leq f_y \leq g+\varepsilon$
and~$f_y(y)=g(y)$.
Since~$f_y$ is continuous at~$y$,
and~$f_y(y)=g(y)$,
there is an open neighbourhood~$U_y$ of~$y$
with $g(y)-\varepsilon\leq f_y(x)$
for all~$x\in U_y$.
Since these open neighbourhoods cover~$X$,
and~$X$ is compact,
there are $y_1,\dotsc,y_N\in X$
with $U_{y_1}\cup\dotsb\cup U_{y_N} = X$.
Define $f:=f_{y_1}\vee \dotsb\vee f_{y_N}$.
Then~$f\in\scrS$,
and $g-\varepsilon \leq f\leq g+\varepsilon$,
giving $\|f-g\|\leq \varepsilon$.\qed
\end{point}
\end{point}
\end{point}
\begin{point}[spectrum-calg-compact-hausdorff]{Lemma}%
The spectrum $\spec(\scrA)$ of~$\scrA$ is a compact Hausdorff space.
\begin{point}{Proof}%
Since for each~$a\in \scrA$
and~$f\in \spec(\scrA)$
we have  $\|f(a)\|\leq \|a\|$ 
by~\TODO{},
we see that~$f(a)$ is an element of the compact set
$\{\,z\in \C\colon\, \left|z\right|\leq\|a\|\,\}$,
and so~$\spec(\scrA)$ is a subset of
\begin{equation*}
\textstyle
\prod_{a\in \scrA}\, \{\,z\in \C\colon\, \left|z\right|\leq \|a\|\,\},
\end{equation*}
which is a compact Hausdorff space
(by Tychonoff's theorem \TODO{ref}, under the product topology
it inherits
from the space of all functions $\scrA\to \C$).
So to prove that~$\spec(\scrA)$
is a compact Hausdorff space,
it suffices to show that~$\spec(\scrA)$
is closed.
In other words,
we must show that if~$f\colon \scrA\to \C$
is the pointwise limit of a net of miu-maps $(f_i)_i$,
then~$f$ is a miu-map as well.
But this is easily achieved
using the continuity of addition, involution and multiplication on~$\C$,
because, for instance, 
for~$a,b\in\scrA$, we have $f(ab)
= \lim_i f_i(ab)=\lim_i f_i(a)f_i(b)
 = (\lim_i f_i(a))\,(\lim_i f_i(b))
= f(a) \,f(b)$.\qed
\end{point}
\end{point}
\begin{point}[gelfand]{Gelfand's Representation Theorem}%
For a commutative $C^*$-algebra~$\scrA$,
the Gelfand representation, 
 $\gamma\colon \scrA\to C(\spec(\scrA))$
defined in~\sref{gelfand-representation}
is a miu-isomorphism.
\begin{point}{Proof}%
We already know that~$\gamma$ is an injective miu-map
(see~\sref{gelfand-representation-basic} 
and~\sref{gelfand-representation-isometry}).
So to prove that~$\gamma$ is a miu-isomorphism,
it remains to be shown that~$\gamma$ is surjective.
Since~$\spec(\scrA)$ is a compact Hausdorff space 
(by~\sref{spectrum-calg-compact-hausdorff}),
and~$\gamma(\scrA)\equiv \{\gamma(a)\colon a\in \scrA\}$
is a $C^*$-subalgebra of~$C(\spec(\scrA))$
(by~\sref{gelfand-representation-isometry}),
it suffices to show that~$\gamma(\scrA)$
separates the points of~$\spec(X)$
by~\sref{stone-weierstrass}.
This is obvious,
because
for~$f,g\in \spec(\scrA)$ with~$f\neq g$
there is~$a\in \scrA$ with~$f(a)\equiv \gamma(a)(f)
\neq \gamma(a)(g)\equiv g(a)$.\qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
While Gelfand's representation theorem
is a result about commutative $C^*$-algebras,
it tells us a lot about non-commutative $C^*$-algebras too,
via their commutative $C^*$-subalgebras.
\end{point}
\begin{point}{Exercise}%
Let~$a$ be an element of a $C^*$-algebra~$\scrA$.

Show that there is a least $C^*$-subalgebra of~$\scrA$
--- which we denote by \Define{$C^*(a)$} --- 
that contains~$a$,
and it is the closure of $\{p(a,a^*)\colon p(x,y)\in \C[x,y]\}$,
where~$\C\left[x,y\right]$ is the
ring of polynomials over two non-commuting
variables~$x$ and~$y$.

Show that~$C^*(a)$ is commutative
iff $aa^*=a^*a$ iff $\Real{a}\Imag{a}=\Imag{a}\Real{a}$.
Such~$a$ are called~\Define{normal}.

\TODO{More work}
\TODO{Functional calculus}
\end{point}
\begin{point}[sqrt-monotone]{Theorem}%
We have $0\leq a\leq b \implies a^\alpha \leq b^\alpha$
for all positive elements $a$ and~$b$
of a $C^*$-algebra~$\scrA$,
and $\alpha\in (0,1]$.
\begin{point}{Proof}%
(Based on~\cite{pedersen1972}.)

Note that the result is trivial if~$a$ and~$b$ commute.

Since~$b\mapsto b^\alpha$
is norm continuous as map~$\scrA_+\to\scrA_+$,
and~$\scrA_+$ is closed,
it suffices to show that
$(a+\frac{1}{n})^\alpha \leq (b+\frac{1}{n})^\alpha$
for all~$n$.
In other words,
it suffices to prove $a^\alpha \leq b^\alpha$
under the additional assumption that~$a$ and~$b$ are invertible.
Thus, writing~$E$ for the set of all~$\alpha\in[0,1]$
for which $b\mapsto b^\alpha$ is monotone
on positive,
\emph{invertible} elements of~$\scrA$,
we must prove that~$E=[0,1]$.
Since clearly~$0,1\in E$
it suffices to show that~$E$ is convex,
and we'll do this by showing that~$E$
is closed,
and $\alpha,\beta\in E\implies \frac{1}{2}\alpha 
+ \frac{1}{2}\beta \in E$.

\begin{point}{$E$ is closed}
Let~$b$ be a positive and invertible element of~$\scrA$.
A moment's though reveals it suffices to 
prove that $\alpha\mapsto b^\alpha, \,[0,1]\to\scrA$
is continuous.
Now, since for $\beta\geq \alpha$ from~$[0,1]$
we have $\|b^\beta - b^\alpha\|\leq  
\left\|b^\alpha\right\|\,\left\|b^{\beta-\alpha}-1\right\|
\leq \left\|b^{\beta-\alpha}-1\right\|$,
it suffices to show that $\lim_{n\to\infty} b^{\nicefrac{1}{n}}=1$.
Note that~$\|b^{-1}\|^{-1}\leq b\leq \|b\|$,
and so
$(\|b^{-1}\|^{-1})^{\nicefrac{1}{n}} \leq b^{\nicefrac{1}{n}}\leq 
\|b\|^{\nicefrac{1}{n}}$
for all~$n$.
Since~$\lim_n r^{\nicefrac{1}{n}}=1$ for every~$r>0$,
and~$b^{\nicefrac{1}{n}}$
is sandwiched between such~$r^{\nicefrac{1}{n}}$s,
we get~$\lim_n b_n=1$.
\end{point}
\begin{point}{$\alpha,\beta\in E\implies \frac{1}{2}\alpha+\frac{1}{2}\beta
	\in E$}
Let~$\alpha,\beta\in E$. Let~$a,b\in\scrA$ be positive
and invertible with $a\leq b$.
We must show that $a^{\nicefrac{\alpha+\beta}{2}}\leq 
b^{\nicefrac{\alpha+\beta}{2}}$.
Since the map $b^{\nicefrac{\alpha+\beta}{4}}(\,\cdot\,)
b^{\nicefrac{\alpha+\beta}{4}}$
is positive (by~\TODO{}),
it suffices to show that
$b^{-\frac{\alpha+\beta}{4}}\,a^{\frac{\alpha+\beta}{2}}\,
b^{-\frac{\alpha+\beta}{4}} \leq 1$,
that is, 
$\|b^{-\frac{\alpha+\beta}{4}}\,a^{\frac{\alpha+\beta}{2}}\,
b^{-\frac{\alpha+\beta}{4}} \| \leq 1$.

For this, it seems, we must take a look under the hood
of the theory of $C^*$-algebras:
writing $\varrho(c):=\sup_{\lambda\in \spec(c)}\left|\lambda \right|$
for~$c\in \scrA$,
we know that $\varrho(c)\leq \|c\|$ for any~$c$,
and $\varrho(c)=\|c\|$ for self-adjoint~$c$ by \TODO{...}.
Moreover, recall that by~\TODO{...}
we know that $\spec(cd)\backslash\{0\}
=\spec(dc)\backslash\{0\}$,
and so~$\varrho(cd)=\varrho(dc)$
for all $c,d\in \scrA$.
Hence
\begin{alignat*}{3}
\|\,b^{-\frac{\alpha+\beta}{4}}\,a^{\frac{\alpha+\beta}{2}}\,
b^{-\frac{\alpha+\beta}{4}}\,\| 
\ &=\ 
\varrho(\,b^{-\frac{\alpha+\beta}{4}}\,a^{\frac{\alpha+\beta}{2}}\,
b^{-\frac{\alpha+\beta}{4}} \,) \\
&=\ 
\varrho(\,b^{-\frac{\alpha+\beta}{4}}\,a^{\frac{\alpha+\beta}{2}}\,
b^{-\frac{\alpha+\beta}{4}} \,b^{-\frac{\alpha-\beta}{4}}
\,b^{\frac{\alpha-\beta}{4}}\,) \\
&=\ 
\varrho(
\,b^{\frac{\alpha-\beta}{4}}\,
\,b^{-\frac{\alpha+\beta}{4}}\,a^{\frac{\alpha+\beta}{2}}\,
b^{-\frac{\alpha+\beta}{4}} \,b^{-\frac{\alpha-\beta}{4}}\,)\\
&=\ 
\varrho(
\,b^{-\nicefrac{\beta}{2}}\,a^{\nicefrac{\beta}{2}}\,
a^{\nicefrac{\alpha}{2}}\,
b^{-\nicefrac{\alpha}{2}} \,) \\
&\leq\ 
\|\,b^{-\nicefrac{\beta}{2}}\,a^{\nicefrac{\beta}{2}}\,\|
\,\|\,
a^{\nicefrac{\alpha}{2}}\,
b^{-\nicefrac{\alpha}{2}} \,\|\\
&=\ 
\|\,b^{-\nicefrac{\beta}{2}}\,a^{\beta}\,
b^{-\nicefrac{\beta}{2}}\,\|^{\nicefrac{1}{2}}
\,\|\,
b^{-\nicefrac{\alpha}{2}} \,a^\alpha\,
b^{-\nicefrac{\alpha}{2}} \,\|^{\nicefrac{1}{2}}\\
\ &\leq\ 
\|\,b^{-\nicefrac{\beta}{2}}\,b^{\beta}\,
b^{-\nicefrac{\beta}{2}}\,\|^{\nicefrac{1}{2}}
\,\|\,
b^{-\nicefrac{\alpha}{2}} \,b^\alpha\,
b^{-\nicefrac{\alpha}{2}} \,\|^{\nicefrac{1}{2}} \ = \ 1,
\end{alignat*}
and so we're done.\qed
\end{point}
\end{point}
\end{point}
\end{parsec}

\begin{parsec}[gelfand-equivalence]%
\begin{point}%
As a cherry on the cake,
we use Gelfand's representation theorem~\sref{gelfand}
to get equivalence between the categories $\op{(\cCstar{miu})}$
and~$\CH$.

To set the stage,
we extend $X\mapsto C(X)$ to a functor
$\CH\to \op{(\cCstar{miu})}$
by sending a continuous function~$f\colon X\to Y$
to the miu-map $C(f)\colon C(Y)\to C(X)$
given by~$C(f)(g)=g\circ f$ for $g\in C(Y)$,
and we extend $\scrA\mapsto \spec(\scrA)$
to a functor $\spec\colon \op{(\cCstar{miu})}\to \CH$
by sending a miu-map $\varphi \colon \scrA\to\scrB$
to the continuous map~$\spec(\varphi)\colon \spec(\scrB)\to\spec(\scrA)$
given by~$\spec(\varphi)(f)=f\circ \varphi$.

The Gelfand representations $\gamma_\scrA\colon \scrA\to C(\spec(\scrA))$
form a natural isomorphism
from $C\circ \spec$ to the idenity functor on~$\op{(\cCstar{miu})}$.
So to get an equivalence,
it suffices to find a natural isomorphism
from the identity on~$\CH$ to~$\spec\circ C$,
which is provided by the following lemma.
\end{point}
\begin{point}{Lemma}%
Let~$X$ be a compact Hausdorff space,
and let~$\tau \colon C(X)\to \C$ be a miu-map.
Then there is~$x\in X$ with $\tau(f)=f (x)$
for all~$f\in C(X)$.
\begin{point}{Proof}%
Define
$Z\,= \, \{\,x\in X\colon \ h(x)\neq 0\text{ for some~$h\in \pos{C(X)}$
with $\tau(h)=0$}\,\}$.
We'll prove~$X\backslash Z$ contains
exactly one point, $x_0$, and $\tau(f)=f(x_0)$ for all~$f$.
\begin{point}%`
To see that~$X\backslash Z$ contains no more than one point,
let~$x,y\in X$ with $x\neq y$ be given;
we will show that either~$x\in Z$ or~$y\in Z$.
By the usual topological trickery,
we can find~$f,g\in \pos{C(X)}$
with $fg=0$, $f(x)=1$ and~$g(y)=1$.
Then~$0=\tau(fg)=\tau(f)\,\tau(g)$,
so either~$\tau(f)=0$ (and~$x\in Z$), or~$\tau(g)=0$
(and~$y\in Z$).

That~$X\backslash Z$ is non-empty
follows from the following result (by taking~$f=1$).
\end{point}
\begin{point}[multiplicative-state-on-cx-1]%
For~$f\in \pos{C(X)}$
with~$f(x)> 0 \implies x\in Z$ for all~$x\in X$
we have~$\tau(f)=0$.
Indeed, for each~$x\in X$ with~$f(x)>0$
(and so~$x\in Z$)
we can find~$h\in \pos{C(X)}$
with $\tau(h)=0$ and~$h(x)\neq 0$.
Then~$f(x)< g(x)$
and~$\tau(g)=0$
for $g:=(\frac{f(x)}{g(x)}+1)h$.
By compactness,
we can find $g_1,\dotsc,g_N\in \pos{C(X)}$
with~$\tau(g_n)=0$,
such that for every~$x\in X$
there is~$n$ with $g(x)<f_n(x)$.
Then writing $g:=g_1\vee \dotsb \vee g_N$,
we have $0\leq f\leq g$ and~$\tau(g)=0$
(by~\TODO{miu-map preserves infima}).
It follows that~$\tau(f)=0$.
\end{point}
\begin{point}%
We now know that~$X\backslash Z$ contains exactly
one point, say~$x_0$.
To see that~$\tau(f)=f(x_0)$
for~$f\in C(X)$,
write $g:=(f-f(x_0))^*(f-f(x_0))$
and note that $g(x)>0\implies x\neq x_0\implies  x\in Z$.
Thus by~\sref{multiplicative-state-on-cx-1},
we get $0=\tau(g)=\left|\tau(f)-f(x_0)\right|^2$,
and so $\tau(f)=f(x_0)$.\qed
\end{point}
\end{point}
\begin{point}{Exercise}%
Let~$X$ be a compact Hausdorff space.
Show that for every~$x\in X$
the map $\delta_x\colon C(X)\to \C,\ f\mapsto f(x)$
is miu,
and that the map $X\to \spec(C(X)),\ x\mapsto \delta_x$
is a continuous bijection
onto a compact Hausdorff space,
and thus a homeomorphism.
\end{point}
\end{point}
\begin{point}[injective-miu-isometry]{Exercise}%
As an application of the equivalence
between $\op{(\cCstar{MIU})}$
and~$\CH$,
we will show that every injective miu-map
between $C^*$-algebras
is an isometry.

Show that an arrow $f\colon X\to Y$
in~$\CH$ is mono iff injective, and epi iff surjective
(using complete regularity of~$Y$).
Conclude that~$f$ is both epi and mono in~$\CH$
only if~$f$ is an isomorphism (c.q.~homeomorphism).

Let~$\varrho\colon \scrA\to\scrB$
be an injective miu-map between $C^*$-algebras.
Let~$a$ be a self-adjoint element of~$\scrA$.
Show that~$\varrho$ can be restricted
to a miu-map $\sigma\colon C^*(a)\to C^*(\varrho(a))$,
which is both epi and mono in~$\cCstar{MIU}$.
Conclude that~$\sigma$ is an isomorphism,
and thus~$\|\varrho(a)\|=\|a\|$.
Use the $C^*$-identity
to extend the equality $\|\varrho(a)\|=\|a\|$ 
to (not necessarily self-adjoint) $a\in \scrA$.
\end{point}
\begin{point}[injective-miu-iso-on-image]{Exercise}%
Let~$\varrho\colon \scrA\to\scrB$ 
be an injective miu-map.
Show that~$\varrho(\scrA)$
is closed (using~\sref{injective-miu-isometry}).
Conclude that~$\varrho(\scrA)$
is a
 $C^*$-subalgebra of~$\scrB$
isomorphic to~$\scrA$.
\end{point}
\end{parsec}
\subsection{Representation by Bounded Operators}
\begin{parsec}%
    \begin{point}[completion-inner-product-space]%
Let us prove that every $C^*$-algebra~$\scrA$
is isomorphic
to a $C^*$-algebra
of bounded operators on some Hilbert space.
We proceed as follows.
To each p-map $\omega\colon \scrA\to\C$
we assign a inner product $[\,\cdot\,,\,\cdot\,]_\omega$ on~$\scrA$,
which can be ``completed'' to a Hilbert space $\scrH_\omega$.
Every element~$a\in \scrA$ gives an bounded operator on~$\scrH_\omega$
via the action $b\mapsto ab$, which in turn gives a 
miu-map $\varrho_\omega\colon \scrA\to \scrB (\scrH_\omega)$.
In general $\varrho_\omega$ is not injective,
but if~$\Omega$ is a set of p-maps which separates the
points of~$\scrA$,
then the composition
\begin{equation*}
	\xymatrix@C=6em{
		\scrA\ar[r]^-{\left<\varrho_\omega\right>_{\omega\in \Omega}}
		&
		\bigoplus_{\omega\in\Omega} \scrB(\scrH_\omega)
		\ar[r]
		&
		\scrB(\,\bigoplus_{\omega\in\Omega}\scrH_\omega\,)
	}
\end{equation*}
does give an injective miu-map~$\varrho$,
which restricts to an isomorphism 
(\sref{injective-miu-iso-on-image})
from~$\scrA$
to the $C^*$-algebra~$\varrho(\scrA)$
of bounded operators
on $\bigoplus_{\omega\in \Omega} \scrH_\omega$.

The creation of~$\varrho_\omega$ from~$\omega$
is known as the \emph{Gelfand--Naimark--Segal construction},
and will make a reappearance in the theory of von Neumann algebras
(in~\sref{normal-functionals-lemma}).

\TODO{Mention Paschke as generalization of GNS}.
\end{point}
\begin{point}[state-inner-product]{Lemma}%
For every p-map~$\omega\colon \scrA\to \C$ on a
$C^*$-algebra~$\scrA$,
$\Define{[a,b]_\omega} = \omega(a^*b)$
defines an inner product~$\Define{[\,\cdot\,,\,\cdot\,]_\omega}$ on~$\scrA$
(see~\sref{hilb-def}).
\begin{point}{Proof}%
Note that $[a,a]_\omega\equiv \omega(a^*a)\geq 0$ for each~$a\in\scrA$,
because $a^*a\geq 0$ (by~\sref{astara-positive});
and  $\smash{\overline{[a,b]}_\omega}=[b,a]_\omega$
for $a,b\in\scrA$,
because $\omega$ is involution preserving (by~\sref{p-implies-i}).
Finally, it is clear that $[a,\,\cdot\,]_\omega\equiv\omega(a^*\,\cdot\,)$
is linear for each~$a\in\scrA$.\qed
\end{point}
\end{point}
\begin{point}[omega-norm-basic]{Exercise}%
Let~$\omega\colon \scrA\to\C$
be a p-map on a $C^*$-algebra.
Let us for a moment study
the 
semi-norm
$\Define{\|\,\cdot\,\|_\omega}$ on~$\scrA$
induced by the inner product $[\,\cdot\,,\,\cdot\,]_\omega$
(so~$\smash{\|a\|_\omega = \omega(a^*a)^{\nicefrac{1}{2}}}$),
because it plays an important role
here,
and all throughout the next chapter.
\begin{enumerate}
\item
Use Cauchy--Schwarz
(\sref{inner-product-basic})
to prove \Define{Kadison's inequality}: for all~$a,b\in\scrA$,
\begin{equation*}
\left|\omega(a^*b)\right|^2\ \leq\ \omega(a^*a)\ \omega(b^*b).
\end{equation*}
\item
Show that $\|ab\|_\omega \leq \|\omega\| \,\|a\|\,\|b\|_\omega$
for all $a,b\in\scrA$
(using $a^*a\leq \|a\|^2$).

Show that we do \emph{not} always have 
$\|ab\|_\omega\leq \|\omega\|\|a\|_\omega \|b\|$.

(Hint:
take $a=(\begin{smallmatrix}0&0\\0&1\end{smallmatrix})$
and $b=\frac{1}{2}(\begin{smallmatrix}1&1\\1&1\end{smallmatrix})$
from~$\scrA=M_2$,
and $\omega(\,(\begin{smallmatrix}c & d\\e&f\end{smallmatrix})\,)=c$.)

Show that neither always
$\|ab\|_\omega \leq \|a\|_\omega \|b\|_\omega$,
or
$\|a^*a\|_\omega = \|a\|^2_\omega$.

(Hint: 
take~$a=b=\frac{1}{2}(\begin{smallmatrix}1 & 1 \\ 1 & 1\end{smallmatrix})$
from~$\scrA= M_2$,
and 
$\omega((\,(\begin{smallmatrix}c&d\\e&f\end{smallmatrix})\,)=c$.)

Give a counterexample to $\|a^*\|_\omega = \|a\|_\omega$.
\end{enumerate}
\end{point}
\begin{point}[inner-product-completion]{Exercise}%
Let us begin by showing how a complex vector space~$V$
with inner product
$[\,\cdot\,,\,\cdot\,]$ can be ``completed'' to a Hilbert space~$\scrH$.

We will take for~$\scrH$ the set of Cauchy sequences on~$V$
modulo the following equivalence relation.
Two Cauchy sequences $(a_n)_n$ and~$(b_n)_n$ in~$V$
are considered equivalent
iff $\lim_n \|a_n-b_n\|=0$.
We ``embed'' $V$ into~$\scrH$ via the map $\eta\colon V\to \scrH$
which sends~$a$ to
the constant sequence $a,a,a,\dotsc$.
Note, however, that $\eta$ need not be injective:
show that $\eta(a)=\eta(b)$ iff $\|a-b\|=0$ for all $a,b\in V$.

Show that $d(\,(a_n)_n,\,(b_n)_n\,) = \lim_n \|a_n-b_n\|$
defines a metric on~$\scrH$,
that~$\scrH$ is complete with respect to this metric,
and that if $(a_n)_n$ is a Cauchy sequence in~$V$,
then $(\eta(a_n))_n$ converges to the \emph{element}~$(a_n)_n$ of~$\scrH$
(so $V$ is dense in~$\scrH$).

Show that every uniformly continuous 
map $f\colon V\to X$ to a complete metric space~$X$
can be uniquely extended to a uniformly continuous map $g\colon \scrH\to X$.
(We say that~$g$ extends~$f$ when $f=g\circ \eta$.)

Show that addition, scalar multiplication, and inner product on~$V$
(being uniformly continuous)
can be uniquely extended to uniformly continuous operations on~$\scrH$,
and turn~$\scrH$ into a Hilbert space.
(Also verify that the extended inner product agrees with the complete
metric we've already put on~$\scrH$.)

Show that every bounded linear map $f\colon V\to\scrK$
to a Hilbert space~$\scrK$
can be uniquely extended to a bounded linear map $g\colon \scrH\to\scrK$.

(Categorically speaking,
Hilbert spaces
form a reflexive subcategory of
the category of bounded linear maps between
complex vector spaces with an inner product.)
\end{point}
\begin{point}[gns]{Definition (Gelfand--Naimark--Segal construction)}%
	\\
\TODO{Do we really not need the fact that $\omega$ is unital?}
Let $\omega\colon \scrA\to\C$ be a p-map on a $C^*$-algebra~$\scrA$.

Let~$\Define{\scrH_\omega}$ denote the completion
of~$\scrA$ endowed with the inner product $[\,\cdot\,,\,\cdot\,]_\omega$
(see~\sref{state-inner-product})
to a Hilbert space as discussed in~\sref{inner-product-completion}.
Recall that we have an ``embedding''
$\Define{\eta_\omega}\colon \scrA\to\scrH_\omega$
with $\left<\eta_\omega(a),\eta_\omega(b)\right>
= [a,b]_\omega$ for all~$a,b\in \scrA$.

Since given~$a\in \scrA$
the map $b\mapsto ab,\ \scrA\to\scrA$ is
bounded with respect to~$\|\,\cdot\,\|_\omega$
(because $\|ab\|_\omega\leq \|\omega\|\|a\|\|b\|_\omega$
by~\sref{omega-norm-basic}),
it can uniquely extended to a bounded linear map
$\scrH_\omega\to\scrH_\omega$
(by the universal property of~$\scrH_\omega$, 
see~\sref{inner-product-completion}),
which we'll denote by~$\Define{\varrho_\omega}(a)$.
So~$\varrho_\omega(a)$ is the unique
bounded linear map $\scrH_\omega\to\scrH_\omega$
with $\varrho_\omega(a)(\eta_\omega(b)) = \eta_\omega(ab)$
for all~$b\in\scrA$.
\end{point}
\begin{point}{Proposition}%
The map $\varrho_\omega\colon \scrA\to\scrB(\scrH_\omega)$
given by~\sref{gns} is a miu-map.
\begin{point}{Proof}%
Let~$a_1,a_2\in\scrA$ be given.
Since $\varrho_\omega(a_1+a_2)\,\eta_\omega(b)
= \eta_\omega((a_1+a_2)b)
= \eta_\omega(a_1b)+\eta_\omega(a_2b)
= (\varrho_\omega(a_1) + \varrho_\omega(a_2))\,\eta_\omega(b)$
for all $b\in\scrA$,
and~$\{\eta_\omega(b)\colon b\in\scrA\}$
is dense in~$\scrH_\omega$,
we see that $\varrho_\omega(a_1+a_2)
=\varrho_\omega(a_1)+\varrho_\omega(a_2)$.
Since similarly $\varrho_\omega(\lambda a)
= \lambda\varrho_\omega(a)$
for $\lambda\in\C$ and~$a\in\scrA$,
we see that~$\varrho_\omega$ is linear.

Since $\varrho_\omega(1)\,\eta_\omega(b)
= \eta_\omega(b)$ for all~$b\in\scrA$,
we have $\varrho_\omega(1)\,x=x$
for all~$x\in\scrH_\omega$,
and so~$\varrho_\omega$ is unital,
$\varrho_\omega(1)=1$.

To see that~$\varrho_\omega$ is multiplicative,
note that
$(\varrho_\omega(a_1)\,\varrho_\omega(a_2))\,\eta_\omega(b)
= \eta_\omega(a_1a_2b)=\varrho_\omega(a_1a_2)\,\eta_\omega(b)$
for all~$a_1,a_2,b\in\scrA$.

Let~$a\in\scrA$ be given.
To show that~$\varrho_\omega$ is involution preserving
it suffices to prove that~$\varrho_\omega(a^*)$
is the adjoint of~$\varrho_\omega(a)$.
Since~$\left<\varrho_\omega(a^*)\,\eta_\omega(b),\eta_\omega(c)\right>
\equiv [a^*b,c]_\omega = \omega(b^*ac)=[b,ac]_\omega
\equiv \left<\eta_\omega(b),\varrho_\omega(a)\,\eta_\omega(c)\right>$
for all~$b,c\in\scrA$,
and~$\{\eta_\omega(b)\colon b\in\scrA\}$
is dense in~$\scrH_\omega$,
we get~$\left<\varrho_\omega(a^*)x,y\right>=\left<x,\varrho_\omega(a)y\right>$
for all~$x,y\in\scrH_\omega$,
and so~$\varrho_\omega(a^*)=\varrho_\omega(a)^*$.\qed
\end{point}
\end{point}
\begin{point}[gelfand-naimark-representation]{Definition}%
Given a collection~$\Omega$ of p-maps $\omega\colon \scrA\to\C$
on a $C^*$-algebra~$\scrA$,
let $\Define{\varrho_\Omega}\colon \scrA\to \scrB(\scrH_\Omega)$
be the miu-map given by~$\varrho_\Omega(a)x 
= \sum_{\omega\in\Omega} \varrho_\omega(a)x(\omega)$,
where~$\Define{\scrH_\Omega}=\bigoplus_{\omega\in\Omega}\scrH_\omega$
(and $\varrho_\omega$ is as in~\sref{gns}).
\end{point}
\begin{point}[proto-gelfand-naimark]{Proposition}%
For a collection of positive maps $\scrA\to \C$
on a $C^*$-algebra~$\scrA$,
the following are equivalent.
\begin{enumerate}
\item
\label{proto-gelfand-naimark-1}
$\varrho_\Omega\colon \scrA\to\scrB(\scrH_\Omega)$
is injective;
\item
\label{proto-gelfand-naimark-2}
$\Omega$ is center separating on~$\scrA$;
\item
\label{proto-gelfand-naimark-3}
$\Omega'=\{\,b*\omega\colon \, b\in\scrA,\,\omega\in\Omega\,\}$
is order separating on~$\scrA$.
\end{enumerate}
In that case, $\varrho_\Omega(\scrA)$ is a $C^*$-subalgebra
of~$\scrB(\scrH_\Omega)$,
and~$\varrho_\Omega$
restricts to a miu-isomorphism from~$\scrA$ to~$\varrho_\Omega(\scrA)$.
\begin{point}{Proof}%
It is clear that~\ref{proto-gelfand-naimark-3}
entails~\ref{proto-gelfand-naimark-2}.
\begin{point}{\ref{proto-gelfand-naimark-2}$\Longrightarrow$%
\ref{proto-gelfand-naimark-1}}%
Let~$a\in \scrA$ with $\varrho_\Omega(a)=0$ be given.
We must show that~$a=0$ (in order to show that~$\varrho_\Omega$
is injective),
and for this it is enough to prove that~$a^*a=0$.
Let~$b\in\scrA$ and~$\omega\in\Omega$ be given.
Since~$\Omega$ is center separating,
it suffices to show that $0=\omega(b^*a^*ab) \equiv \|ab\|_\omega^2$.
Since~$\varrho_\Omega(a)=0$,
we have $\varrho_\omega(a)=0$,
thus $0=\varrho_\omega(a)\,\eta_\omega(b)
=\eta_\omega(ab)$,
and so $\|ab\|_\omega=0$.
Hence~$\varrho_\Omega$ is injective.
\end{point}
\begin{point}{\ref{proto-gelfand-naimark-1}$\Longrightarrow$%
\ref{proto-gelfand-naimark-3}}%
Let~$a\in\scrA$ with $(b*\omega)(a)\geq 0$
for all~$\omega\in\Omega$ and~$b\in\scrA$
be given.
We must show that~$a\geq 0$.
Since~$\varrho_\Omega$ is injective,
we know by~\sref{injective-miu-iso-on-image}
that~$\varrho_\Omega(\scrA)$ is a $C^*$-subalgebra
of~$\scrB(\scrH_\Omega)$,
and~$\varrho_\Omega$ restricts to a miu-isomorphism
from~$\scrA$ to~$\varrho_\Omega(\scrA)$.
So in order to prove that~$a\geq 0$,
it suffices to show that $\varrho_\Omega(a)\geq 0$,
and for this we must prove that $\varrho_\omega(a)\geq 0$
for given $\omega\in \Omega$.
Since the vector states on~$\scrH_\omega$ are order separating
by~\sref{hilb-vector-states-order-separating}, it suffices to show that 
$\left<x,\varrho_\Omega(a)x\right>\geq 0$
for given~$x\in \scrH_\omega$.
Since~$\{\eta_\omega(b)\colon b\in\scrA\}$
is dense in~$\scrH_\omega$,
we only need to prove 
that~$0\leq \left<\eta_\omega(b),\varrho_\omega(a)\eta_\omega(b)\right>
\equiv \omega(b^*ab)$ for given~$b\in \scrA$,
but this is true
by assumption.\qed
\end{point}
\end{point}
\end{point}
\begin{point}[gelfand-naimark]{Theorem (Gelfand--Naimark)}%
Every $C^*$-algebra~$\scrA$ is miu-isomorphic
to a $C^*$-algebra of operators on a Hilbert space.
\begin{point}{Proof}%
Since the states on~$\scrA$
are separating
(\sref{states-order-separating}),
and therefore center separating,
the miu-map $\varrho_\Omega\colon \scrA\to\scrB(\scrH_\Omega)$
(defined in~\sref{gelfand-naimark-representation})
restricts to a miu-isomorphism
from~$\scrA$ onto the $C^*$-subalgebra
$\varrho(\scrA)$ of~$\scrB(\scrH_\Omega)$
by~\sref{proto-gelfand-naimark}.\qed
\end{point}
\end{point}
\end{parsec}
\section{Matrices over $C^*$-algebras}
\begin{parsec}%
\begin{point}%
\TODO{see if this material can be moved up}

We have seen (in~\sref{hilb}) that the $N\times N$-matrices
($N$ being a natural number) over the complex numbers~$\C$
form a $C^*$-algebra (denoted by~$M_N$) by interpreting
them as bounded operators on the Hilbert space $\C^N$,
and proving
that the bounded operators~$\scrB(\scrH)$
on any Hilbert space~$\scrH$ form a $C^*$-algebra.

In this paragraph, we'll prove the analogous
and more general
result that the 
$N\times N$-matrices \emph{over a $C^*$-algebra~$\scrA$}
form a $C^*$-algebra by interpreting them
as \emph{adjointable module maps} on
the \emph{Hilbert $\scrA$-module} $\scrA^n$,
see~\sref{chilb-basic} and~\sref{bax-cstar}.
\end{point}
\begin{point}[chilb-basic]{Definition}%
An \Define{inner product} on a right $\scrA$-module
($\scrA$ being a $C^*$-algebra) is a map
$\left<\,\cdot\,,\,\cdot\,\right>\colon X\times X\to\scrA$
such that, for all $x,y\in X$,
$\left<x,\,\cdot\,\right>\colon X\to \scrA$
is a module map, $\left<x,x\right>\geq 0$,
and $\left<x,y\right>=\left<y,x\right>^*$.
We say that such an inner product is \Define{definite}
if~$\left<x,x\right>=0\implies x=0$ for all~$x\in X$.

A \Define{pre-Hilbert $\scrA$-module} $X$
(where~$\scrA$ is always assumed to be a $C^*$-algebra)
is a right $\scrA$-module endowed with a definite inner product.
Such~$X$ is called
a \Define{Hilbert $\scrA$-module}
when it is complete
with respect to
the norm we'll define in~\sref{chilb-norm-basic}.

Let~$X$ and~$Y$ be pre-Hilbert $\scrA$-module.
We say that a map $T\colon X\to Y$
is adjoint to a map $S\colon Y\to X$
when
\begin{equation*}
\left<Tx,y\right>\ =\ \left<x,Sy\right>
\qquad \text{for all $x\in X$ and $y\in Y$}.
\end{equation*}
In that case, we call~$T$ \Define{adjointable}.
It is not difficult to see that~$T$
must be linear, and a module map, and 
adjoint to exactly one~$S$, which we denote by~$\Define{T^*}$.

(Note that we did not require that~$T$
is bounded, and in fact, it need not be, 
see~\sref{hellinger-toeplitz-needs-complete}.
However, if~$T$ is bounded, then so is~$T^*$, 
see~\sref{chilb-form-bounded},
and if either~$X$ or~$Y$ is complete,
then~$T$ is automatically bounded, see~\sref{hellinger-toeplitz}.)

The vector space of adjointable bounded module maps~$T\colon X\to Y$ 
is denoted
by~$\Define{\scrB_a(X,Y)}$,
and we write $\Define{\scrB_a(X)}=\scrB_a(X,X)$.
\end{point}
\begin{point}{Example}%
We endow $\scrA^N$
(where~$\scrA$ is a $C^*$-algebra and~$N$ is a natural number)
with the inner product $\left<x,y\right>=\sum_n x_n^*y_n$,
making it a Hilbert $C^*$-module.
\end{point}
\begin{point}{Exercise}%
Let~$S$ and~$T$ be adjointable operators on a 
pre-Hilbert $\scrA$-module.
\begin{enumerate}
\item
	Show that~$T^*$ is adjoint to~$T$ (and so~$T^{**}=T$).
\item
Show that $(T+S)^*=T^*+S^*$ 
and $(\lambda S)^*=\overline{\lambda}S^*$ for $\lambda\in \C$.
\item
Show that $ST$ is adjoint to $T^*S^*$
(and so $(ST)^*=T^*S^*$).
\end{enumerate}
\end{point}
\begin{point}{Exercise}%
Although a bounded linear map between Hilbert spaces
is always adjointable (see~\sref{hilb-adjoint}),
a bounded module map
between Hilbert $\scrA$-modules
might have no adjoint
as is revealed by the following example
(based on~\cite{paschke}, p.~447).

Prove that~$J:=\{\,f\in C[0,1]\colon\, f(0)=0\,\}$
is a closed right ideal of~$C[0,1]$, and thus a
Hilbert $C[0,1]$-module.

Show that the inclusion $T\colon J\to C[0,1]$
is a bounded module map,
which has no adjoint
by proving that there is no~$b\in J$
with $\left<b,a\right>=Ta\equiv a$ for all~$a\in J$
(for if~$T$ had an adjoint~$T^*$,
then $\left<T^*1,a\right>=\left<1,Ta\right>=a$
for all~$a\in J$).

\begin{point}{Remark}%
Note that part of the problem here is the lack 
of the obvious analog to
Riesz'~representation theorem (\sref{riesz-representation-theorem})  
for Hilbert $\scrA$-modules.
One solution (taken in the literature) is to simply 
add Riesz'~representation theorem as axiom
giving us the \emph{self-dual} Hilbert $\scrA$-modules,
but we'd like to keep Riesz'~representation theorem as a theorem,
and instead assume the Hilbert $\scrA$-module
is complete with respect to a suitable uniformity,
but more on that in~\sref{}.

\TODO{add reference, and, of course, the theorem itself}
\end{point}
\end{point}
\begin{point}[chilb-cs]{Proposition (Cauchy--Schwarz)}%
	We have
$\left<x,y\right>\,\left<y,x\right>
\,\leq\,\left\|\left<y,y\right>\right\|\,\left<x,x\right>$
for every inner product $\left<\,\cdot\,,\,\cdot\,\right>$
on a right $\scrA$-module~$X$,
and $x,y\in X$.
\begin{point}{Proof}%
Let~$\omega\colon \scrA\to \C$ be a state of~$\scrA$.
Since the states on~$\scrA$
are order separating (\sref{states-order-separating}), 
it suffices to show that
$\omega(\,\left<x,y\right>\,\left<y,x\right>\,)
\,\leq\,\left\|\left<y,y\right>\right\|\,\omega(\left<x,x\right>)$.
Noting that $(u,v)\mapsto \omega(\left<u,v\right>)$
is a complex-valued inner product on~$X$,
we compute
\begin{alignat*}{3}
	\omega&(\,\left<x,y\right>\,\left<y,x\right>\,)^2\\
\ &= \ 
\omega(\,\left<x,\,y\left<y,x\right>\right>\,)^2
\\
&\leq\ 
\omega(\left<x,x\right>)\ 
\omega(\,\left<\,y\left<y,x\right>,\, y\left<y,x\right>\,\right>\,)
\qquad
&&\text{by Cauchy--Schwarz, \sref{inner-product-basic}}
\\
&=\ 
\omega(\left<x,x\right>)\ 
\omega(\,\left<x,y\right> \,\left<y,y\right>\, \left<y,x\right>\,)
\\
&\leq\ 
\omega(\left<x,x\right>)\ 
\omega(\,\left<x,y\right>\left<y,x\right>\,)
\  \left\|\left<y,y\right>\right\|
\qquad
&&\text{since $\left<y,y\right>\leq \left\|\left<y,y\right>\right\|$.}
\end{alignat*}
It follows
(also when~$\omega(\,\left<x,y\right>\,\left<y,x\right>\,)=0$),
that $\omega(\,\left<x,y\right>\,\left<y,x\right>\,)\leq
\left\|\left<y,y\right>\right\|\,
\omega(\left<x,x\right>)$,
and so we're done.\qed
\end{point}
\end{point}
\begin{point}{Remark}%
\TODO{that the ``$\|$'' in this version of Cauchy--Schwarz
cannot be dropped}
\end{point}
\begin{point}[chilb-norm-basic]{Exercise}%
Let~$X$ be a pre-Hilbert $\scrA$-module.
Verify that
\begin{enumerate}
	\item
$\Define{\|x\|} = \left\|\left<x,x\right>\right\|^{\nicefrac{1}{2}}$
defines a norm~$\left\|\,\cdot\,\right\|$ on~$X$, and
\item
$\left\|xb\right\|\leq \left\|x\right\|\left\|b\right\|$
and $\left\|\left<x,y\right>\right\|\leq \left\|x\right\|
\left\|y\right\|$
for all~$x,y\in X$ and $b\in \scrA$.
\end{enumerate}
\end{point}
\begin{point}[chilb-form-bounded]{Lemma}%
For a linear map~$T\colon X\to Y$
between pre-Hilbert $\scrA$-modules,
and $B>0$,
the following are equivalent.
\begin{enumerate}
\item 
\label{chilb-form-bounded-1}
$\|Tx\|\leq B\,\|x\|$ for all~$x\in X$
(that is, $T$ is bounded by~$B$);
\item
\label{chilb-form-bounded-2}
$\left\|\left<y,Tx\right>\right\|\leq B\,\|y\|\|x\|$
for all~$x\in X$, $y\in Y$.
\end{enumerate}
Moreover,
if~$T$ is adjointable,
and bounded, then $\|T^*\|=\|T\|$.
\begin{point}{Proof}%
If~$\|Tx\|\leq B\|x\|$ for all~$x\in X$,
then~$T$ is bounded, $\|T\|\leq B$, and therefore
$\left\|\left<y,Tx\right>\right\|
\leq \|y\|\,\|Tx\|\leq B \|y\|\|x\|$
for all~$x\in X$ and~$y\in Y$ using~\sref{chilb-cs}.

On the other hand,
if~\ref{chilb-form-bounded-2} holds,
and~$x\in X$ is given,
then we have $\|Tx\|^2=\left\|\left<Tx,Tx\right>\right\|
\leq B \,\|Tx\|\|x\|$,
entailing $\|Tx\|\leq B\|x\|$
(also when~$\|Tx\|=0$).

If~$T$ is adjointable, and bounded,
then~$\left\|\left<x,T^*y\right>\right\|=\left\|\left<y,Tx\right>\right\|
\leq \|T\|\|y\|\|x\|$ for all~$x\in X$, $y\in Y$,
so~$\|T^*\|\leq \|T\|$,
giving us that~$T^*$ is bounded.
Since by a similar reasoning $\|T\|\leq \|T^*\|$,
we get $\|T\|=\|T^*\|$.\qed
\end{point}
\end{point}
\begin{point}[module-maps-cstar-identity]{Exercise}%
Show that $\|T^*T\|=\|T\|^2$
for every adjointable bounded map~$T$ on a pre-Hilbert $\scrA$-module.
(Hint: adapt the proof of~\sref{operators-cstar-identity}.)
\end{point}
\begin{point}[bax-cstar]{Proposition}%
The adjointable bounded module maps~$\scrB_a(X)$
on a Hilbert $\scrA$-module
form a $C^*$-algebra
with composition as multiplication,
adjoint as involution,
and the operator norm as norm.
\begin{point}{Proof}%
Considering~\sref{bounded-operators-banach-algebra}
and~\sref{module-maps-cstar-identity},
the only thing that remains to be shown is that~$\scrB_a(X)$
is closed (with respect to the operator norm)
in the set of all bounded \emph{linear} maps $\scrB(X)$.
So let~$T\colon X\to X$ be a bounded linear map
which is the limit of a sequence $T_1,T_2,\dotsc$
of adjointable bounded module maps.

Since given $x\in X$, and $b\in\scrA$, we have, for all~$n$,
using~\sref{chilb-norm-basic}
\begin{alignat*}{3}
\left\|\,(Tx)b-T(xb)\,\right\|
\ &\leq\ \left\|((T-T_n)x)b\right\|
\,+\,\left\|(T_n-T)(xb)\right\|
\\
&\leq\ 
2\|T-T_n\|\|x\|\|b\|,
\end{alignat*}
we see that $(Tx)b=T(xb)$, and so~$T$ is a module map.

To see that~$T$ has an adjoint,
note that~$\left\|T_n^*-T_m^*\right\|
=\left\|(T_n-T_m)^*\right\|
=\left\|T_n-T_m\right\|$
for all~$n,m$, and so $T_1^*,\,T_2^*,\,\dotsc$
is a Cauchy sequence,
and converges to some bounded operator~$S$ on~$X$.
Since for~$x,y\in X$ and~$n$,
\begin{alignat*}{3}
\left|\left<Sx,y\right>-\left<x,Ty\right>\right|
\ &\leq\ 
\left|\left<(S-T^*_n)x,y\right>\right|
\,+\,
\left|\left<x,(T_n-T)y\right>\right|
\\
\ &\leq\ 
\|S-T^*_n\|\|x\|\|y\|\,+\,\|T_n-T\|\|x\|\|y\|,
\end{alignat*}
we see that $\left<Sx,y\right>=\left<x,Ty\right>$,
so~$S$ is the adjoint of~$T$,
and~$T$ is adjointable.
\qed
\end{point}
\end{point}
\begin{point}[chilb-vector-states-order-separating]{Exercise}%
Let~$X$ be a Hilbert~$\scrA$-module.
Show that 
the vector states
of~$\scrB^a(X)$
are order separating (see~\sref{separating}).
Conclude that 
for an adjointable operator~$T$ on~$X$
\begin{enumerate}
\item
$T$ is self-adjoint iff $\left<x,Tx\right>$
is self-adjoint for all~$x\in (X)_1$;
\item
$0\leq T$ iff $0\leq\left<x,Tx\right>$
for all~$x\in (X)_1$;
\item
	$\|T\|=\sup_{x\in (X)_1}\|\left<x,Tx\right>\|$
when~$T$ is self-adjoint.
\end{enumerate}
(Hint:~adapt the proofs
of~\sref{hilb-vector-states-order-separating}
and~\sref{hilb-positive-operators}.)
\end{point}
\begin{point}{Corollary}%
The operator
$T^*T$ is positive
in~$\scrB^a(X)$
for every adjointable operator~$T\colon X\to Y$
between Hilbert $\scrA$-modules.
\begin{point}{Proof}%
$\left<x,T^*Tx\right>=
\left<Tx,Tx\right> \geq 0$
for all~$x\in X$,
and so~$T^*T\geq 0$ by~\sref{positive-operators}.\qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}
\begin{point}{Exercise}%
Let us consider matrices over a $C^*$-algebra $\scrA$.
\begin{enumerate}
\item
	Show that every $N\times M$-matrix~$A$ (over~$\scrA$)
gives a bounded module map~$\underline{A}\colon \scrA^N\to\scrA^M$ 
via $\underline{A}(a_1,\dotsc,a_N)= A(a_1,\dotsc,a_M)$,
which is adjoint to~$\underline{A^*}$
(where $\Define{A^*}= (A_{ji}^*)_{ij}$ is conjugate transpose).

\item
Show that $A\mapsto \underline{A}$
gives a linear bijection between the vector 
space of $N\times M$-matrices 
over~$\scrA$ and the vector space of adjointable bounded
module maps~$\scrB^a(\scrA^N,\scrA^M)$.

\item
Show that~$\underline{A}\circ \underline{B} = \underline{AB}$
when $A$ is an $N\times M$ and~$B$ an $M\times K$ matrix.

\item
Conclude that the vector space $\Define{M_N\scrA}$
of $N\times N$-matrices over~$\scrA$
is a $C^*$-algebra
with matrix multiplication (as multiplication),
conjugate transpose as involution,
and the operator norm (as norm, so~$\|A\|=\|\underline{A}\|$).
\end{enumerate}
\end{point}
\begin{point}{Exercise}%
Let us describe the positive  $N\times N$ matrices
over a $C^*$-algebras~$\scrA$.
\begin{enumerate}
\item
Show that an $N\times N$ matrix~$A$ over~$\scrA$
is positive iff $0\leq \sum_{i,j} a_i^* A_{ij} a_j$
for all~$a_1,\dotsc,a_N\in\scrA$.
(Hint: use~\sref{vector-states-order-separating}.)
\item
Show that the matrix $(\,\left<x_i,x_j\right>\,)_{ij}$
is positive for all vectors $x_1,\dotsc,x_N$
from a pre-Hilbert $\scrA$-module~$X$.
\item
Show that the matrix $(a^*_ia_j)_{ij}$
is positive for all $a_1,\dotsc,a_N\in\scrA$.
\end{enumerate}
\end{point}
\begin{point}{Exercise}%
Let~$f\colon \scrA\to\scrB$ be a linear map between $C^*$-algebras.
\begin{enumerate}
\item
Show that applying~$f$ entrywise to a $N\times N$ matrix~$A$
over~$\scrA$ (yielding the matrix $(f(A_{ij}))_{ij}$ over~$\scrB$)
gives a linear map,
which we'll denote by~$\Define{M_Nf}\colon M_N\scrA\to M_N\scrB$.
\item
The map~$M_Nf$ inherits some traits of~$f$:
show that if~$f$ is unital, then~$M_Nf$ unital;
if~$f$ is multiplicative, then $M_Nf$ is multiplicative; and
if~$f$ is involution preserving, then so is~$M_Nf$.
\item
However,
show that $M_nf$ need not be positive when~$f$ is positive,
and that~$M_nf$ need not be bounded, when~$f$ is.
\TODO{give concrete example of a non-completely-positive positive map}
\TODO{give concrete example of a  non-completely-bounded bounded maps}
\end{enumerate}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
Let us briefly return
to the completely positive maps (defined in~\sref{maps}),
to show that a map $f$ between $C^*$-algebras
is completely positive precisely
when~$M_Nf$ is positive for all~$N$,
and to give some examples of completely positive maps.

We also prove two lemmas
stating special properties of completely positive maps (setting
them apart from plain positive maps),
that'll come in very handy later on.
The first one is a variation on Cauchy--Schwarz
(\sref{cp-cs}),
and the second one concerns
the points at which a cpu-map is multiplicative (\sref{choi}).

Completely positive maps are often touted as 
a good model for quantum processes
(over plain positive maps)
with an argument involving the tensor product,
and while we agree,
we submit that the absense of analogues of \sref{cp-cs} and~\sref{choi}
for positive maps
is already enough to make complete positivity indispensable.
\end{point}
\begin{point}[n-pos]{Lemma}%
For a linear map $f\colon \scrA\to\scrB$
between $C^*$-algebras,
and natural number~$N$,
the following are equivalent.
\begin{enumerate}
\item
\label{n-pos-1}
$M_Nf\colon M_N\scrA\to M_N\scrB$
is positive;
\item
\label{n-pos-2}
	$\sum_{ij} b^*_if(a^*_ia_j)b_j \geq 0$
	for all~$a\equiv(a_1,\dotsc,a_N)\in \scrA^N$
	and $b\in \scrB^N$;
\item
\label{n-pos-3}
the matrix $(\,f(a_i^*a_j)\,)_{ij}$
is positive in $M_N\scrB$ for all $a\in\scrA^N$.
\end{enumerate}
\begin{point}{Proof}%
Recall that~$M_Nf$ is positive
iff $(M_Nf)(C)$ is positive for all $C\in \pos{(M_N\scrA)}$.
The trick is to note that such~$C$ can be written as $C\equiv A^*A$
for some~$A\in M_N\scrA$,
and thus as $C \equiv (a_1^T)^* a_1^T+\dotsb+(a_N^T)^*a_N^T$,
where $a_n\equiv(A_{n1},\dotsc,A_{nN})$ is the $n$-th row of~$A$.
Hence~$M_Nf$ is positive
iff $(M_Nf)(\,(a^T)^*a^T\, )\equiv(\,f(a_i^*a_j)\,)_{i,j}$ is positive
for all tuples~$a\in\scrA^N$.
Since~$B\in M_N\scrB$ is positive iff $\left<b,Bb\right>\geq 0$
for all~$b\in \scrB^N$,
we conclude:
$M_Nf$ is positive iff 
$0\leq\left<b,(M_Nf)(\, (a^T)^*a^T\,) b\right>
= \sum_{ij} b_i^*f(a_i^*a_j)b_j$
for all~$a\in\scrA^N$ and~$b\in\scrB^N$.\qed
\end{point}
\end{point}
\begin{point}[cp]{Exercise}%
Conclude from~\sref{n-pos}
that a linear map~$f$ between $C^*$-algebras
is completely positive iff~$M_Nf$ is positive for all~$N$
iff 
for all~$N$ and~$a\in \scrA^N$
the matrix $(\,f(a_i^*a_j)\,)_{i,j}$ 
is positive in~$M_N\scrB$.

Deduce that the composition of cp-maps is
completely positive.

Show that a mi-map~$f$ is completely positive.
(Hint: $M_Nf$ is a mi-map too.)
\end{point}
\begin{point}[ad-cp]{Exercise}%
Show that
given a $C^*$-algebra~$\scrA$,
the following maps are completely positive:
\begin{enumerate}
\item
$b\mapsto a^*ba\colon \scrA\to\scrA$
for every~$a\in\scrA$;
\item
$T\mapsto S^* T S\colon \scrB^a(X)
\to\scrB^a(Y)$
for every adjointable operator $S\colon Y\to X$
between Hilbert $\scrA$-modules;
\item
$T\mapsto \left<x,Tx\right>,\scrB^a(X)\to \scrA$
for every element~$x$ of a Hilbert $\scrA$-module~$X$.
\end{enumerate}
\end{point}
\begin{point}[ccstar-pos-mat]{Lemma}%
Let~$\scrA$ be a commutative $C^*$-algebra,
and let~$N$ be a natural number.
The set of  matrices of the form $\sum_k a_k B_k$,
where $a_1,\dotsc,a_K\in \scrA$
and $B_1,\dotsc,B_K\in M_N(\C)$,
is norm dense in~$(M_N\scrA)_+$.

\TODO{Compare this with that $a\otimes b$ where $a\in\scrA_+$
and $b\in \scrB_+$ do not generate $(\scrA\otimes\scrB)_+$.}
\begin{point}{Proof}%
Since~$\scrA$ is isomorphic to~$C(X)$ for some compact
Hausdorff space~$X$ (by~$\sref{gelfand})$),
we may as well assume that~$\scrA\equiv C(X)$.

Let~$A\in (M_NC(X))_+$ and~$\varepsilon>0$ be given.
We're looking for $g_1,\dotsc,g_K\in C(X)$
and $B_1,\dotsc,B_K\in M_N$
with $\|A-\sum_k g_k B_k\|\leq \varepsilon$.
Since $A(x):=(A_{ij}(x))_{ij}$
gives a continuous map $X\to M_N$,
the sets
$U_x = \{\,y\in X\colon \, \|A(x)-  A(y)\| < \varepsilon\,\}$
form an open cover of~$X$.
By compactness of~$X$
this cover has a finite subcover;
there are $x_1,\dotsc,x_K\in X$ with
$U_{x_1}\cup\dotsb\cup U_{x_K}=X$.

Let~$y\in X$ be given. Since $y\in U_{x_k}$
for some~$k$, there is, by complete regularity of~$X$,
a function $f_y\in (C(X))_+$
with $f_y(y)>0$
and $\supp(f_y)\subseteq U_{x_k}$.
Since the open subsets~$\supp(f_y)$
cover~$X$
there are (by compactness of~$X$) finitely many $y_1,\dotsc y_L$
with $X = \supp(f_{y_1})\cup \dotsb \cup \supp(f_{y_L})$,
and so~$\sum_\ell f_{y_\ell} > 0$.
Let us group together the $f_{y_\ell}$s:
pick for each~$\ell$ an $k_\ell$ with $\supp(f_{y_\ell})\subseteq 
U_{x_{k_\ell}}$,
and let $g_k:= \sum\{f_\ell\colon k_\ell = k\}$.
Then $g_k\in (C(X))_+$,
$\supp(g_k)\subseteq U_k$,
and $\sum_k g_k >0$.
Upon replacing $g_k$ with $g^{-1} g$ if necessary,
we see that $\sum_k g_k=1$.

Since~$\supp(g_k)\subseteq U_{x_k}$,
we have $-\varepsilon \leq A(x)-A(x_k)\leq \varepsilon$
for all~$x\in \supp(g_k)$,
and so  $-g_k(x) \varepsilon
\,\leq\, g_k(x) A(x) - g_k(x) A(x_k)\,\leq\, g_k(x) \varepsilon$
for all~$x\in X$,
that is,  $-g_k \varepsilon
\,\leq\, g_k A - g_k A(x_k)\,\leq\, g_k \varepsilon$.
Summing yields
$-\varepsilon \,\leq\, A- \sum_k g_k A(x_k)\,\leq\, \varepsilon$,
and so $\|A-\sum_k g_k A(x_k)\|\leq \varepsilon$.\qed
\end{point}
\end{point}
\begin{point}[cp-commutative]{Proposition}%
Let~$f\colon \scrA\to\scrB$ be a 
positive map between $C^*$-algebras.
If either~$\scrA$ or~$\scrB$ is commutative,
then~$f$ is completely positive.
\begin{point}{Proof}%
Suppose that~$\scrB$ is commutative,
and let~$a_1,\dotsc,a_N\in \scrA$,
$b_1,\dotsc,b_N\in\scrB$ be given.
We must
show that $\sum_{i,j} b_i^*f(a_i^*a_j)b_j$ is positive.
This follows from the observation that
$\omega(\,\sum_{i,j} b_i^*f(a_i^*a_j)b_j\,)
= \omega(f(\,\sum_{i,j}(a_i\omega(b_i))^*\,a_j \omega(b_j)\,))\,\geq \,0$
for every~$\omega\in\spec(\scrA)$.
\begin{point}%
Suppose instead that~$\scrA$ is commutative,
and let $A\in (M_N\scrA)_+$
be given for some natural number~$N$.
We must show that~$(M_Nf)(A)$ is positive in~$M_N\scrB$.
By~\sref{ccstar-pos-mat},
the problem reduces to the case that~$A\equiv a B$
where~$a\in \scrA_+$ and~$B\in (M_N)_+$.
Since $(M_Nf)(aB)\equiv f(a)B$ is clearly positive
in~$M_N\scrB$,
we are done.\qed
\end{point}
\end{point}
\end{point}
\begin{point}[cstar-positive-2x2matrix]{Lemma}%
For a positive
matrix $A\equiv \bigl(\begin{smallmatrix} p & a \\ a^* & q
\end{smallmatrix}\bigr)$
over a $C^*$-algebra~$\scrA$
we have
\begin{equation*}
	a^*a\ \leq\  \|p\|q
	\quad\text{ and }\quad
	aa^*\leq \|q\|p.
\end{equation*}
In particular,
if $p=0$ or~$q=0$, then~$a=a^*=0$.
\begin{point}{Proof}%
Since $(x,y)\mapsto \left<x,Ay\right>$
gives an $\scrA$-valued inner product
on~$\scrA^2$,
{
\newcommand\twovect[2]{%
\left(\begin{smallmatrix}#1\\#2\end{smallmatrix}\right)}
\newcommand\onezero{\twovect{1}{0}}
\newcommand\zeroone{\twovect{0}{1}}
\begin{alignat*}{3}
	aa^*
	\ &=\  \left<\,\onezero,\,A\zeroone\,\right> \ 
\left<\,\zeroone,\,A\onezero\,\right> \\
\ &\leq\  
\left\|\left<\,\zeroone,\,A\zeroone\right>\right\| \ 
\left<\,\onezero,\,A\onezero\,\right>
\ =\  \|q\|\  p
\end{alignat*}
}
by Cauchy--Schwarz (see \sref{chilb-cs}).

By a similar reasoning, we get $a^*a\leq \|p\|q$.\qed
\end{point}
\end{point}
\begin{point}[cp-cs]{Lemma}%
We have $f(a^*b) f(b^*a)\leq \|f(b^*b)\|\,f(a^*a)$
for every p-map $f\colon \scrA\to\scrB$
between $C^*$-algebras
and $a,b\in\scrA$,
provided that $M_2f$ is positive.
\begin{point}{Proof}%
Since writing $x\equiv (a,b)\in \scrA^2$,
the $2\times 2$ matrix $(x^T)^* x^T\equiv 
	\bigl(
\begin{smallmatrix}
a^*a & a^*b \\
b^*a & b^* b
\end{smallmatrix} \bigr)$
in $M_2\scrA$
is positive,
the $2\times 2$ matrix $T:=\bigl(
\begin{smallmatrix}
	f(a^*a) & f(a^*b) \\
	f(b^*a) & f(b^* b)
\end{smallmatrix}\bigr)$
in~$M_2\scrB$ is positive.
Thus we get $f(a^*b) f(b^*a)\leq \|f(b^*b)\|\,f(a^*a)$
by~\sref{cstar-positive-2x2matrix}.\qed
\end{point}
\end{point}
\begin{point}[cp-russo-dye]{Corollary}
$\|f\|= \|f(1)\|$
for every cp-map $f\colon \scrA\to\scrB$ between $C^*$-algebras.
\begin{point}{Proof}%
Let~$a\in\scrA$ be given.
It suffices to show that $\|f(a)\|\leq \|f(1)\|\,\|a\|$
so that~$\|f\|\leq\|f(1)\|$,
because we already know that~$\|f(1)\|\leq \|f\|\,\|1\| = \|f\|$.
Since $\|f(a^*a)\|\leq \|f(1)\|\,\|a^*a\|$
by~\sref{weak-russo-dye},
we have
 $\|f(a)\|^2=\|f(a)^*f(a)\|=\|f(a^*1)f(1^*a)\|
\leq \|f(1^*1)\|\,\|f(a^*a)\|
\leq \|f(1)\|\, \|f(1)\|\|a^*a\|
= \|f(1)\|^2 \|a\|^2$
by~\sref{cp-cs},
and so~$\|f(a)\|\leq \|f(1)\|\,\|a\|$.\qed
\end{point}
\end{point}
\begin{point}[choi]{Lemma (Choi)}%
We have
$f(a)^*f(a) \leq f(a^* a)$ for
every
cpu-map~$f\colon \scrA\to\scrB$ between $C^*$-algebras,
and~$a\in\scrA$.
Moreover, if $f(a^*a)=f(a)^*f(a)$
for some~$a\in\scrA$,
then~$f(ba)=f(b)(a)$
for all~$b\in \scrA$.
\begin{point}{Proof}%
By~\sref{cp-cs}
we have $f(a)^*f(a)=f(a^* 1)f(1^* a) \leq
\|f(1^*1)\| f(a^*a)=f(a^*a)$,
where we used that~$f$ is unital, viz.~$f(1)=1$.

Let~$a,b\in \scrA$ be given,
and assume that $f(a^*a)=f(a)^*f(a)$.
Instead of~$f(ba)=f(b)f(a)$,
we'll prove that $f(a^*b)=f(a)^*f(b)$
(but this nothing more than  a reformution).
Since~$M_2f$ is cp,
we have, writing 
$A\equiv\bigl(\begin{smallmatrix}a&b\\0&0\end{smallmatrix}\bigr)$,
\begin{alignat*}{3}
\left(\,\begin{matrix}f(a)^*f(a)&f(a)^*f(b)\\
f(b)^*f(a)&f(b)^*f(b)\end{matrix}\,\right) 
	\ &=\ (M_2f)(A)^*\,(M_2f)(A)\\
\ &\leq\ (M_2f)(A^*A) \ =\ 
\left(\,\begin{matrix}f(a^*a)&f(a^*b)\\
f(b^*a)&f(b^*b)\end{matrix}\,\right).
\end{alignat*}
Hence
(using that $f(a^*a)=f(a)^*f(a)$)
the following matrix is positive.
\begin{equation*}
\left(\,\begin{matrix}
0 & f(a^*b) - f(a)^*f(b) \\
f(b^*a)-f(b)^*f(a) & f(b^*b)-f(b)^*f(b)
\end{matrix}\,\right)
\end{equation*}
But then
the corners must vanish
(by~\sref{cstar-positive-2x2matrix}),
and so
$f(a^*b)-f(a)^*f(b)=0$.\qed
\end{point}
\end{point}
\end{parsec}
\section{Towards von Neumann algebras}
\begin{parsec}%
\begin{point}%
Let us work towards
the subject of the next chapter, von Neumann algebras,
by pointing out some special properties
of~$\scrB(\scrH)$
on which the theory of von Neumann algebra is based.
We will show that any bounded directed net
of self-adjoint bounded operators on~$\scrH$
has a supremum (in~$\Real{\scrB(\scrH)}$),
and that the \emph{vector states}
$\left<x,(\,\cdot\,)x\right>\colon \scrB(\scrH)\to\C$
preserve these suprema.
To this end, 
we'll show that~$\scrB(\scrH)$ is complete
with respect to the topology induced by these vector states.
\end{point}
\begin{point}[pub]{Theorem (Uniform Boundedness)}%
A set~$\scrF$ of bounded linear maps 
from a complete normed vector space~$\scrX$
to a normed vector space~$\scrY$
is bounded
in the sense that $\sup_{T\in \scrF} \|T\|<\infty$
provided that 
 $\sup_{T\in \scrF} \|Tx\|<\infty$
 for all~$x\in \scrX$.
\begin{point}{Proof}%
Based on~\cite{sokal}.
\begin{point}[sokal-lemma]%
Let $r>0$ and~$T\in\scrF$ be given.
Writing~$B_r(x)=\{\,y\in\scrX\colon \|x-y\|\leq r\,\}$
for the ball around~$x\in\scrX$ with radius~$r$,
note that $r\|T\|=\sup_{\xi\in B_r(0)} \|T \xi\|$
almost by definition of the operator norm.
We will need the less obvious fact
that $r\|T\|\leq \sup_{y\in B_r(x)}\|T y\|$
for every~$x\in \scrX$.

To see why this is true,
note that for~$\xi\in B_r(0)$
either $\|T\xi\|\leq \|T(x+\xi)\|$
or $\|T\xi\|\leq \|T(x-\xi)\|$,
because we would otherwise have
$2\|T\xi\| = \|T(x+\xi)-T(x-\xi)\|
\leq \|T(x+\xi)\|+\|T(x-\xi)\|<2\|T\xi\|$.
Hence
$r\|T\|=\sup_{\xi\in B_r(0)} \|T\xi\|\leq  
\sup_{y\in B_r(x)} \|Ty\|$.
\end{point}
\begin{point}%
Suppose towards a contradiction
that $\sup_{T\in\scrF}\|T\|=\infty$,
and pick~$T_1,T_2,\dotsc$ with $\|T_n\|\geq n3^{n}$.
Using~\sref{sokal-lemma},
choose $x_1,x_2,\dotsc$ in~$\scrX$
with $\|x_{n}-x_{n-1}\|\leq 3^{-n}$
and~$\|T_{n} x_{n}\|\geq \frac{2}{3}3^{-n}\|T_{n}\|$,
so that~$(x_n)_n$ is a Cauchy sequence, 
and therefore converges to some
$x\in\scrX$.
Note that~$\|x-x_n\|\leq \frac{1}{2}3^{-n}$
(because $\sum_{k=0}^\infty 3^{-k}=\frac{3}{2}$),
and so $\|T_n x\|\geq  \|T_nx_n\| - \|T_n(x_n-x)\|
\geq \frac{2}{3}3^{-n}\|T_n\|-\frac{1}{2}3^{-n}\|T_n\|
\geq \frac{1}{6}n$,
which contradicts
the assumption that $\sup_{T\in \scrF} \|Tx\| <\infty$.\qed
\end{point}
\end{point}
\end{point}
\begin{point}[hellinger-toeplitz]{Theorem}%
Let~$T\colon X\to Y$ be an adjointable map
between pre-Hilbert $\scrA$-modules.
If either~$X$ or~$Y$ is complete,
then~$T$ and~$T^*$ are bounded.
\begin{point}{Proof}%
We may assume without loss of generality
that~$X$ is complete (by swapping~$T$ with~$T^*$
and~$X$ with~$Y$ if necessary).

Note that for every~$y\in Y$,
the linear map $\left<y,T\,\cdot\,\right>\equiv
\left<T^*y,\,\cdot\,\right>\colon Y\to \scrA$
is bounded,
because $\left\|\left<T^*y,x\right>\right\| \leq \|T^*y\|\|x\|$
for all~$x\in X$ (see~\sref{chilb-cs}).

Since 
on the other hand,
$\left\|\left<y,Tx\right>\right\|
\leq \|y\|\,\|Tx\|\leq \|Tx\|$
for all~$x\in X$ and~$y\in Y$ with $\|y\|\leq 1$,
we have $\sup_{\|y\|\leq 1} \|\left<y,Tx\right>\| \leq \|Tx\|<\infty$
for all~$x\in X$,
and thus $B:=\sup_{\|y\|\leq 1} \|\left<y,T\,\cdot\,\right>\|<\infty$
by~\sref{pub}.

It follows that~$\|\left<y,Tx\right>\|\leq B\|y\|\|x\|$
for all~$y\in Y$ and~$x\in X$,
and thus~$T$ and~$T^*$ are bounded, by~\sref{chilb-form-bounded}.\qed
\end{point}
\begin{point}{Remark}%
As a special case of the preceding theorem
we get the fact,
known as the \Define{Hellinger--Toeplitz theorem},
that every symmetric
operator on a Hilbert space is bounded.
\end{point}
\begin{point}[hellinger-toeplitz-needs-complete]{Example}%
The condition that either~$X$ or~$Y$ is complete cannot be dropped:
the linear map $T\colon c_{00}\to c_{00}$
given by $T\alpha = (n\alpha_n)_n$ for $\alpha\in c_{00}$
is self-adjoint,
but not bounded,
because~$T$ maps $(1,\frac{1}{2},\dotsc,\frac{1}{n},0,0,\dotsc)$
having 2-norm below~$\frac{\pi}{\sqrt{6}}$
to $(1,1,\dotsc,1,0,0,\dotsc)$,
which has $2$-norm equal to~$\sqrt{n}$.
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}{Definition}%
A Hilbert $\scrA$-module~$X$ is \Define{self-dual}
when every bounded module map $r\colon X\to \scrA$
is of the form $r\equiv \left<y,(\,\cdot\,)\right>$
for some~$y\in X$.
\end{point}
\begin{point}{Example}%
By Riesz' representation theorem (\sref{riesz-representation-theorem})
every Hilbert space is self-dual.
\end{point}
\begin{point}[chilb-form]{Definition}%
Let us say that a \Define{(bounded) form}
on Hilbert $\scrA$-modules
$X$ and~$Y$
is a map $[\,\cdot\,,\,\cdot\,]\colon X\times Y\to \scrA$
such that $[x,\,\cdot\,]\colon Y\to \scrA$
and $[\,\cdot\,,y]^*\colon X\to \scrA$
are (bounded) module maps for all~$x\in X$ and~$y\in Y$.
\end{point}
\begin{point}[chilb-form-representation]{Proposition}%
Every bounded form  $[\,\cdot\,,\,\cdot\,]\colon X\times Y\rightarrow \scrA$
on self-dual Hilbert $\scrA$-modules
$X$ and~$Y$
is of the form
$[x,y]\equiv \left<Tx,y\right>$
(where $x\in X$ and~$y\in Y$)
for some unique adjointable bounded module map
$T\colon X\to Y$.
\begin{point}{Proof}%
Let $x\in X$ be given.
Since~$[x,\,\cdot\,]\colon Y\to \scrA$ is a
a bounded module map,
and~$Y$ is self-dual,
there is a unique $Tx\in Y$ with
$[x,y]=\left<Tx,y\right>$
for all~$y\in Y$,
giving a map $T\colon X\to Y$.
For a similar reason
we get a map $S\colon Y\to X$
with $\left<Sy,x\right>=[x,y]^*$ 
for all~$x\in X$ and~$y\in Y$.
Since $S$ and~$T$ are clearly adjoint,
they are bounded module maps by~\sref{hellinger-toeplitz}.\qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
	Another consequence of~\sref{pub}
	is this:
\end{point}
\begin{point}[hilb-weakly-bounded-complete]{Proposition}%
Given a net~$(y_\alpha)_\alpha$
in a Hilbert space~$\scrH$
for which $\left<y_\alpha,x\right>$
is Cauchy \emph{and bounded}
for every~$x\in \scrH$,
there is a unique~$y\in\scrH$
with $\left<y,x\right>=\lim_\alpha \left<y_\alpha,x\right>$
for all~$y\in\scrH$.
\begin{point}{Proof}%
To obtain~$x$,
we want to apply  Riesz' representation theorem
(\sref{riesz-representation-theorem})
to the linear map $f\colon \scrH\to\C$
defined by~$f(x)=\lim_\alpha\left<y_\alpha,x\right>$,
but must first show that~$f$ is bounded.
For this it suffices to show
that~$\sup_\alpha \left \|\left<y_\alpha,(\,\cdot\,)\right>\right\|<\infty$,
and this follows by~\sref{pub}
from the assumption 
that $\sup_{\alpha} \left|\left<y_\alpha,x\right>\right| <\infty$
for every~$x\in \scrH$.

By Riesz' representation theorem (\sref{riesz-representation-theorem}),
there is a unique~$x\in\scrH$ with 
$\left<y,x\right>=f(x)\equiv \lim_\alpha \left<y_\alpha,x\right>$
for all~$x\in \scrH$,
and so we're done.\qed
\end{point}
\begin{point}{Remark}%
The condition in~\sref{hilb-weakly-bounded-complete} 
that the net~$(\,\left<y_\alpha,x\right>\,)_\alpha$
is bounded for every~$x$ cannot be omitted
(even though $(\,\left<y_\alpha,x\right>\,)_\alpha$
being Cauchy is eventually bounded).

To see this,
consider a linear map $f\colon \scrH\to\C$ on a Hilbert space~$\scrH$
which is not bounded.
We claim that there is a net~$(y_\alpha)_\alpha$ in~$\scrH$
with $f(x)=\lim_\alpha \left<y_\alpha,x\right>$ for all~$x\in\scrH$,
and so there can be no~$y\in \scrH$ 
with $\left<y,x\right> = \lim_\alpha \left<y_\alpha,x\right>$
for all~$x\in \scrH$, because 
that would imply that~$f$ is bounded.

To create this net,
note that~$f$ is bounded
on the span $\left<F\right>$ of every 
finite subset $F\equiv \{x_1,\dotsc,x_n\}$
of vectors from~$\scrH$,
and so by Riesz' representation theorem~\sref{riesz-representation-theorem}
applied to~$f$ restricted to closed subspace~$\left<F\right>$
of~$\scrH$ there is a unique $y_F\in \left<F\right>$
such that~$f(x)=\left<y_F,x\right>$
for all~$x\in\left<F\right>$.

These $y_F$'s form a net in~$\scrH$
(when we order the finite subsets~$F$ of~$\scrH$ by inclusion),
which approximates~$f$ in the
sense that~$f(x)=\lim_F \left<y_F,x\right>$
for every~$x\in \scrH$,
(because 
$f(x)=\left<y_F,x\right>$
for every~$F$
with $\{x\}\subseteq F$).
\end{point}
\end{point}
\begin{point}{Definition}%
Let~$\scrH$ be a Hilbert space.
\begin{enumerate}
\item
The \Define{weak operator topology}
on~$\scrB(\scrH)$ is least topology
with respect to which $T\mapsto \left<x,Tx\right>,\,\scrB(\scrH)\to\C$
is continuous for every~$x\in\scrH$.
\item
The \Define{strong operator topology}
on~$\scrB(\scrH)$ is the least topology
with respect to which $T\mapsto \|Tx\|\equiv \smash{\left<x,T^*Tx\right>^{%
\nicefrac{1}{2}}}$
is continuous for every~$x\in\scrH$.
\end{enumerate}
\end{point}
\begin{point}[bh-wot-bounded-complete]{Lemma}%
Let~$(T_\alpha)_\alpha$ be a net of bounded operators
on a Hilbert space~$\scrH$
such that $(\,\left<x,T_\alpha x \right>\,)$ is
Cauchy and bounded for every~$x\in \scrH$.

Then~$(T_\alpha)_\alpha$
WOT-converges to some bounded operator~$T$ in $\scrB(\scrH)$.
\begin{point}{Proof}%
Let~$x,y\in \scrH$ be given.
Since by a simple computation
\begin{equation*}
	\textstyle
	\left<y,T_\alpha x\right>
	\ = \ \frac{1}{4}\sum_{k=0}^3
	i^k\left<\,i^ky+x,\,T_\alpha (i^ky+x)\,\right>,
\end{equation*}
 $(\,\left<y,T_\alpha x\right>\,)_\alpha$
is bounded for every~$y\in \scrH$,
and so by~\sref{hilb-weakly-bounded-complete} there is~$Tx\in \scrH$ 
with $\left<y,Tx\right>=\lim_\alpha \left<y,T_\alpha x\right>$
for all~$y\in\scrH$,
giving us a linear map $T\colon \scrH\to \scrH$.
It is clear that~$(T_\alpha)_\alpha$
WOT-converges to~$T$,
provided that~$T$ is bounded.

So to complete the proof,
we must show that~$T$ is bounded,
and we'll do this by showing that~$T$ has an adjoint
(see~\sref{hellinger-toeplitz}).
Note that $\left<x,T_\alpha^* x\right>=\overline{\left<x,T_\alpha x\right>}$
is Cauchy and bounded (with~$\alpha$ running),
so by a similar reasoning as before (but with~$T^*_\alpha$
instead of~$T_\alpha$)
we get a map
$S\colon \scrH\to\scrH$
with $\left<x,Sy\right>=\lim_\alpha \left<x,T^*_\alpha y\right>$
for all~$x,y\in\scrH$, which will be adjoint to~$T$,
which is therefore bounded.\qed
\end{point}
\end{point}
\begin{point}[hilb-suprema]{Proposition}%
Let~$\scrH$ be a Hilbert space,
and~$\scrD$ an upwards directed subset of~$\Real{\scrB(\scrH)}$
with $\sup_{T\in \scrD} \left<x,Tx\right> <\infty$
for all~$x\in \scrH$. Then
\begin{enumerate}
\item
$(T)_{T\in\scrD}$
converges 
in the weak operator topology
to some~$T'$ in~$\Real{(\scrB(\scrH))}$,
\item
$T'$ is the supremum of~$\scrD$
in $\Real{(\scrB(\scrH))}$,
and 
\item
$\left<x,T'x\right> = 
\sup_{T\in\scrD}\left<x,Tx\right> $
for all~$x\in \scrH$.
\end{enumerate}
\begin{point}{Proof}%
Let~$x\in \scrH$.
Since $\left<x,(\,\cdot\,)x\right>\colon \scrB(\scrH)\to \C$
is positive (by~\TODO{}),
we see that
$(\left<x,Tx\right>)_{T\in\scrD}$
is an increasing net in~$\R$, 
bounded from above (by assumption),
and therefore converges to~$\sup_{T\in\scrD}\left<x,Tx\right>$.
In particular,~$(T)_{T\in\scrD}$
is WOT-Cauchy,
and WOT-bounded,
and thus
(by~\sref{bh-wot-bounded-complete})
WOT-converges to some~$T'$ from~$\scrB(\scrH)$.

Since $(\,\left<x,Tx\right>\,)_{T\in\scrD}$
converges both to~$\left<x,T'x\right>$,
and to~$\sup_{T\in\scrD} \left<x,Tx\right>$,
we conclude that $\left<x,T'x\right>=\sup_{T\in\scrD}\left<x,Tx\right>$
for every~$x\in\scrH$.
In particular,  $\left<x,Tx\right>\leq \left<x,T'x\right>$
for all~$x\in\scrH$ and $T\in\scrD$, and thus $T\leq T'$
for all~$T\in\scrD$.

Let~$S$ be a self-adjoint bounded operator on~$\scrH$ with $T\leq S$
for all~$T\in\scrD$.
To prove that~$T'$ is the supremum of~$\scrD$,
we must show that~$T'\leq S$.
Let~$x\in \scrH$ be given.
Since $\left<x,Tx\right>\leq \left<x,Sx\right>$
for each~$T\in \scrD$ (because $T\leq S$),
we have $\left<x,T'x\right>\equiv \sup_{T\in\scrD} \left<x,Tx\right>
\leq \left<x,Sx\right>$,
and therefore $T'\leq S$ by~\TODO{}.\qed
\end{point}
\end{point}
\begin{point}{Definition}%
Let~$\scrH$ be a Hilbert space.
\begin{enumerate}
\item
The supremum of a (norm) bounded directed subset~$\scrD$ 
in~$\Real{(\scrB(\scrH))}$
is denoted by~$\Define{\bigvee\scrD}$.
\item
A p-map $\omega\colon \scrB(\scrH)\to\C$
is called \Define{normal} when
$\omega(\bigvee \scrD)=\bigvee_{T\in\scrD} \omega(T)$
for every bounded directed subset $\scrD$ of~$\Real{\scrB(\scrH)}$.
\end{enumerate}
\end{point}
\begin{point}[bh-normal-effects]{Exercise}%
To show that a map is normal, it suffices to show 
that it preserves directed suprema of \emph{effects}:

Show that given a Hilbert space~$\scrH$
a  positive map $\omega\colon \scrB(\scrH)\to\C$
is normal 
provided that $\omega(\bigvee \scrD) = \bigvee_{T\in\scrD} \omega(T)$
for every directed subset $\scrD$ of $[0,1]_{\scrB(\scrH)}$.
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
Let~$\scrH$ be a Hilbert space.
In~\sref{hilb-suprema}
we saw that maps of the form $a\mapsto \left<x,ax\right>$
are normal 
(i.e.~preserve
suprema of bounded operators on~$\scrH$).
As it turns out,
not every p-map
is normal,
and in fact,
we'll show that if a p-map $\omega$ is normal,
then $\omega\equiv \sum_{n=1}^\infty \left<x_n,(\,\cdot\,)x_n\right>$
for some $x_1,x_2,\dotsc$ in~$\scrH$
with $\sum_n \|x_n\|^2 <\infty$.
\end{point}
\begin{point}{Lemma}%
Every sequence $x_1,x_2,\dotsc $ in a Hilbert space~$\scrH$
with $\sum_n \|x_n\|^2 < \infty$
gives a normal p-map $\omega\colon\scrB(\scrH)\to\C$
defined by~$\omega(T)=\sum_n \left<x_n,Tx_n\right>$.
\begin{point}{Proof}%
Given $T\in\scrB(\scrH)$ 
we have $\left|\left<x_n,Tx_n\right>\right|\leq \|x_n\|^2\|T\|$ 
by Cauchy--Schwarz (\sref{inner-product-basic}),
so $\sum_n \left|\left<x_n,Tx_n\right>\right|
\leq \|T\| \sum_n \|x_n\|^2$,
which means that~$\sum_n \left<x_n,Tx_n\right>$
converges, 
and so we may define~$\omega$ as above.

It is easy that~$\omega$ is linear and positive,
so we'll only show that~$\omega$ is normal.
We must prove that $\omega(\bigvee \scrD)=\bigvee_{T\in\scrD} \omega(T)$
for every bounded directed subset of~$\Real{(\scrB(\scrH))}$.
By~\sref{bh-normal-effects}
we may assume without loss of generality that 
$\scrD\subseteq [0,1]_{\scrB(\scrH)}$.
This has the benefit that $\left<x_n,T x_n\right>$
is positive for all~$n$ and~$T\in\scrD$,
so that their sum (over~$n$) is given by
a supremum over partial sums, viz.~$\sum_n\left<x_n,Tx_n\right>
=\bigvee_N\sum_{n=1}^N\left<x_n,Tx_n\right>$.
Completing the proof is now simply a matter of
interchanging suprema,
\begin{alignat*}{3}
	\textstyle \bigvee_{T\in \scrD} \omega(T)
	\ &=\ 
	\textstyle\bigvee_{T\in \scrD} \bigvee_N \sum_{n=1}^N 
	\left<x_n,Tx_n\right>\\
	\ &=\ 
	\textstyle\bigvee_N \bigvee_{T\in \scrD}\sum_{n=1}^N 
	\left<x_n,Tx_n\right>\\
	\ &=\ 
	\textstyle\bigvee_N \sum_{n=1}^N \left<x_n,(\bigvee \scrD )\,x_n\right>
	\ =\ \textstyle\omega(\bigvee\scrD),
\end{alignat*}
where we used that~$\sum_{n=1}^N \left<x_n,(\,\cdot\,)x_n\right>$
is normal.\qed

\TODO{Perhaps a better way to present this is:
np-maps are closed under suprema and finite sums,
and thus under arbitrary sums}
\end{point}
\end{point}
\TODO{Remark on the ultraweak topology.}
\end{parsec}
\begin{parsec}%
\begin{point}[bh-np]{Theorem}%
Let~$\scrH$ be a Hilbert space.
Every normal p-map $\omega\colon \scrB(\scrH)\to \C$
is of the form $\omega = \sum_n\left<x_n,(\,\cdot\,)x_n\right>$
where $x_1,x_2,\dotsc\in \scrH$
with~$\sum_n \|x_n\|^2=\|\omega\|$.
\begin{point}{Proof}%
	\TODO{}
\end{point}
\end{point}
\end{parsec}
\end{document}
