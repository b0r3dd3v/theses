\documentclass[b5page]{book}
\input{common}
\externaldocument{a}
\externaldocument{b}

\begin{document}
\appendix
\chapter{Solutions, Addenda, Errata}
\begin{erratum}{parsec-40.160}%
    It should be assumed that $T$ is bounded.
\end{erratum}
\begin{erratum}{parsec-50.60}%
Don't follow the hints.
\end{erratum}
\begin{erratum}{parsec-60.30}%
    ``$\|x_\infty-x\|\leq \varepsilon$'' should read  ``$\|x_\infty-x_n\|\leq\varepsilon$''.
\end{erratum}
\begin{erratum}{parsec-110.60}
``$\|a\| < \|b\|$'' in point~2
    should read ``$\|a\|<  \|b^{-1}\|^{-1}$''.
\end{erratum}
\begin{erratum}{parsec-110.150}
In the hint for point 3,
``$a^n+1 = \prod_{k=1}^n a+\zeta^{2k+1}$''
should read
``$a^n+1 = \prod_{k=1}^n a-\zeta^{2k+1}$''.
\end{erratum}
\begin{erratum}{parsec-120.30}
``$(f\cdot g)'=f'\cdot g + g'\cdot f$'' should
    read ``$(f\cdot g)' = f'\cdot g + f\cdot g'$''.
\end{erratum}
\begin{erratum}{parsec-200.30}
Where  ``$\|f(a)\|\leq f(1)\,\|a\|\leq\|f(1)\|\,\|a\|$
    by \sref{parsec-170.60}''
is written
one should read
``$\|f(a)\|\leq\|f(1)\|\,\|a\|$ by \sref{parsec-170.60}''.
\end{erratum}



\begin{solution}{parsec-40.30}%
Let~$\scrX$, $\scrY$ and~$\scrZ$ be normed (complex) vector spaces.
\begin{enumerate}
\item
To show that the operator norm does indeed
give a norm on~$\scrB(\scrX,\scrY)$,
the following
three observations
regarding $S,T\in\scrB(\scrX,\scrY)$
suffice.
\begin{enumerate}
\item
We have $\|S+T\|\leq \|S\|+\|T\|$.

To see this,
note that
given~$x\in \scrX$,
we have $\|Sx\|\leq \|S\|\|x\|$
and $\|Tx\|\leq \|T\|\|x\|$---because $\|S\|$ and $\|T\|$ are bounds
for~$S$ and~$T$, respectively,---and so 
\begin{equation*}
    \|(S+T)x\|
\ \leq\  \|Sx\|+\|Tx\|
\ \leq\  (\|S\|+\|T\|)\|x\|.
\end{equation*}
Thus~$\|S\|+\|T\|$ is a bound for~$S+T$.
Since~$\|S+T\|$ is the least bound for~$S+T$,
we get~$\|S+T\|\leq \|S\|+\|T\|$.

\item
We have
$\|\lambda S\|=\left|\lambda \right| \|S\|$
for any $\lambda \in \C$.

Surely this statement is correct when~$\lambda= 0$.
To see why it's correct for~$\lambda \neq 0$,
note that
$r\mapsto \left|\lambda\right| r$
sends bounds of~$S$ to bounds of~$\lambda S$.
Indeed,
if~$r\in[0,\infty)$ is a bound of~$S$,
then $\|Sx\|\leq r\|x\|$
for all~$x\in \scrX$,
and so~$\|\lambda Sx\| \equiv 
\left|\lambda \right|\|Sx\|\leq \left|\lambda\right| r \|x\|$
for all~$x\in\scrX$,
that is, $\left|\lambda\right|r$
is a bound for~$\lambda S$.
Similarly~$r\mapsto \left|\lambda\right|^{-1} S$
sends bounds of $\lambda S$
to bounds of~$S$.
Since the two aforementioned maps are each other's inverse,
and both are order preserving,
$r\mapsto \left|\lambda \right|r$
gives an order isomorphism from 
the bounds of~$S$ to the bounds of~$\lambda S$,
and, in particular,
    sends the least bound of~$S$ (being $\|S\|$)
to the least bound of~$\lambda S$
        (being~$\|\lambda S\|$),
that is,
$\left|\lambda\right|\|S\|=\|\lambda S\|$.
\item
We have $\|S\|=0$ iff~$S=0$.

Indeed, the following are equivalent:
$\|S\|=0$; the number~$0$ is a bound for~$S$;
$\|Sx\|\leq 0$ for all~$x\in\scrX$;
$Sx=0$ for all~$x\in\scrX$;
$S=0$.
\end{enumerate}
\item
Since $\|STx\|\leq \|S\| \|Tx\|
\leq \|S\|\|T\|\|x\|$
for all~$x\in \scrX$
the operator $ST$ is bounded by
$\|S\|\|T\|$.
\item
Indeed, $ \|\id x \|\equiv \|x\|\leq  1\cdot\|x\|$
for all~$x\in\scrX$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-40.40}%
Recall that we must prove that
    \begin{equation*}
r\|T\|\ = \ \sup_{x\in (\scrX)_r} \|Tx\|.
    \end{equation*}
Since $(\scrX)_r \equiv \{x\in\scrX\colon \|x\|\leq r\}
    = \{rx\colon x\in (\scrX)_1\}$
    the problem becomes
\begin{equation*}
r\|T\|\ = \ \sup_{x\in (\scrX)_1} \|Trx\|
    \,\equiv\, r\sup_{x\in (\scrX)_1} \|Tx\|.
\end{equation*}
So we've reduced the 
problem to the case~$r=1$, that is, to showing that
\begin{equation*}
    \|T\|\ = \ \sup_{x\in (\scrX)_1} \|Tx\|.
\end{equation*}
Since for~$x\in (\scrX)_1$
we have $\|x\|\leq 1$,
and so~$\|Tx\|\leq \|T\|\,\|x\|\leq \|T\|$,
we see that~$\sup_{x\in (\scrX)_1} \|Tx\|\leq \|T\|$.
For the other direction,
    $\|T\|\leq \sup_{x\in (\scrX)_1} \|Tx\|$,
    it suffices to show that
 $r:=\sup_{x\in(\scrX)_1} \|Tx\|$
is a bound for~$T$,
that is, we must show given~$x\in\scrX$
that $\|Tx\|\leq r\|x\|$.
When~$x=0$ this is obvious, so we'll assume that~$x\neq 0$.
Then~$\| \,x\|x\|^{-1}\,\|\leq 1$,
    so $\|x\|^{-1} \|Tx\|\equiv \|\,T x \|x\|^{-1}\, \| \leq r$,
    and thus $\|Tx\|\leq r\|x\|$,
    making $r$ is a bound for~$T$.
\end{solution}
\begin{solution}{parsec-40.100}%
Taking~$y:=x-x'$ we see that
$\|y\|^2 = \left<y,y\right>
= \left<y,x\right> - \left<y,x'\right> = 0$,
so~$\|y\|=0$,
so~$y\equiv x-x'=0$,
and thus~$x=x'$.

For the second part,
let~$T_1,T_2\colon \scrH\to\scrK$
be operators between pre-Hilbert spaces~$\scrH$
and~$\scrK$
that are both adjoint to an operator~$S\colon \scrK\to\scrH$.
We must show that~$T_1=T_2$.
Given $x\in\scrH$ we have
\begin{equation*}
\left<T_1x,y\right>
\ = \ 
\left<x,Sy\right>
\ = \ 
\left<T_2x,y\right>
\qquad 
    \text{for all~$y\in\scrK$,}
\end{equation*}
and so~$T_1x=T_2x$ by the previous part.
Whence~$T_1=T_2$.
\end{solution}
\begin{solution}{parsec-40.120}%
We prove slightly more than was requested.
Let~$\scrH$, $\scrK$ and~$\scrL$ be pre-Hilbert spaces.
\begin{enumerate}
\item
Let~$T\colon \scrH\to\scrK$ be an adjointable operator,
        so we know that~$T$ is adjoint to some (by~\sref{parsec-40.100}
        unique) operator~$T^*\colon \scrK\to\scrH$.
We must show that $T^*$ is adjoint to~$T$ too.

Let~$x\in\scrH$ and~$y\in\scrK$ be given.
Since~$T$ is adjoint to~$T^*$,
we know that~$\left<Tx,y\right>=\left<x,T^*y\right>$,
and so taking the complex conjugate, we get
        \begin{equation*}
\left<y,Tx\right>\  =\  
    \overline{\left<Tx,y\right>}
    \ =\ 
    \overline{\left<x,T^*y\right>}
    \ =\ \left<T^*y,x\right>,
\end{equation*}
and see that~$T^*$ is adjoint to~$T$.
        Thus~$T^{**}=T$ by definition, \sref{parsec-40.80}.

\item
Given adjointable operators
$S,T\colon \scrH\to\scrK$ 
and~$x\in \scrH$ and $y\in \scrK$,
\begin{equation*}
\left<(S+T)x,y\right>
\ =\  \left<Sx,y\right>\,+\,\left<Tx,y\right>
\ =\ \left<x,S^*y\right>\,+\,\left<x,T^*y\right>
    \ =\ \left<x,(S^*+T^*)y\right>,
\end{equation*}
so~$S+T$ is adjoint to~$S^*+T^*$,
and thus~$(S+T)^*=S^*+T^*$.

Given an adjointable operator~$S\colon \scrH\to\scrK$,
$\lambda\in\C$, $x\in\scrH$, and~$y\in\scrK$,
\begin{equation*}
\left<\lambda Sx,y\right>
\ = \ 
    \overline{\lambda} \left<Sx, y\right>
\ = \ 
    \overline{\lambda} \left<x, S^*y\right>
\ = \ 
     \left<x, \overline{\lambda}S^*y\right>,
\end{equation*}
so~$\lambda S$ is adjoint to $\overline{\lambda}S^*$,
and thus $(\lambda S)^*=\overline{\lambda}S^*$.
\item
Given adjointable operators
$S\colon \scrK\to\scrL$
and $T\colon \scrH\to\scrK$,
and
$x\in\scrH$  and $y\in\scrL$,
we have
\begin{equation*}
\left<STx,y\right>
\ = \ \left<Tx,S^*y\right>
\ = \ \left<x,T^*S^*y\right>,
\end{equation*}
so~$ST$ is adjoint to~$T^*S^*$,
        and thus~$(ST)^*=T^*S^*$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-40.150}%
We'll check the first two requirements
    for $\|x\|=\smash{\sqrt{\left<x,x\right>}}$
    to give a seminorm first.
Given $x\in V$,
we have $\left<x,x\right>\geq 0$,
    so~$\|x\|\equiv \smash{\sqrt{\left<x,x\right>}}\geq 0$.
Given $x\in V$ and $\lambda\in \C$,
we have $\left\|\lambda x\right\|^2
    = \left<\lambda x,\lambda x\right> = \overline{\lambda}\left<x,x\right>
    \lambda = \left|\lambda\right|^2\|x\|^2\geq 0$,
    so
    we get~$\|\lambda x\| = \left|\lambda\right|\|x\|$
    by taking the square root.

Verifying that the triangle inequality holds takes some 
preparations.
As the hint suggests, we prove the Cauchy--Schwarz inequality first.
For this, we must given $x,y\in V$  prove
    that $\left|\left<x,y\right>\right|^2 \leq \left<x,x\right>
    \left<y,y\right>$.
This inequality follows
by applying~\sref{positive-2x2matrix} 
to the matrix
$\smash{\bigl(\begin{smallmatrix}
\smash{\left<x,x\right>} & \smash{\left<x,y\right>} \\
\smash{\left<y,x\right>} & \smash{\left<y,y\right>}
\end{smallmatrix}\bigr)}$,
which is positive,
as for all~$u,v\in\C$,
    \begin{alignat*}{3}
        (
        \begin{smallmatrix}
            \bar{u} & \bar{v}
        \end{smallmatrix})
        \ 
        \bigl(
        \begin{smallmatrix}
\smash{\left<x,x\right>} & \smash{\left<x,y\right>} \\
\smash{\left<y,x\right>} & \smash{\left<y,y\right>}
\end{smallmatrix}\bigr)
        \ \bigl(
        \begin{smallmatrix}
            u \\ v
        \end{smallmatrix}
        \bigr)
        \ &=\  
        \bar{u}u\left<x,x\right>\,+\,
        \bar{u}v\left<x,y\right> \,+\,
        u\bar{v}\left<y,x\right> \,+\,
        \bar{v}v\left<y,y\right> 
        \\
        &=\ \left<\,ux+vy,\,ux+vy\,\right>\,\geq \,0.
    \end{alignat*}
Upon taking the square root
the Cauchy--Schwarz inequality
takes the forms
    \begin{equation*}
    \left|\left<x,y\right>\right|
    \ \leq\  \|x\|\,\|y\|\qquad\text{for all }x,y\in V.
    \end{equation*}
Next, note that~$\bar{z}+z \leq 2\left|z\right|$ for any~$z\in\C$,
    because writing $z\equiv a+ib$,
    we have $\left|\bar{z}+z\right|^2=(\bar{z}+z)^2 = 4a^2 \leq 4(a^2 + b^2) = 4\left|z\right|^2$,
    and so $\bar{z}+z \leq \left|\bar{z}+z\right|\leq 2\left|z\right|$.
In particular, we have,
for all~$x,y\in V$,
\begin{equation*}
\left<x,y\right>+\left<y,x\right>
\ \leq\  2\left|\left<x,y\right>\right|\ \leq\ 
2 \|x\|\,\|y\|.
\end{equation*}
Given $x,y\in V$,
the triangle inequality,
$\|x+y\|\leq \|x\|+\|y\|$,
holds,
because
\begin{alignat*}{3}
    \|x+y\|^2\ &=\ 
    \left<x+y,x+y\right> 
    \ =\ \left<x,x\right>\,+\,
    \left<x,y\right>\,+\,
    \left<y,x\right>\,+\,
    \left<y,y\right> \\
    &\leq \ \left<x,x\right>\,+\,
    2\|x\|\,\|y\|
    \,+\,
    \left<y,y\right>  
    \quad\equiv\ 
    \|x\|^2 \,+\, 2\|x\|\,\|y\| \,+\, \|y\|^2\\
    \ &=\   (\|x\|+\|y\|)^2.
\end{alignat*}

Whence~$\|x\|=\smash{\sqrt{\left<x,x\right>}}$ gives
a seminorm on~$V$.
Recall that for~$\|\,\cdot\,\|$ to be a \emph{norm},
the additional condition
$\|x\|=0\implies x=0$
for all~$x\in V$
must be met.
This is the case when
$\left<\,\cdot\,,\,\cdot\,\right>$
is definite,
because 
$\|x\|=0$
entails $0=\|x\|^2=\left<x,x\right>$,
which, by definiteness of~$\left<\,\cdot\,,\,\cdot\,\right>$,
entails $x=0$.

Let~$x,y\in V$ be given.
To complete this exercise we must establish three
identities.
\emph{Pythagoras' theorem}
holds since $\left<x,y\right>=0$ implies
\begin{alignat*}{3}
\|x+y\|^2\ \equiv  \ \left<x+y,x+y\right>
    \ &=\ 
\left<x,x\right>
\,+\, \left<x,y\right>
\,+\, \left<y,x\right>
\,+\, \left<y,y\right>\\
    \ &=\  
\left<x,x\right>\,+\,\left<y,y\right>
\ = \ \|x\|^2 + \|y\|^2.
\end{alignat*}
Similar to the first line of the display above, we have,
(for any~$x,y\in V$,)
\begin{equation*}
\|x-y\|^2\ =\ 
\left<x,x\right>
\,-\, \left<x,y\right>
\,-\, \left<y,x\right>
\,+\, \left<y,y\right>.
\end{equation*}
Taking the average of these two equations gives the \emph{parallelogram law}:
\begin{equation*}
    \textstyle \frac{1}{2}(\ \|x+y\|^2\,+\,\|x-y\|^2\ )
    \ =\ 
\left<x,x\right>
\,+\, \left<y,y\right>\ \equiv\ 
\|x\|^2 + \|y\|^2.
\end{equation*}
Concerning the \emph{polarisation identity},
note that for any~$n$, we have
\begin{equation*}
i^n\left<i^nx+y,i^nx+y\right>
\ = \ i^n\left<x,x\right>
\,+\, \left<x,y\right>
    \,+\, (-1)^n\left<y,x\right>
    \,+\, i^n\left<y,y\right>.
\end{equation*}
Since~$\sum_{n=0}^3 i^n = 0$
and $\sum_{n=0}^3 (-1)^n=0$,
we get 
\begin{equation*}
    \textstyle
    \sum_{n=0}^3i^n\left\|i^nx+y\right\|^2
\ = \ 4\left<x,y\right>.
\end{equation*}
\end{solution}
\begin{solution}{parsec-40.180}%
Let~$\scrS \subseteq \scrB(\scrH)$
denote the set of bounded adjointable operators $\scrH\to\scrH$.
Since by Exercise~\sref{parsec-40.120},
a linear combination
of adjointable operators is again adjointable,
$\scrS$ is a linear subspace of~$\scrB(\scrH)$.

To show that~$\scrS$ is a closed subset of~$\scrB(\scrH)$,
we must prove that 
the limit~$T$ in $\scrB(\scrH)$
of
a
sequence  $T_1,T_2,\dotsc$
in~$\scrS$
is adjointable.

Note that the sequence $T_1^*,\,T_2^*,\,\dotsc$
is Cauchy, because,
by~\sref{parsec-40.160}, for all~$n,m$,
    \begin{equation*}
    \|T_n^*-T_m^*\|\ =\ \|(T_n-T_m)^*\|\ =\ \|T_n-T_m\|.
    \end{equation*}
Since~$\scrB(\scrH)$ is complete
by~\sref{parsec-40.50},
we may define $S:=\lim_n T_n^*$.
We claim that~$T$ is adjoint to~$S$.
Let~$x,y\in \scrH$ be given.
To prove our claim,
we must show that
that~$\left<Tx,y\right> = \left<x,Sy\right>$.

Note that $T_n^*y$ converges to~$Sy$ as~$n\to\infty$,
because~$\|T_n^*y-Sy\|\leq \|T_n^*-S\|\,\|x\|$
and $\|T_n^*-S\|$ vanishes as~$n$ increases
    by definition of~$S$.
As a result,
$\lim_n \left<x,T_n^*y\right> = \left<x,Sy\right>$.
Note that we use here
that the map $\left<x,\,\cdot\,\right>$,
being bounded by Cauchy--Schwarz
(\sref{parsec-40.150}),
is continuous.
On the other hand,
by a similar reasoning,
$\left<x,T_n^*y\right>
\equiv \left<T_nx,y\right>$
converges to~$\left<Tx,y\right>$ too
as~$n$ increases,
and so~$\left<x,Sy\right>=\left<Tx,y\right>$.
Whence~$T$ is adjoint to~$S$,
and thus~$\scrS$ is closed.
\end{solution}
\begin{solution}{parsec-40.190}%
That~$\ketbra{x}{y}\equiv \left<y,\,\cdot\,\right>x\colon \scrH\to\scrH$ 
is linear is pretty obvious.
    
    Since $\|\,\ketbra{x}{y}z\,\|
    = \|\left<y,z\right>x\|
    =\left|\left<y,z\right>\right|\,\|x\|
    \leq \|y\|\,\|z\|\,\|x\|$
    for all~$z\in\scrH$,
    we see that~$\ketbra{x}{y}$
    is bounded by~$\|y\|\,\|x\|$,
    and so~$\|\ketbra{x}{y}\|\leq \|x\|\,\|y\|$.
    For the other direction,
    note that $\|\ketbra{x}{y}\| \,\|y\|\geq 
    \|\ketbra{x}{y}y\|=\|\left<y,y\right>x\|
    = \|y\|^2\,\|x\|$,
    and so~$\|\ketbra{x}{y}\|\geq \|y\|\,\|x\|$.
    (Even when~$\|y\|=0$.)
    Whence $\|\ketbra{x}{y}\|=\|x\|\,\|y\|$.

Finally,  $\ketbra{x}{y}$
    is adjoint~$\ketbra{y}{x}$,
    because, for all~$w,z\in\scrH$,
    \begin{equation*}
        \left<\,\ketbra{x}{y}z,\, w\,\right>
        \ = \ 
        \left<z,y\right>\,\left<x,w\right>
        \ = \ 
        \left<\, z,\,(\ketbra{y}{x}w)\,\right>.
    \end{equation*}
\end{solution}
\begin{solution}{parsec-50.30}%
Let~$x$ be an element of~$\ell^2\backslash c_{00}$
    (so $x_n$ is non-zero for infinitely many~$n$s.)
We must show that there are no element of~$c_{00}$ with minimal
distance to~$x$.
So let~$y$ be an element of~$c_{00}$,
and suppose (towards a contradiction)
that~$\|x-y\|\leq \|x-y'\|$
for all~$y'\in c_{00}$.

Since~$y$ is in $c_{00}$,
there's~$N$ such that~$y_n=0$ for all~$n> N$.
We claim that~$x_n=y_n$ for all~$n\leq N$.
    Indeed, (if not) define $y'\in c_{00}$
    by $y_n' = x_n$ for all~$n\leq 0$, and~$y_n'=0$ for all~$n >N$.
    Then
\begin{alignat*}{3}
\textstyle
    \|x-y'\|^2\ &=\ 
\textstyle
    \sum_{n=N+1}^\infty \left|x_n\right|^2\\
    \ &\leq \ 
\textstyle
    \sum_{n=0}^N \left|x_n-y_n\right|^2 
    \ +\ \sum_{n=N+1}^\infty \left|x_n\right|^2
    \ = \ \|x-y\|^2.
\end{alignat*}
Thus~$\|x-y'\|\leq \|x-y\|$.
But since~$y$ is assumed to have minimal
distance to~$x$ among the elements of~$c_{00}$,
we already had $\|x-y\|\leq \|x-y'\|$,
and so~$\|x-y\|=\|x-y'\|$.
    Whence~$\sum_{n=0}^N \left|x_n-y_n\right|^2
    = 0$,
    and so~$x_n=y_n$ for all~$n\leq N$.
    In particular, $y=y'$.

It's now easy to find a better approximation
    of~$x$ in~$c_{00}$ than~$y$.
    Indeed, since~$x_n$ is non-zero for infinitely many~$n$s,
    there's an~$M\geq 0$ with 
    \begin{equation*}
        \textstyle
        \sum_{n=M+1}^\infty \left|x_n\right|^2
    \ <\  \sum_{n=N+1}^\infty \left|x_n\right|^2.
    \end{equation*}
    Writing $y''$ for the element of~$c_{00}$
    with $y_n''=x_n$ for all~$n\leq M$ and~$y_n''=0$
    for all~$n > M$,
    we have 
    $\|x-y''\|^2=\sum_{n=M+1}^\infty \left|x_n\right|^2
    < \sum_{n=N+1}^\infty \left|x_n\right|^2 = \|x-y'\|^2 = \|x-y\|^2$,
    which contradicts $\|x-y\|\leq \|x-y''\|$.
    Hence no such~$y$ exists.
\end{solution}
\begin{solution}{parsec-50.60}%
Surely, if $y$ is closest to~$x$
among all elements of~$C$,
it is among all elements of~$y\C\subseteq C$.
Whence~$y$ is a projection of~$x$ on~$y\C$.

We claim that~$\|y\|^2 = \left<x,y\right>$.  When~$y=0$
    this is obvious, so we may assume that~$y\neq 0$,
    so that we can define $e:= y\|y\|^{-1}$.
Since~$y$ is the projection of~$x$ on~$y\C\equiv e\C$,
we know by~\sref{parsec-50.40} that
$y=\left<e,x\right>e$,
and so $\|y\|^2 y = \left<y,x\right>y$.
Whence~$\|y\|^2 = \left<y,x\right>$.
Note that the claim implies that $\left<x-y,y\right>=0$:
\begin{equation*}
0\ =\ \|y\|^2-\left<x,y\right> \ =\  \left<y,y\right>-\left<x,y\right>
\ =\  \left<y,x-y\right>.
\end{equation*}
Let~$c\in C$ be given.
Note that when~$y_1$ is a projection of
    $x$ on~$C$, then~$y_1+c$ is a projection
of~$x+c$ on~$C$, because
    $\|(y_1+c)-(x+c)\|=\|y_1-x\|\leq \|(y'-c)-x\|\equiv \|y'-(x+c)\|$
    for all~$y'\in C$.

Let~$y_1$ and~$y_2$ be projections of~$x$ on~$C$;
we will show that~$y_1=y_2$.
By the previous paragraph,
$0\equiv y_1-y_1$ and~$y_2-y_1$ are projections of~$x-y_1$ on~$C$,
and thus on~$y_1\C$.
But since there's at most one projection of~$x-y_1$ on~$y_1\C$
    by~\sref{parsec-50.40} (even when~$y=0$),
    we get~$0=y_2-y_1$, and so~$y_1=y_2$.

Let~$y'\in C$ be given.
Recall that~$y$ is a (and thus the unique) projection of~$x$
on~$C$. It remains to be shown that
$\left<y',x-y\right>=0$.
Since~$y' \equiv y+y'-y$ is a projection
of $x':=x+y'-y$ on~$C$,
    we get 
\begin{equation*}
0\ =\ \left<y',x'-y'\right>\ \equiv \ 
    \left<y',(x+y'-y)-y'\right>\ \equiv\  \left<y',x-y\right>.
\end{equation*}
\end{solution}
\begin{solution}{parsec-50.110}%
Let~$T\colon \scrH\to\scrK$
be a bounded linear map between Hilbert spaces
$\scrH$ and~$\scrK$.
We'll show that~$T$ is adjointable.

Let~$y \in \scrK$ be given. 
    Then~$\left<y,T(\,\cdot\,)\right>\colon \scrH\to\C$
    is a linear map,
    bounded by $\|y\|\|T\|$,
    because $\left|\left<y,Tx\right>\right|\leq
    \|y\|\, \|Tx\|\leq \|y\|\,\|T\|\,\|x\|$
    for all~$x\in \scrH$.
Thus $\left<y,T(\,\cdot\,)\right>\equiv \left<Sy,\,\cdot\,\right>$
    for some unique $Sy\in \scrH$ by~\sref{parsec-50.90}.

The resulting map~$S\colon \scrK\to\scrH$
is linear, because
    \begin{alignat*}{3}
\left<S(y_1+\lambda y_2),\,\cdot\,\right>
        &=\  \left< y_1+\lambda y_2, T(\,\cdot\,)\right>
    \ =\  \left<y_1,T(\,\cdot\,)\right> + 
    \bar\lambda\left<y_2,T(\,\cdot\,)\right>\\
        \ &=\  \left<Sy_1,\,\cdot\,\right> + 
    \bar\lambda\left<Sy_2,\,\cdot\,\right>
    \ =\  \left<(Sy_1+\lambda Sy_2),\,\cdot\,\right>,
\end{alignat*}
for all $y_1,y_2\in\scrK$ and~$\lambda\in\C$.
Since $\left<Sy,x\right>=\left<y,Tx\right>$
for all~$x\in\scrH$ and~$y\in\scrK$,
 $S$ is adjoint to~$T$ (and~$T$ is adjoint to~$S$).

Finally, note that~$S$ is bounded by~$\|T\|$,
because
$\|Sy\|^2 = \left<Sy,Sy\right>
= \left<y,TSy\right>
\leq \|y\|\,\|T\|\,\|Sy\|$,
and so~$\|Sy\|\leq \|y\|\|T\|$,
for all~$y\in\scrK$.
\end{solution}
\begin{solution}{parsec-70.30}
Let~$a$ be an element of a $C^*$-algebra~$\scrA$.
\begin{enumerate}
    \item[1.]
$\Real{a}$ is self-adjoint, because
$(\Real{a})^*
        = \frac{1}{2}(a^{*}+a^{**}) = \frac{1}{2}(a^*+a) = \Real{a}$.
To see that~$\Imag{a}$ is self-adjoint, recall
        that $\bar{i}=-i$,
so
        $(\Imag{a})^*
        = -\frac{1}{2i}(a^*-a) 
        = \Imag{a}$.

The identity $a=\Real{a}+i\Imag{a}$
follows from
        $2(\Real{a}+i\Imag{a})
        = a+a^* \,+\, (a-a^*)
        = 2a$.
    \item[2.]
    Since $a^*=b^*+\bar{i}c^* =b-ic$,
        we have $2\Real{a}=a+a^* = b+ic\,+\,b-ic = 2b$,
        and $2i\Imag{a} = a-a^* = b+ic \,-\, (b-ic) = 2ic$,
        so~$\Real{a}=b$, and~$\Imag{a}=c$.

\item[3.]
Since $a^* = (\Real{a}+i\Imag{a})^*
        = \Real{a} - i\Imag{a}$ by point~1,
        we get $\Real{(a^*)}=\Real{a}$
        and $\Imag{(a^*)} = -\Imag{a}$ by point~2.

\item[4.]
Indeed,
$a$ is self-adjoint iff~$a=a^*$
        iff $a+a^*=2a$
        iff $\Real{a} \equiv \frac{1}{2}(a+a^*) = a$
        iff $a-a^* = 0$
        iff $\Imag{a}\equiv \frac{1}{2i}(a-a^*) = 0$.

\item[5.]
    $\Real{(\,\cdot\,)}$
        and $\Imag{(\,\cdot\,)}$
        are $\R$-linear,
        because~$(\,\cdot\,)^*$
        is $\R$-linear.

\item[6.]
    Apply point~2 to
    $ia = i(\Real{a}+i\Imag{a}) = \Imag{a}-i\Real{a}$.

\item[7.]
The element
$a^*a$ is self-adjoint,
        because $(a^*a)^*=a^*a^{**}=a^*a$.

Further,
        $a^*a = (\Real{a}-i\Imag{a})(\Real{a}+i\Imag{a})
        = \Real{a}^2 + \Imag{a}^2 + i(\Real{a}\Imag{a}-\Imag{a}\Real{a})$.

\item[8.]
It suffices to find self-adjoint elements~$b$ and~$c$
of some~$C^*$-algebra~$\scrA$ with~$bc\neq cb$,
because then~$a:= b+ic$ will do the job.

Given any linearly independent vectors
$x$ and~$y$
from some Hilbert space~$\scrH$
with $\left<x,y\right>\neq 0$.
define~$b:=\ketbra{x}{x}$ and $c:=\ketbra{y}{y}$.
Then~$bc = \ketbra{x}{y}\,\left<x,y\right> $
and~$cb=\ketbra{y}{x}\,\left<y,x\right>$.
So if~$bc=cb$,
then~$\left|\left<x,y\right>\right|^2x = bcx
= cbx = \left<y,x\right>\|x\|^2y$,
contradicting the linear independence of~$x$ and~$y$.

\item[9.]
Combine point~3 and point~7.

\item[10.]
Indeed, $bc$ is self-adjoint
iff~$bc=(bc)^*\equiv c^*b^*\equiv cb$.

So~$x$ and~$y$ are non-orthogonal linearly independent vectors
of a Hilbert space~$\scrH$ as in point~8,
then~$\ketbra{x}{x}\ketbra{y}{y}\equiv \left<x,y\right>\,\ketbra{x}{y}$
is not self-adjoint.

\item[11.]
Surely, if~$a=0$,
then~$a^*=0$, and so~$\|a\|=0=\|a^*\|$.
So we may assume that~$a\neq 0$
(and so~$a^*\neq 0$).
Then, since~$\|a\|^2=\|a^*a\|\leq \|a^*\|\,\|a\|$,
we have $\|a\|\leq \|a^*\|$.
Since similarly $\|a^*\|\leq \|a\|$,
we get~$\|a\|=\|a^*\|$.

\item[12.]
Note that
$\|\Real{a}\|\leq
\frac{1}{2}\|a\|+\frac{1}{2}\|a^*\|
= \|a\|$
and $\|\Imag{a}\|\leq
\frac{1}{2}\|a\| + \frac{1}{2}\|a^*\|
= \|a\|$
by the triangle inequality and $\|a^*\|=\|a\|$.

\item[13.]
When~$a$ is self-adjoint,
$\|a^2\| = \|a^*a\| = \|a\|^2$.

Let~$x$ and~$y$ be non-zero orthogonal vectors
from some Hilbert space~$\scrH$.
Then~$\ketbra{x}{y}^2 = 0$, and so~$\|\ketbra{x}{y}^2\|=0$,
while $\|\ketbra{x}{y}\|^2 = \|x\|^2\|y\|^2$
(see~\sref{parsec-40.190}) is non-zero.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-80.20}
For the sake of clarity,
we'll denote the zero and unit of a $C^*$-algebra~$\scrA$
in this exercise
by~$0_\scrA$ and~$1_\scrA$, respectively.
\begin{enumerate}
\item
Since~$0_\scrA=1_\scrA$ when~$\scrA=\{0_\scrA\}$,
then also $0_\C=\|0_\scrA\|=\|1_\scrA\|$.
\item
We claim that~$\|1_\scrA\|\leq 1_\C$.
Indeed, since $\|1_\scrA\|=\|1_\scrA^*1_\scrA\|=\|1_\scrA\|^2$,
we either have $\|1_\scrA\|=1_\C$
        or $\|1_\scrA\|=0_\C$.
        In either case, $\|1_\scrA\|\leq 1_\C$.

Thus $\|\lambda 1_\scrA\| = \left|\lambda\right|\|1_\scrA\|\leq
        \left|\lambda\right|$, in~$\C$.
\item
Since $\|\lambda 1_\scrA\|1_\scrA
= \left|\lambda\right| \,\|1_\scrA\|\, 1_\scrA$,
it suffices to show that $\|1_\scrA\|\, 1_\scrA = 1_\scrA$,
        that is, that $\left| 1_\C-\|1_\scrA\|\right|\,\|1_\scrA\| =0$.
But as we already saw that~$\|1_\scrA\|$
is equal to either~$1_\C$ or~$0_\C$,
this is indeed the case.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-90.20}
Showing that the first three points are equivalent is not too difficult.
$\text{1.}\implies\text{2.}$:
    If~$f(x)\geq 0$ for all~$x\in X$,
    then~$g\colon X\to\C$ given by~$g(x)=\sqrt{f(x)}$
    for all~$x\in X$ is continuous,
    and~$g^2=f$.
$\text{2.}\implies\text{3.}$:
is obvious.
$\text{3.}\implies\text{1.}$:
If~$f\equiv g^*g$ for some~$g\in C(X)$,
    then~$f(x)=\smash{\overline{g(x)}}g(x)=\left|g(x)\right|^2\geq 0$
    for all~$x\in X$.
Of course,
$\text{5.}\implies \text{4.}$ is obvious.
For the remainder,
note that given~$t\in \R$ we have
    $\|f-t\|\equiv \sup\{\left|f(x)-t\right|\colon x\in X\}\leq t$
    iff $\left|f(x)-t\right|\leq t$ for all~$x\in X$
    iff $-t\leq f(x)-t \leq t $ for all~$x\in X$
    iff $0\leq f(x)\leq 2t$ for all~$x\in X$
    iff $0\leq f\leq 2t$
    iff $0\leq f$ and~$\frac{1}{2}\|f\|\leq t$.
Hence $\text{4.}\implies\text{1.}\implies\text{5.}$.
\end{solution}
\begin{solution}{parsec-90.30}
Since only~$0$ is not invertible in~$\C$,
    we see that an element $f$ of $C(X)$
    is invertible (with inverse given by~$f^{-1}(x)=f(x)^{-1}$ 
    for all~$x\in X$) precisely when~$f(x)\neq 0$ for all~$x\in X$,
    that is, when $0\notin f(X)$.
In particular,
    $f-\lambda $ is \emph{not} invertible
    iff $0\in (f-\lambda)(X)$
    iff $f(x)=\lambda$ for some~$x\in X$
    iff $\lambda \in f(X)$.
\end{solution}
\begin{solution}{parsec-90.90}
Given an element~$a$ of a $C^*$-algebra,
we have that
    $a$ is an effect iff $0\leq a\leq 1$
    iff both $a$ and~$a^\perp \equiv 1-a$ 
    are positive (using the definition of~$\leq$ here)
    iff both $a^{\perp\perp}\equiv a$ and~$a^\perp$ are positive
    iff $0\leq a^\perp\leq 1$
    iff $a^\perp$ is an effect.
\end{solution}
\begin{solution}{parsec-90.100}
\begin{enumerate}
\item[1.]
$0$ is positive, because~$0^*=0$ and~$\|0-0\|\leq 0$.

That~$a+b\in\scrA_+$ when~$a,b\in\scrA_+$
was proven in~\sref{parsec-90.70}.

To show that~$\lambda a$ is positive
for~$a\in\scrA_+$ and~$\lambda\in[0,\infty)$,
pick~$t\in \R$ with~$\|a-t\|\leq t $.
Then~$\lambda a$ is self-adjoint,
        and~$\|\lambda a -\lambda t\| = \lambda \|a-t\|\leq  \lambda t$,
so~$\lambda a$ is positive.

Since~$0$ is positive,
we have $a\leq a$ for all~$a\in\scrA$.
Further, when~$a\leq b\leq c$ for some~$a,b,c\in\scrA$,
then~$b-a$ and~$c-b$ are positive,
so~$c-a\equiv (c-b)+(b-a)$
    is positive,
        that is~$a\leq c$.
Hence~$\leq$ is a preorder, on~$\scrA$.

\item[2.]
The unit, $1$, is self-adjoint since
$1^*=1^*1 = (1^*1)^* = (1^*)^*=1$,
and positive, because $\|1-1\|\leq 1$.

Given self-adjoint $a$ in~$\scrA$,
$\|a\|+a$ and~$\|a\|-a$ are self-adjoint,
and positive,
because~$\|\,(a+\|a\|)\,-\,\|a\|\,\|\leq\|a\|$
        and $\|\,(\|a\|-a)\,-\,\|a\|\,\|\leq \|a\|$.
    Hence~$-\|a\|\leq a \leq \|a\|$
        for self-adjoint~$a\in\scrA$.

\item[3.]
Let~$x$ and~$y$ be non-orthogonal linearly independent
vectors of a Hilbert space~$\scrH$.
        Then~$\ketbra{x}{x}$ and~$\ketbra{y}{y}$ are self-adjoint.

To see that~$\ketbra{x}{x}$ is positive,
note that~$\ketbra{x}{x}^2 = \ketbra{x}{x}\|x\|^2$,
and   
\begin{alignat*}{3}
    \|\,\ketbra{x}{x}\,-\,\|x\|^2\,\|^2
        &=\  \|\,\ketbra{x}{x}^2 
        \,-\, 2\|x\|^2\ketbra{x}{x}\,+\,\|x\|^4\,\|\\
        \ &=\  \|x\|^2 \ \|\,\ketbra{x}{x}-\|x\|^2\,\|,
\end{alignat*}
        so $\|\,\ketbra{x}{x}-\|x\|^2\,\| \leq \|x\|^2$,
        and hence~$\ketbra{x}{x}$ is positive.

Similarly, $\ketbra{y}{y}$ is positive,
but their product
$\ketbra{x}{x}\,\ketbra{y}{y} 
\equiv \ketbra{x}{y}\,\left<x,y \right>$
isn't even self-adjoint,
        as we saw in 
        the solution to~\sref{parsec-70.30}(10).
\item[4.]
Note that~$\|a\|_o\leq \|a\|$, because
we saw that $-\|a\|\leq a \leq \|a\|$ in point~2.
In particular, $\|a\|_o < \infty$.
Also, clearly, $\|a\|_o\geq 0$ for all~$a\in\Real\scrA$.

Note that~$\|a\|_o = \|-a\|_o$
for all~$a\in\Real\scrA$,
because $-\lambda \leq a\leq \lambda$
iff $\lambda\geq -a \geq -\lambda$
for all~$\lambda\in[0,\infty)$.

Let~$\mu\in\R$ and~$a\in\scrA$ be given;
we want to show that $\|\mu a \|_o = \left|\mu\right|\|a\|_o$.
Since this identity holds when~$\mu=0$,
we may assume that~$\mu\neq 0$.
Suppose for now that~$\mu>0$;
we'll deal with the case that~$\mu<0$ in a moment.
Note that for~$\lambda\in [0,\infty)$,
with $-\lambda \leq \mu a \leq \lambda$
we have~$-\smash{\frac{\lambda}{\mu}}\leq a \leq \smash{\frac{\lambda}{\mu}} $,
so~$\|a\|_o\leq \smash{\frac{\lambda}{\mu}}$,
that is~$\mu \|a\|_o \leq \lambda$.
Taking the infimum, we get~$\mu \|a\|_o\leq \|\mu a\|_o$.
For the other direction,
replace~$\mu$ and $a$ by $\mu^{-1}$ and~$\mu a$,
to get $\mu^{-1} \|\mu a\|_o \leq \|\mu^{-1} \mu a\|_o$,
and so~$\|\mu a\|_o \leq \mu \|a\|_o$.
Thus~$\|\mu a\|_o = \mu\|a\|_o$,
for~$\mu>0$.
In the other case, $\mu<0$,
we have~$-\mu=\left|\mu\right| >0$, 
and so $\|\mu a\|_o = \|-(-\mu)a\|_o
= -\mu \|a\|_o = \left|\mu\right|\|a\|_o$.

Let~$a$ and~$b$ be self-adjoint elements of~$\scrA$.
To show that~$\|\,\cdot\,\|_o$ is a seminorm,
it remains to be shown that
$\|a+b\|_o\leq \|a\|_o+\|b\|_o$.
Given~$\lambda,\mu\in [0,\infty)$
with $-\lambda \leq a\leq \lambda$
and $-\mu \leq b\leq \mu$,
we have $-(\lambda+\mu)\leq a+b\leq \lambda+\mu$,
and so~$\|a+b\|_o\leq \lambda+\mu$.
Taking the infimum over all such~$\lambda$ and~$\mu$,
we get $\|a+b\|_o\leq \|a\|_o + \|b\|_o$.

\item[5.]
Please contact me if you've found a short and elementary proof for any of these
five problems.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-110.60}
\begin{enumerate}
\item[1.]
Since~$\|a\|<\left|\lambda\right|$,
we have $\| \, a\lambda^{-1}\,\|
= \left|\lambda\right|^{-1}\|a\| <1$.
Thus by~\sref{parsec-110.20},
$1-a\lambda^{-1}$ is invertible.
But then~$\lambda-a \equiv \lambda (1-a\lambda^{-1})$
is invertible too.
\item[2.]
(There is an erratum to the printed
        version of this exercise.)

Since~$a-b = b(1-ab^{-1})$
it suffices to show
        that~$1-ab^{-1}$ is invertible.
    Indeed it is, by~\sref{parsec-110.20},
        because $\|ab^{-1}\|\leq \|a\|\,\|b^{-1}\| < 
        \|b^{-1}\|^{-1}\,\|b^{-1}\| = 1$.

\item[3.]
Let~$b\in U$ be given.
To show that~$U$ is open,
we must find~$\varepsilon>0$
with $a\in U$ for all~$a\in\scrA$ with $\|a-b\|\leq \varepsilon$.

Take~$\varepsilon:= \|b^{-1}\|^{-1}$. 
By the previous point,
        $a\equiv (a-b)-(-b)$
        is invertible
        provided that~$\|a-b\|\leq \varepsilon \equiv \|(-b)^{-1}\|^{-1}$,
        because~$-b$ is invertible.
\end{enumerate}
\end{solution}

\begin{solution}{parsec-110.150}
\begin{enumerate}
\item
Since~$\lambda \in \C\backslash \R$,
        we have~$\Imag{\lambda}\neq 0$.
        Then~$\smash{\frac{a-\lambda}{\Imag{\lambda}}}
        = \smash{\frac{a-\Real{\lambda}}{\Imag{\lambda}}}-i$
        is invertible by~\sref{parsec-110.130},
        since $\smash{\frac{a-\Real{\lambda}}{\Imag{\lambda}}}$
        is self-adjoint.
        Upon multiplication with~$\Imag{\lambda}$
        we
        see that~$a-\lambda$ is invertible too.

    \item
We already know that~$a^2-\lambda$ is invertible
for all~$\lambda \in\C\backslash\R$,
so the only thing that remains to be shown is that
$a^2+\lambda$ is invertible
        for $\lambda \in (0,\infty)$.
For this,
        note that since~$a-\sqrt{\lambda}i$ and~$a+\sqrt{\lambda}i$
        are invertible by point~2,
        so is their product $(a-\sqrt{\lambda}i)(a+\sqrt{\lambda}i)
        = a^2+\lambda$.
\item
We already know that~$a^n-\lambda$
is invertible for all~$\lambda\in \C\backslash \R$,
by point~1, so we only need to show
that~$a^n+\lambda$ is invertible for all~$\lambda>0$
iff $a+\lambda$ is invertible for all~$\lambda>0$.
In fact, we'll show that for any~$\lambda>0$ 
the element~$a+\lambda$ is invertible
        iff~$a^n+\lambda^n$ is invertible.
    Since~$a+\lambda = \lambda(\lambda^{-1}a+1)$
    and $a^n+\lambda^n = \lambda^n((\lambda^{-1}a)^n + 1)$,
    it suffices to show that
    $b+1$ is invertible iff $b^n+1$ is invertible, where~$b:=\lambda^{-1}a$.

    Since~$\zeta^2, \zeta^4,\zeta^6,\dotsc,\zeta^{2n}$
are the $n$ roots
of the polynomial~$x^n-1$,
        we have $x^n-1 = \prod_{k=1}^n (x-\zeta^{2k})$.
Substituting~$\zeta^{-1} b$ for~$x$,
and
multiplication by~$-1\equiv \zeta^n$ gives
\begin{equation}
\label{eq:11XV3}
b^n+1 \ =\  \zeta^n(\zeta^{-1}b)^n - \zeta^n
        \ =\  \prod_{k=1}^n b-\zeta^{2k+1}.
\end{equation}
Note that~$\zeta^{2k+1}\notin \R$ when~$k\neq \frac{1}{2}(n-1)$,
and so~$b-\zeta^{2k+1}$
is invertible for such~$k$, by point~1
of this exercise.

Thus in light of~\eqref{eq:11XV3},
$b^n+1$ is invertible
iff $b-\zeta^n\equiv b+1$ is invertible.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-110.180}
Let~$a$ be an element of a $C^*$-sublalgebra~$\scrA$
of a $C^*$-algebra~$\scrB$,
    and assume~$a$ has an inverse~$a^{-1}$ in~$\scrB$.
    We must show that~$a^{-1}\in\scrA$.

Note that~$a^*a$ is invertible in~$\scrB$
    with inverse~$a^{-1} (a^{-1})^*$.
This inverse
$(a^*a)^{-1}$ is in the subalgebra~$\scrA$
by~\sref{parsec-110.160},
because~$a^*a$ is self-adjoint.
    Thus~$(a^*a)^{-1}a^*\equiv a^{-1} (a^{-1})^* a^*
    \equiv a^{-1} (aa^{-1})^* = a^{-1}$
    is in the subalgebra~$\scrA$ as well.
\end{solution}
\begin{solution}{parsec-110.200}
\begin{enumerate}
    \item
Given~$\lambda\in\C$, we have
        $\lambda \in \spec(f)$
        iff $f-\lambda$ is not invertible
        iff~$\lambda \in f(X)$,
using~\sref{parsec-90.30} in the last step.
        Thus~$\spec(f)=f(X)$.
    \item
        A square matrix is invertible iff its kernel is not~$\{0\}$.
In particilar, $A-\lambda$
        is not invertible iff $(A-\lambda)v=0$
        for some non-zero vector~$v\in \C^n$.
In that case, we have $Av=\lambda v$, and so~$\lambda$
is an eigenvalue for~$A$.  Conversely,
for any eigenvalue~$\lambda$ of~$A$
the kernel of~$A-\lambda$ will consist
of the associated eigenvectors, and so~$A-\lambda$ will not be invertible.
Hence the spectrum of~$A$ 
is the set of eigenvalues of~$A$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-110.210}
\begin{enumerate}
\item[1.]
That~$\spec(a)\subseteq \R$ for self-adjoint~$a$
follows from \sref{parsec-110.150}(1).

        To see that  $ \spec(\,\smash{\bigl(\begin{smallmatrix} 0 & 2 \\ 0 & 0
        \end{smallmatrix}\bigr)}\,)=\{0\}$
we must show that~$0$ is the only eigenvalue of
        $ \smash{\bigl(\begin{smallmatrix} 0 & 2 \\ 0 & 0
        \end{smallmatrix}\bigr)}$,
that is,
that~$0$ is the only root of the characteristic polynomial
        $\det(
        \smash{\bigl(\begin{smallmatrix} 0 & 2 \\ 0 & 0
        \end{smallmatrix}\bigr)}
        -\lambda ) = \lambda^2$,
        which is so.
\item[2.]
This follows immediately from \sref{parsec-110.150}(2).
\item[3.]
This follows directly from~\sref{parsec-110.60}(1).
\item[4.]
Let~$\lambda_1,\lambda_2,\dotsc$
        be a sequence in~$\spec(a)$
        that converges to some~$\lambda\in \C$;
        we must show that~$\lambda\in\spec(a)$.
Note that since the set of invertible elements of~$\scrA$
        is open by~\sref{parsec-110.60}(3),
        the set of non-invertible elements of~$\scrA$
        is closed.
Thus, as the $a-\lambda_1,\,a-\lambda_2,\,\dotsc$
are all non-invertible,
and converge to~$a-\lambda$,
this element~$a-\lambda$ is non-invertible as well.
        Hence~$\lambda\in\spec(a)$.

Thus, $\spec(a)$, being a closed and bounded subset of~$\C$,
is compact.
\item[5.]
Given $\lambda\in\C$
        we have $\lambda\in \spec(a)$
        iff $a-\lambda\equiv a+z-(\lambda+z)$ is not invertible
        iff $\lambda+z\in \spec(a+z)$.
        Thus $\spec(a)+z = \spec(a+z)$.
\item[6.]
Let~$\lambda\in \C$ be given.
    Since~$\lambda-a = \lambda a (a^{-1}-\lambda^{-1})$,
    we see that~$\lambda-a$ is invertible
    iff $a^{-1} - \lambda^{-1}$ is invertible.
        Hence~$\spec(a^{-1})=\spec(a)^{-1}$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-120.30}
\begin{enumerate}
\item[1.]
Let~$U:= \dom(f)\equiv\dom(g)$.
Given~$x\in U$ the expression
        \begin{equation*}
            \frac{(f+g)(x)-(f+g)(y)}{x-y}
            \ =\  \frac{f(x)-f(y)}{x-y}
            \ +\ \frac{g(x)-g(y)}{x-y}
        \end{equation*}
        converges to~$f'(x)+g'(x)$ as $y\in U\backslash\{x\}$
        tends to~$x$.  
Thus $f+g$ is holomorphic, and $(f+g)'=f'+g'$.

Given~$x\in U$ the expression
\begin{equation*}
            \frac{(f\cdot g)(x)-(f\cdot g)(y)}{x-y}
            \ =\  \frac{f(x)-f(y)}{x-y}\cdot g(x)
            \ +\ f(y)\cdot \frac{g(x)-g(y) }{x-y}
\end{equation*}
converges to $f'(x)g(x)+f(x)g'(x)$ as $y\in U\backslash\{x\}$
tends to~$x$. Hence~$f\cdot g$ is holomorphic, 
        and $(f\cdot g)' = f'g + fg'$.

\item[2.]
Since for all $x,y\in\C$ with $x\neq y$, 
        we have
\begin{equation*}
\frac{f(x)-f(y)}{x-y} \ = \ 
    \frac{x-y}{x-y} \ = \ 1,
\end{equation*}
$f$ is holomorphic, and $f'(x)=1$ for all~$x\in \C$.

\item[3.]
    Since we have, for all $x,y\in U$ with $x\neq y$,
\begin{equation*}
\frac{f(x)-f(y)}{x-y} \ = \ 
    \frac{a-a}{x-y} \ = \ 0,
\end{equation*}
$f$ is holomorphic, and $f'=0$.

\item[4.]
That~$f$ is holomorphic follows from the previous three points.

The only thing that's not immediately clear
about the expression for~$f'$
is that $(\chi^{n+1})'=(n+1)\chi^n$,
where $\chi$ denotes the holomorphic
function with~$\dom(\chi)=\C$
given by~$\chi(z)=z$ for all~$z\in \C$.

This is, however, easily proven with induction as follows.
The case~$n=0$ follows from point~2.
Further, if~$(\chi^{n+1})'=(n+1)\chi^n$
        for some~$n$,
        then we have~$(\chi^{n+2})'
        = (\chi^{n+1}\cdot\chi)'
        = (\chi^{n+1})'\cdot \chi + \chi^{n+1}\cdot\chi'
        = (n+1)\chi^n\cdot \chi + \chi^{n+1}\cdot 1
        = (n+2)\chi^{n+1}$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-130.60}
Let~$f$ denote the holomorphic
    function on the disk $\dom(f)=\{z\in \C\colon \left|z\right|<R\}$
    given by the power series $\sum_n a_n z^n$.
Let~$r>0$ be the radius of a disk around~$0$ on  which~$f$ is zero,
    so~$f(z)=0$ for all~$z\in \C$ with $\left|z\right|<r$.
Then~$f'(z)=0$ for all~$z\in \C$ with~$\left|z\right|<r$,
    (because~$f'$ is zero on an open neighbourhood around~$z$.)
In particular~$f'(0)=0$.
On the other hand,
    since~$f'(z)=\sum_{n=1}^\infty
    n a_{n} z^{n-1}$ for all~$z\in \C$
by~\sref{parsec-130.40},
    we get~$f'(0)=a_1$.
    Thus~$a_1=0$.

Writing $f^{n\prime }$ for the $n$-th derivative of~$f$,
we get by induction 
that $f^{n \prime }(z)=0$ for all~$z\in \C$
    with $\left|z\right|< r$,
    and~$0=f^{n\prime }(0)=na_n$, for all~$n$.

    Thus~$0=a_0=a_1=a_2=\dotsb$,
    and so~$f=0$.
\end{solution}
\begin{solution}{parsec-140.20}
\begin{enumerate}
    \item[1.]
Following the hint
it suffices to show that
we have
$\sum_n a_n\left|I_n\right| = 0$
for any intervals~$I_1,\dotsc,I_N$ 
and~$a_1,\dotsc,a_N\in \scrA$
with $\sum_n a_n \mathbf{1}_{I_n}=0$.

Note that when an interval $I$ is the disjoint
union of two intervals $I'$ and~$I''$,
        we have both
        $\mathbf{1}_{I} = \mathbf{1}_{I'} + \mathbf{1}_{I''}$,
        and $\left|I\right| = \left|I'\right|+\left|I''\right|$.

It's therefore possible
by splitting the intervals~$I_1,\dotsc,I_N$ as needed,
        to find intervals~$I_1',\dotsc,I_M'$
    and~$a_1',\dotsc,a_M'\in\scrA$
with~$\sum_n a_n \mathbf{1}_{I_n}
= \sum_n a_n' \mathbf{1}_{I_n'}$
and~$\sum_n a_n\left|I_n\right|
= \sum_n a_n'\left|I_n'\right|$,
and the property
that if~$I_n'\cap I_m'\neq \varnothing$,
then~$I_n'=I_m'$.
    Furthermore, by aggregating the~$a_n'$'s of intersecting (and thus equal)
    intervals, we can get  $I_n'\cap I_m'\neq \varnothing$
        to imply that~$n=m$.

We can also arrange the~$I_m'$ to be non-empty, by discarding
        the empty $I_m'$'s (which
        doesn't affect the values of  $\sum_n a_n'\mathbf{1}_{I_n'}$
        and $\sum_n a_n'\left|I_n'\right|$.)

Let~$m$ be given,
        and pick some~$x\in I_m'$.
Since~$I_m'$ intersects none of the intervals $I_1',\dotsc,I_M'$
except itself, we have
\begin{equation*}
    \textstyle
    0\ \equiv\  (\sum_n a_n \mathbf{1}_{I_n})(x)
        \ \equiv\ 
        (\sum_n a_n' \mathbf{1}_{I_n'})(x) \ =\  a_m'.
\end{equation*}
Hence~$a_m'=0$ for all~$m$,
and so~$\sum_n a_n \left|I_n\right|
 = \sum_n a_n' \left|I_n'\right| = 0$.
\item[2.]
We already showed in point~1 that any step function~$f$
        may be written as 
        $f=\sum_n a_n \mathbf{1}_{I_n}$,
        using disjoint and non-empty intervals 
$I_1,\dotsc,I_N$, and~$a_1,\dotsc, a_N\in\scrA$.

We'll show that~$\|f\|=\sup_n\|a_n\|$.
Let~$x\in [0,1]$ be given.
Since the~$I_n$ are disjoint,
        either $f(x)=0$,
        or $f(x)=a_n$ for some~$n$.
In either case, $\|f(x)\|\leq \sup_n \|a_n\|$,
so that~$\|f\|=\sup_{x\in [0,1]}\|f(x)\|\leq \sup_n\|a_n\|$.
On the other hand,
since each~$I_n$ is non-empty,
$f(x)=a_n$ for some~$x$,
and so~$\|a_n\|\leq \|f\|$ for all~$n$,
Hence~$\|f\|=\sup_n \|a_n\|$.

That~$\sum_n\left|I_n\right| \leq 1$ is rather obvious,
but useful in
\begin{equation*}
    \textstyle
    \|\int f \|
\ \equiv\  \|\sum_n a_n \left|I_n\right| \|
\ \leq\  \sum_n \|a_n\| \left|I_n\right|
\ \leq\  \|f\| \sum_n \left|I_n\right|
\ \leq\  \|f\|,
\end{equation*}
to show that the linear operator~$\int\colon S_\scrA\to \scrA$
is bounded by~$1$.

Let~$g\in \overline{S}_\scrA$ be given,
and let
$f_1,f_2,\dotsc$ be a sequence in~$S_\scrA$ converging
to~$g$.
Then since~$\|\int (f_n-f_m)\|\leq \|f_n-f_m\|$
for all~$n$ and~$m$,
the sequence~$\int f_1, \,\int f_2,\dotsc$
is Cauchy,
and therefore convergent.
If~$f_1',f_2',\dotsc$ is a sequence in~$S_\scrA$
that converges to~$g$ too,
then the differences $f_1-f_1',\ f_2-f_2',\ \dotsc$
converge to~$0$,
so $\int f_1 - \int f_1',\ \int f_2-\int f_2',\ \dotsc$
converges to~$\int 0 = 0$.
Since that sequence also converges to
$\lim_n \int f_n - \lim_n \int f_n'$,
we
get~$\lim_n \int f_n = \lim_n \int f_n'$.

We may thus define a map $\int\colon \overline{S}_\scrA \to\scrA$
by setting~$\int g = \lim_n \int f_n$
for any sequence~$f_1,f_2,\dotsc $ in~$S_\scrA$
that converges to~$g$.

It's not hard to see that~$\int$ is linear
using the facts that addition and scalar multiplication
are continuous on~$S_\scrA$ and~$\scrA$.

To see that the map~$\int\colon \overline{S}_\scrA\to\scrA$
is bounded,
let $g\in\overline{S}_\scrA$ be given,
and let~$f_1,f_2,\dotsc$ be a sequence in~$S_\scrA$
that converges to~$g$.
Since~$f_1,f_2,\dotsc$ converges to~$g$,
we have~$\lim_n \|f_n\| = \|g\|$.
We already know that~$\| \int f_n \| \leq \|f_n\|$.
Taking the limit on both sides, we get
$\|\int g\| \equiv \lim_n \|\int f_n\| = \lim_n \|f_n\| \equiv
\|g\|$,
and so~$\int$ is bounded.

That~$\int\colon \overline{S}_\scrA\to \scrA$
is the only bounded linear extension of~$\int\colon S_\scrA\to\scrA$
is rather obvious.

\item[3.]
Let~$g\colon [0,1]\to\scrA$
be a continuous map,
and let~$\varepsilon>0$ be given.
We must find a step function~$f\in S_\scrA$
with $\|f-g\|\leq \varepsilon$.
Since~$g$ is continuous,
there is
for each~$x\in [0,1]$
a $\delta_x>0$
such that $\|g(x)-g(y)\|\leq \varepsilon$
for all~$y\in I_x:=(x-\delta_x,x+\delta_x)\cap[0,1]$.
Since these in-$[0,1]$-open interval~$I_x$
cover the compact set~$[0,1]$,
there are~$x_1,\dotsc,x_N\in [0,1]$
with~$I_{x_1}\cup \dotsb\cup I_{x_N} = [0,1]$.
Pick disjoint intervals~$J_1,\dotsc,J_N$
with $J_n\subseteq I_{x_n}$ for all~$n$,
and~$J_1\cup \dotsb\cup J_N=[0,1]$,
and define $f:= \sum_n g(x_n) \mathbf{1}_{J_n}$.

We claim that~$\|f-g\|\leq \varepsilon$.
To proof this, let~$x\in [0,1]$ be given.
There's exactly one~$n$ with~$x\in J_n$,
and so~$f(x) = g(x_n)$.
Thus $\|g(x)-f(x)\|= \|g(x)-g(x_n)\|\leq \varepsilon$
since~$x\in J_n\subseteq I_{x_n}$.
Hence~$\|f-g\|\leq \varepsilon$.

\item[4.]
Let~$a\in\scrA$ be given.
We must show that
$\int af = a\int f$
for all continuous $f\colon [0,1]\to \C$.
Since such~$f$ can be written as the limit
of linear combinations
of indicator functions,
we may assume without loss of generality
that $f=\mathbf{1}_I$ for some interval~$I$.
Now,
$\int a \mathbf{1}_I = a \left|I\right|
= a \int \mathbf{1}_I$.
\end{enumerate}

\end{solution}
\begin{solution}{parsec-140.80}
    \begin{enumerate}
    \item
   Since~$\bar{z}z=\left|z\right|^2$,
            we have $z (\bar{z} \left|z\right|^{-2})=1$,
            and so~$z^{-1} = \bar{z} (\left|z\right|^2)^{-1}$.
This yields the required identity since
            $\bar{z}=\Real{z}-i\Imag{z}$
            and $\left|z\right|^2 = \Real{z}^2+ \Imag{z}^2$.
    \item
        To the first computation
            I've got nothing to add,
            except $$\textstyle \frac{1}{2}\log(a^2+b^2)
            \ =\  \smash{\log(\sqrt{a^2+b^2})} \ =\  
            \log\left|a+ib\right|.$$
    Concerning the second integral:
            \begin{alignat*}{3}
                \int_{a+ib}^{ib} z^{-1} \,dz 
                \ &=\ \int_a^0
                \frac{t-ib}{t^2+b^2}\,dt \\
                \ &=\ 
                \int_a^0
                \frac{-ib}{t^2+b^2}\,dt 
                \ +\ 
                \int_a^0
                \frac{t}{t^2+b^2}\,dt 
                \\
                \ &=\  i\arctan(\,b/a\,)
                \ + \  \log\left|b\right|
                \ + \ \log\left|a+ib\right|.
            \end{alignat*}
\item
The problem is easily reduced to the case that~$z_0=0$.
In other words,
we must show that
\begin{equation}
    \label{eq:14VIII}
    \int_w^{w'} z^{-1}
    \,dz \ =\ i\measuredangle(w,0,w')\ +\ \log\frac{\left|w'\right|}{\left|w\right|}.
\end{equation}
            Suppose that~$\Imag{w}=\Imag{w'}=:b$
            then the equation above
            follows easily
            from the expression for $
                \int_{a+ib}^{ib} z^{-1} \,dz $ computed above,
                because
                $$\int_w^{w'}
                z^{-1}\,dz\ = \ 
                \int_{\Real{w}+ib}^{ib} z^{-1}\,dz\ - \ 
                \int_{\Real{w'}+ib}^{ib} z^{-1}\,dz
                \ = \ \dotsb
                \ =\  i\measuredangle(w,0,w')
                \ + \ \log\frac{\left|w'\right|}{\left|w\right|},$$
            using here that
            $\arctan(\,\Real{w}/\Imag{w}\,)
            = 2\pi - \arctan(\,\Imag{w}/\Real{w}\,)
            = 2\pi - \measuredangle(1,0,w)$,
            and so~$\arctan(\,\Real{w}/\Imag{w}\,)
            -\arctan(\,\Real{w'}/\Imag{w'}\,) =
            \measuredangle(w,0,w')$.

Similarly, \eqref{eq:14VIII}
follows easily from the first integral computed in point~2
when $\Real{w}=\Real{w'}$.

For the general case we consider
the triangle~$T$ with vertices~$w$, $w'$ and~$w''$
where either $w''=\Real{w}'+i\Imag{w}$
or 
$w''=\Real{w}+i\Imag{w}'$
such that~$0$ is not on the closure of~$T$.
Then Goursat's Theorem, \sref{parsec-140.40}
implies that
\begin{equation*}
    \int_w^{w''} z^{-1}\,dz  \ +\ 
    \int_{w''}^{w'} z^{-1}\,dz \ +\ 
    \int_{w'}^{w} z^{-1}\,dz\ = \ 0,
\end{equation*}
and so
\begin{alignat*}{3}
    \int_{w}^{w'} z^{-1}\,dz \ &= \ 
    \int_w^{w''} z^{-1}\,dz  \ +\ 
    \int_{w''}^{w'} z^{-1}\,dz \\
    &=\ i\measuredangle(w,0,w'')\ 
    +\ \log\frac{\left|w''\right|}{\left|w\right|}
    \ +\ \ i\measuredangle(w'',0,w')\ 
    +\ \log\frac{\left|w'\right|}{\left|w''\right|}\\
    &=\ i(\,\measuredangle(w,0,w'')\,+\measuredangle(w'',0,w')\,)\ 
    +\ \log\frac{\left|w''\right|}{\left|w\right|}\frac{\left|w'\right|}{\left|w''\right|}\\
    &=\ i\measuredangle(w,0,w')\ 
    +\ \log\frac{\left|w'\right|}{\left|w\right|}.
\end{alignat*}
\item
This is obvious if one notes
that the ``$\log$'' terms  will cancel.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-160.50}%
    If~$\spec(a)=\varnothing$,
    then~$\|a\|=\sup\varnothing=\infty$ by~\sref{parsec-160.20},
    which is absurd.
\end{solution}
\begin{solution}{parsec-160.60}%
Given~$\mu\in \C$,
the scalar~$\lambda - \mu$ 
is invertible in~$\scrA$
iff it is invertible in~$\C$
iff~$\lambda\neq \mu$.
Hence~$\spec(\lambda)=\{\lambda\}$.

For the other direction,
suppose that~$a$ is a self-adjoint element of~$\scrA$
    with $\spec(a)=\{\lambda\}$ for some $\lambda\in\C$.
Then $\spec(a-\lambda)=\spec(a)-\lambda = \{0\}$.
    Hence~$\|a-\lambda\|=\sup\{0\}=0$
    by~\sref{parsec-160.20},
    and so~$a=\lambda$.
\end{solution}
\begin{solution}{parsec-160.61}
    Let~$a$ from~$\scrA$ be given.
    Since~$\spec(a)$ is not empty by~\sref{parsec-160.60},
    there is~$\lambda\in\C$ such that~$a-\lambda$ is not intertible.
    As~$0$ is the only non-invertible element of~$\C$,
    we get $a-\lambda = 0$, and so~$a=\lambda$.
    Whence every element of~$\scrA$ is a scalar.
    Thus~$\scrA=\C$ or~$\scrA=\{0\}$.
\end{solution}
\begin{solution}{parsec-170.20}
    We already saw this in~\sref{parsec-90.20},
    but here's the argument again.
We have $\left|\lambda - t\right| \leq t$
iff $-t\leq \lambda - t\leq t$
iff $0\leq \lambda \leq 2t$.
\end{solution}
\begin{solution}{parsec-170.50}
    Note that
2$\implies$1 is obvious, and
1$\iff$4 is true by definition of ``positive'',
so it suffices to prove 
that 1$\implies$ 3$\implies$ 2.

Concerning~1$\implies$ 3, if
$\|a-t\|\leq t$,
    then~$\spec(a)\subseteq [0,2t]\subseteq [0,\infty)$
    by~\sref{parsec-170.30}.

Ad~3$\implies$ 2,
    if~$\spec(a)\subseteq [0,\infty)$,
    then given~$t\geq \frac{1}{2}\|a\|$,
    we have $\spec(a)\subseteq [0,\|a\|]\subseteq [0,2t]$,
    and so~$\|a-t\|\leq t$ by~\sref{parsec-170.30}.
\end{solution}
\begin{solution}{parsec-170.60}
\begin{enumerate}
\item
If~$0\leq a\leq 0$,
then~$\spec(a)\subseteq [0,\infty)$,
and~$\spec(a)=-\spec(-a)= (-\infty,0]$,
so that~$\spec(a)=\{0\}$,
which entails that~$a=0$.
\item
Let~$a_1,a_2,\dotsc$ be a sequence of positive elements
of~$\scrA$ that converges to some element~$a$ of~$\scrA$;
we must show that~$a$ is positive.
Then it's easy to see that~$a$ is self-adjoint,
using the fact that~$(\,\cdot\,)^*$ is continuous.

To show that~$a$ is positive,
it suffices to show that~$\|a-t\|\leq t$ for some~$t\in \R$.
Since the sequence $a_1,a_2,\dotsc$  converges,
it is bounded,
so there is some~$t>0$ with $\|a_n\|\leq t$ for all~$n$.
Since~$a_n$ is positive,
we have~$\|a_n-t\|\leq t$ for all~$n$
by~\sref{parsec-170.50}.
Taking the limit over~$n$,
we get $\lim_n\|a_n-t\|\equiv \|a-t\|\leq t$.
Hence~$a$ is positive, and so~$\scrA_+$ is closed.

\item
We have
$\|a\|\leq \lambda$
iff (\sref{parsec-160.20}) $\left|\mu\right|\leq \lambda$
for all~$\mu\in\spec(a)$
iff $-\lambda \leq \mu \leq \lambda$
for all~$\mu\in\spec(a)$
iff
$\lambda-\mu\geq 0$ and~$\lambda+\mu\geq 0$
for all~$\mu\in\spec(a)$
iff
$\lambda-\spec(a)\equiv\spec(\lambda-a)\subseteq [0,\infty)$
and $\lambda+\spec(a)\equiv\spec(\lambda+a)\subseteq [0,\infty)$
iff (\sref{parsec-170.50})
$\lambda -a$ and~$\lambda+a$ are positive
iff~$-\lambda \leq a\leq \lambda$.

Next,
writing $\|a\|_o = \inf\{\lambda\in \R\colon -\lambda\leq a \leq \lambda\}$
we must show that~$\|a\|=\|a\|_o$.
In~\sref{parsec-90.100},
we already saw that~$\|a\|_o\leq \|a\|$.
For the other direction,
let~$\lambda_1\geq \lambda_2\geq\dotsb\geq \|a\|_o$
be such that~$-\lambda_n \leq a\leq \lambda_n$
for all~$n$,
and~$\inf_n \lambda_n = \|a\|_o$.
Then~$\|a\|\leq \lambda_n$
(by the previous paragraph,)
and so~$\|a\|\leq \inf_n\lambda_n = \|a\|_o$.
Whence~$\|a\|=\|a\|_o$.

Finally,
given self-adjoint elements~$a,b\in\scrA$ with~$0\leq a\leq b$,
we have~$-\|b\|\leq 0\leq a \leq b\leq \|b\|$,
and so $\|a\|\leq\|b\|$.
\item
All this follows from~\sref{parsec-110.150},
using the fact (from~\sref{parsec-170.50}) that self-adjoint~$b\in\scrA$
is positive iff~$\spec(b)\subseteq[0,\infty)$.
\item
This follows from~\sref{parsec-110.210}(6).
\item
First note that~$\frac{1}{n}\leq a$
iff~$a-\frac{1}{n}$ is positive
iff $\spec(\,a-\frac{1}{n}\,)\equiv \spec(a)-\frac{1}{n} \subseteq [0,\infty)$
iff $\spec(a)\subseteq [\frac{1}{n},\infty)$.

Recall that~$a$ is invertibe iff~$0\notin\spec(a)$.
Surely, if~$\spec(a)\subseteq [\frac{1}{n},\infty)$,
then~$0\notin \spec(a)$, and so~$a$ is invertible.
For the other direction,
suppose that~$a$ is not invertible,
then~$0\notin \spec(a)\subseteq [0,\infty)$,
and so (since~$\spec(a)$ is closed),
there's $n$ such that~$\lambda\notin \spec(a)$
for all~$\lambda\in \C$ with $\left|\lambda\right|\leq \frac{1}{n}$.
Thus $\spec(a)\subseteq[\frac{1}{n},\infty)$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-201.10}
Note that the projections
$\pi_j\colon\bigoplus_i \scrA_i\to \scrA_j$
are miu-maps.

Let~$a$ be an element of~$\bigoplus_i \scrA_i$.
Note that since
    $\|a\|=\sup_i\|a(i)\|$, we have $\|a(i)\|\leq \|a\|$ for all~$i\in I$.
Thus, $a$ is positive iff
$\|\,a-\|a\|\,\|\leq\|a\|$
    iff $\|\,a(i)-\|a\|\,\|\leq \|a\|$
    for all~$i\in I$
    iff $a(i)$ is positive for all~$i\in I$.
In particular,
every projection $\pi_j\colon \bigoplus_i\scrA_i\to\scrA_j$
is positive,
    (which also follows from~\sref{parsec-200.50}.)

Let~$\scrB$ be a $C^*$-algebra,
and for each~$i\in I$,
let $f_i\colon \scrB \to \scrA_i$ be an pu-map.
We must show that there is a unique
    pu-map $g\colon \scrB\to \bigoplus_i \scrA_i $
    with~$\pi_i\circ g = f_i$ for all~$i\in I$.
Given~$b\in \scrB$,
    we have~$\|f_i(b)\|\leq 2\|b\|$
    by~\sref{parsec-200.20},
    and so $g(b)(i)=f_i(b)$
    defines an element~$g(b)$ of~$\bigoplus_i\scrA_i$,
    and a map~$g\colon \scrB\to\bigoplus_i\scrA_i$.
Clearly, $g$ is linear, unital,
    and $\pi_i\circ g = f_i$ for all~$i\in I$.
Also, $g$ is positive:
given positive~$b\in \scrB_+$,
we know that~$g(b)(i)=f_i(b)\geq 0$ for every~$i\in I$,
    and so~$g(b)\geq 0$.

The only thing left to show
before we know~$\bigoplus_i \scrA_i$
is the product of the~$\scrA_i$
    in~$\Cstar{pu}$
    is the uniqueness of~$g$.
So let~$g'\colon \scrB\to\bigoplus_i\scrA_i$
be a pu-map
with $\pi_i\circ g' =f_i$ for all~$i\in I$.
Then 
    $g'(b)(i)=\pi_i(g'(b))
    = f_i(b) = g(b)(i)$
    for all~$i\in I$ and~$b\in\scrB$.
    Hence~$g=g'$.

Since the projections $\pi_i$ are all miu-maps,
and the map~$g$ in the proof above is clearly miu when all~$f_i$'s are miu,
we see that $\bigoplus_i\scrA_i$ is also the product
    of the~$\scrA_i$ in~$\Cstar{miu}$.
Since clearly $\bigoplus_i \scrA_i$ is commutative
when all~$\scrA_i$ are commutative,
the full subcategories
    $\cCstar{miu}$ and~$\cCstar{pu}$
    of~$\Cstar{pu}$
    are closed under products.
\end{solution}
\begin{solution}{parsec-201.20}
The only non-trivial part to proving that~$\scrE$
is a $C^*$-subalgebra of~$\scrA$ is
showing that~$\scrE$ is a closed subset of~$\scrA$.
So let~$a_1,a_2,\dotsc$ be a sequence from~$\scrE$
converging to some element~$a$ of~$\scrA$;
we must show that~$a\in \scrE$.
Since~$a_1,a_2,\dotsc$ converges to~$a$,
    the sequence $f(a_1),\,f(a_2),\,\dotsc$
    converges to~$f(a)$,
since $f$, being bounded, is continuous.
    Similarly, $g(a_1),\,g(a_2),\,\dotsc$
    converges to~$g(a)$.
But since  $f(a_n)=g(a_n)$
    for all~$n$ (as~$a_n\in\scrE$)
these sequences
    are the same, and thus their
    limits are equal too.  Thus~$f(a)=g(a)$ and~$a\in\scrE$.

That the inclusion $e\colon \scrE\to\scrA$
is a miu-map is obvious. To see that it's also the equaliser
    of~$f$ and~$g$ in~$\Cstar{pu}$, let~$\scrC$ be a $C^*$-algebra,
and let $\gamma\colon \scrC\to\scrA$ be a pu-map with
$f\circ \gamma = g\circ \gamma$.
We must show that there's a unique pu-map $h\colon \scrC\to\scrE$
with~$e\circ h = g$.
Since~$e$ is injective, uniqueness is clear.
Concerning existence, note
that~$f(\gamma(c))=g(\gamma(c))$
for all~$c\in\scrC$,
and so~$\gamma(c)\in\scrE$.
We may thus define $h\colon \scrC\to\scrE$ by
$h(c)=\gamma(c)$ for all~$c\in\scrC$.
Clearly, $h$ is linear, unital, and~$\gamma=e\circ h$.
Also~$h$ is positive, 
since the elements of~$\scrE$ that are positive in~$\scrA$
are positive in~$\scrE$ too.
    Thus~$e$ is the equaliser of~$f$ and~$g$ in~$\Cstar{pu}$.

Note that since~$e$ is a miu-map,
and the map~$h$ in the proof above is miu provided that~$\gamma$
is miu,
    we see that~$e$ is the equaliser of~$f$ and~$g$ in~$\Cstar{miu}$ too.

Since~$\scrE$ is commutative when~$\scrA$ is commutative,
    $e$ is the equaliser of~$f$ and~$g$ in~$\cCstar{miu}$
    and~$\cCstar{pu}$
    when~$\scrA$ and~$\scrB$ are commutative.
\end{solution}
\begin{solution}{parsec-210.50}
If~$a$ is self-adjoint,
then given $\omega\in\Omega$
we have~$\omega(a)^* = \omega(a^*)=\omega(a)$,
using here that~$\omega$ is involution preserving,
    so~$\omega(a)$ is self-adjoint.

    Conversely,
    if~$\omega(a)$ is self-adjoint for every $\omega\in\Omega$,
then $\omega(a-a^*)=\omega(a)-\omega(a^*)=
    \omega(a)-\omega(a)^*=0$ for every $\omega\in\Omega$,
    and so~$a-a^*=0$, because~$\Omega$ is separating.
    Hence~$a$ is self-adjoint.
\end{solution}
\begin{solution}{parsec-210.100}
Let~$a$ be an element of~$\scrA$
such that~$\omega'(a)\geq 0$
for all~$\omega'\in \Omega'$;
we must show that~$a\geq 0$.
    It suffices to show that~$\omega(a)\geq 0$
    for all~$\omega\in \Omega$,
    since~$\Omega$ is order separating.
    So let~$\omega\in \Omega$ be given,
    and let~$\omega_1',\omega_2',\dotsc$
    be a sequence in~$\Omega'$ converging to~$\omega$
    with respect to the operator norm.
    Then $\omega_1'(a),\,\omega_2'(a),\,\dotsc$
    are all positive, by assumption, and converge
    to~$\omega(a)$.  Thus~$\omega(a)\geq 0$, and so~$a=0$.
    Hence~$\Omega'$ is order separating.
\end{solution}
\begin{solution}{parsec-220.30}
\begin{enumerate}
\item
Let~$f\colon \scrA\to\C$ be a state,
and let~$I$ be an order ideal of~$\scrA$
with~$\ker(f)\subsetneq I$.
Then there's an element~$x\in I$ with~$f(x)\neq 0$.
By scaling~$x$ if necessary,  we may assume that~$f(x)=1$.
Note that~$f(1-x)=f(1)-f(x)=1-1=0$,
and so~$1-x\in\ker(f)\subseteq I$.
But since~$x\in I$, too, we get $1\equiv(1-x)+x\,\in I$.
Hence~$I=\scrA$, and so~$\ker(f)$ is maximal.
\item
By Zorn's lemma,
it suffices to show that a non-empty
chain~$\mathcal{I}$ of proper order ideals
containing~$I$ has an upper bound.
We claim that $J:=\bigcup\mathcal{I}$
is such an upper bound.
For this, we only need to check that~$J$
is an order ideal.  Indeed,
if it is, it'll be an upper bound for~$\mathcal{I}$,
and proper, because~$1\in J\equiv\bigcup \mathcal{I}$
would imply that~$1\in I$
for some $I \in\mathcal{I}$.

Let~$a,b\in J$
be given.
Then $a\in I_1$, and~$b\in I_2$ for some~$I_1,I_2\in\mathcal{I}$.
Since~$\mathcal{I}$ is a chain,
either $I_1\subseteq I_2$ or~$I_2\subseteq I_1$.
Letting~$I$ denote the largest one,
we have~$a,b\in I$, and so~$a+b\in I\subseteq J$.
You get the idea;
by such reasoning we see that~$I$
is an order ideal.

\item
Define $(a):=\Real{(a)}+i\Real{(a)}$,
where
$$\Real{(a)}\ :=\ \{\ b\in \Real{\scrA}\colon \exists\lambda,\mu\in\R\ 
[ \ \lambda a \leq b \leq \mu a\ ]\ \}.$$
Then clearly~$(a)$ is a linear subpace of~$\scrA$
that contains~$a$.
Moreover,
given~$b\in\scrA$
we have $b\in(a)$
iff~$\Real{b},\Imag{b}\in \Real{(a)}$.
Thus~$b\in(a)\implies b^*\in (a)$.

To show that~$(a)$ is an order ideal,
let~$b\in (a)\cap \scrA_+$ 
and $c\in\scrA$ with $-b\leq c\leq b$ be given;
we must show that~$c\in(a)$.

Since~$b$ being positive is self-adjoint,
we have~$b=\Real{b}\in \Real{(a)}$,
and so there are $\lambda,\mu\in \R$
with $\lambda a\leq b\leq \mu a$.
Then $-\mu \leq-b \leq c \leq b  \leq \mu a$,
and so~$c\in \Real{(a)}\subseteq (a)$.
Hence~$(a)$ is an order ideal.

It remains to be shown that~$(a)$ is the least order ideal
that contains~$a$. 
To this end, let an order ideal~$I$ that contains~$a$ be given;
we must show that~$(a)\subseteq I$.
It suffices to show that~$\Real{(a)}\subseteq I$,
and for this,
we must show given~$\lambda,\mu\in \R$
and~$b\in \Real{\scrA}$ with $\lambda a \leq b \leq \mu a$,
that~$b\in I$.

Since then $(\mu-\lambda)a \geq 0$
is a positive element of~$I$,
and $-(\mu-\lambda)a\leq 0 \leq b-\lambda a \leq (\mu-\lambda)a$,
we get $b-\lambda a \in I$,
and thus $b\in I$ too, (since~$\lambda a\in I$).

Hence~$(a)$ is the least order ideal that contains~$a$.

Suppose that~$0\nleq a\nleq 0$,
and let~$b\in \Real{(a)}$ be given.
Pick~$\lambda,\mu \in \R$ with $\lambda a \leq b \leq \mu a$.
Then~$(\mu-\lambda)a\geq 0$.
There are now three cases to consider:
if~$\mu-\lambda >0$, then~$a\geq 0$;
if~$\mu-\lambda < 0$, then~$a\leq 0$;
and if~$\mu-\lambda = 0$, then~$\lambda a = b = \mu a$.
Since the latter case is the only possibility,
we see that~$\Real{(a)}=a\R$, and so~$(a)=a\C$.

Suppose that~$1\in(a)$.
If $0\nleq a\nleq 0$, then we have~$(a)=a\C$,
so~$a$ is a real scalar, which contradicts
$0\nleq a\nleq 0$.
So either~$0\leq a$ or~$a\leq 0$.
In any case,
since~$1\in (a)$,
we have~$1\in \Real{(a)}$,
and so $\lambda a\leq 1\leq \mu a$
for some~$\lambda,\mu\in \R$.
If~$a\geq 0$,
then~$1\leq \mu a$ entails that~$\mu\geq 0$, 
and
$\frac{1}{\mu}\leq a$,
so~$a$ is invertible, by~\sref{parsec-170.60}(6).
If~$a\leq 0$,
then~$1\leq \mu a$ entails that~$\mu\leq 0$,
and
$-\frac{1}{\mu} \leq -a$,
so~$-a$ is invertible,
thus $a$ is invertible too.
\item
Since~$a$ is not invertible,
$(a)$ is proper, by point~3,
and~$(a)$ is thus contained in a maximal order ideal, by point~2.
\item
Recall that $\|a\|=\sup\{\left|\lambda\right|\colon \lambda\in \spec(a)\}$
by~\sref{parsec-160.20}.
Let~$\lambda_1,\lambda_2,\dotsc$
be a sequence in~$\spec(a)$
such that~$\left|\lambda_1\right|\,\leq\,
\left|\lambda_2\right|\,\leq\,
\dotsb$ converges to~$\|a\|$.
Then since~$\spec(a)$ is compact,
a subsequence~$\lambda_{n_1},\,\lambda_{n_2},\,\dotsc$
of  $\lambda_1,\lambda_2,\dotsc$
converges to some~$\lambda\in\spec(a)$.
Since $\left|\lambda_{n_1}\right|,\,\left|\lambda_{n_2}\right|,\,\dotsc$
is a subsequence of 
$\left|\lambda_1\right|\,\leq\,
\left|\lambda_2\right|\,\leq\,$
it must converge to~$\|a\|$, too.
Thus~$\left|\lambda\right|=\|a\|$,
and so either~$\lambda=\|a\|$ or~$\lambda=-\|a\|$.
Thus either~$\|a\|\in \spec(a)$
or~$-\|a\|\in \spec(a)$.
So at least one of
$\|a\|-a$ and~$\|a\|+a$
is not invertible.
\end{enumerate}
\end{solution}

\end{document}
