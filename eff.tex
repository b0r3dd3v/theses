% https://link.springer.com/article/10.1007/s10992-013-9275-5 
% coproduct supremum
% monoidal
%
\documentclass[b]{subfiles}
\begin{document}

\chapter{Diamond, andthen, dagger}

\begin{parsec}%
\begin{point}%
In the previous chapter and in \cite{bram}
    we have studied the categorical properties of von Neumann algebras.
In this chapter we change pace:
    we study categories which share part of the structure
    of the category of von Neumann algebras.
The goal of this line of study, is to identify
    axioms which uniquely pick out the category of von Neumann algebras.
We do not reach this ambitious goal ---
    instead we will build up to a characterization of
    the existence of a unique $\dagger$-structure
    on the pure maps of a von Neumann-like category.
\end{point}
\begin{point}%
As basic axiom we will require the categories we consider to be
    effectuses.
For us the definition of an effectus will play a similar role
    to that of a topological space for a geometer.
General topological spaces on their own are usually of little interest:
    the axioms are so weak that there are many pathological examples.
    These weak axioms, however, are very expressive in the sense
    that they allow for the definition of many useful notions.
    Herein lies the strength of topological spaces ---
    as a stepping stone:
    many important classes of mathematical spaces
    are just plain topological spaces with a few additional axioms.
Similarly, there will be many pathalogical effectuses.
Their use for us lies in their expressiveness.
\end{point}
\begin{point}%
Before we can dive into effectuses,
    we need to learn about effect algebras (and related structures),
    which were introduced by mathematical physicists as
    a generalization of Boolean algebra to study unsharp predicates
    in quantum mechanics.
    In a sense, effectuses are the categorical counterpart of effect algebras.
Then we continue with a brief, but thorough development
    of the basic theory of effectuses.
There is a lot more to say about effectuses
    (see \cite{effintro}), which has been omitted
    to avoid straining the Reader.
    However, we will indulge in one tangent:
    the study of abstract convex sets in
    \S\ref{more-aconvm}, which can be skipped.
For the moment, think of an effectus as a generalization
    of the opposite category of von Neumann algebras:
    the objects represent the physical systems
    (or data types, if you like)
    and the maps represent the physical processes
    (or properly typed maps).
\end{point}
\begin{point}%
The first two axioms we add on top of an effectus
    are the existence of quotients and comprehension.
It's helpful to discuss the origin of these axioms.
It started with the desire to axiomatize categorically
    the sequential product on a von Neumann algebra~$\scrA$,
    the operation~$\andthen{a}{b} \equiv  \sqrt{a} b \sqrt{a}$,
    which represents sequential measurement
    of first~$a$ \emph{andthen} $b$.
The sequential product is the quantum mechanical counterpart
    of conjunction (logical `and').
In  contrast to the tame~$\wedge$ in a Boolean algebras,
    the sequential product does not obey a lot of insightful
    formulas.
Instead, we take a step back and
    consider the map~$\asrt_a(b) \equiv  \andthen{a}{b}$
        for fixed~$a$, which factors into two part:
\begin{equation*}
    \xymatrix@C+2pc@R-2pc{
        \scrA \ar[r]^\pi & \ceil{a} \scrA \ceil{a} \ar[r]^\xi
        & \scrA \\
        b \ar@{|->}[r] & \ceil{a}b\ceil{a}
            \ar@{|->}[r] & \sqrt{a}b\sqrt{a}.
    }
\end{equation*}
It turns out that both~$\pi$ and~$\xi$ have
    nice and dual (in a sense) defining universal properties
    which can be expressed in an effectus:
    $\pi$ is a comprehension and~$\xi$ is a quotient.\footnote{%
            Beware: an effectus quotient is not the same thing
        as a von Neumann-algebra quotient.}
\end{point}
\begin{point}%
The existence of quotients and comprehension in some effectus~$C$
    is interesting on its own, but with
    two additional axioms (the existence of images and
    preservation of images under orthocomplement),
    we get a surprisingly firm handle
    on the possibilistic side of~$C$,
    by means of the existence
    of a certain functor~$(\ )_\diamond\colon C \to \mathsf{OLat}$.
In the guiding example of von Neumann algebras,
    we have~$f_\diamond = g_\diamond$
        if and only
    there is no post-measurement~$a$ and initial state~$\omega$
    that can distinguish with certainty
    between whether~$f$ or~$g$ has been performed.\footnote{%
    In symbols: $
    f_\diamond = g_\diamond \iff 
\bigl(\forall a,\omega.\  \omega(f(a))  =  0 \ \Leftrightarrow\ \omega(g(a))  =  0\bigr).$}
With this functor we can introduce several
    possibilistic notions of which~$\diamond$-adjoint
    and~$\diamond$-positive are the most important.
Because of the central role of~$\diamond$,
    we call an effectus with these axioms 
    a~$\diamond$-effectus.
\end{point}
\begin{point}%
The axioms of a~$\diamond$-effectus do not force
    any coherence between the quotients and comprehension.
This has been a roadblock in the axiomatization
    of the sequential product for quite a while.
The key insight was the following:
    the map~$\asrt_a$ (i.e.~$b\mapsto \andthen{a}{b}$)
    is the unique~$\diamond$-positive map on~$\scrA$
    with~$\asrt_a(1) = a$.
We turn this Theorem into an axiom:
    an~$\&$-effectus is
    a~$\diamond$-effectus
    where there are such unique~$\diamond$-positive maps~$\asrt_a$
    and an additional polar decomposition axiom holds.
In an~$\&$-effectus, the predicates on an object carry a canonical~$\&$
    which is the intended sequential product in
    the case of von Neumann algebras.
\end{point}
\begin{point}%
In an effectus, we call a map pure if it can be written
    as the composition of quotients and comprehensions.
In \TODO{} we saw that in the case of von Neumann algebras,
    a map is pure (in this sense) if and only if the corresponding Paschke
    embedding is surjective.
In particular, the pure maps~$\scrB(\scrH) \to \scrB(\scrK)$
    are exactly of the form~$\ad_v$,
    which carry a~$\dagger$-structure,
    namely~$(\ad_v)^\dagger = \ad_{v^*}$.
This begs the question: can we define a~$\dagger$ on all pure maps
    in an~$\&$-effectus?
The main result of this chapter
    is Theorem \sref{dagger-theorem}
    which gives  necessary and sufficient conditions
    for an~$\&$-effectus
    to have a well-behaved~$\dagger$-structure on its pure maps.
After this highpoint, we reflect and discuss how these
    structures compare to those already known in the literature.
\end{point}
\end{parsec}
\section{Effect algebras et al}
\begin{parsec}%
\begin{point}%
Before we turn to effectuses,
    it is convenient to introcuce some lesser-known algebraic structures first
    of which the effect algebra is the most important.
It will turn out that the set of predicates associated to an object in
    an effectus can be arranged into an effect algebra.
In this way, effect algebras play the same role
    for effectuses as heyting algebras for topoi.
    First, we will recall the definition of partial commutative monoid (PCM)
    --- as later in \sref{cho-thm} 
    we will see that the partial maps between
    two objects in an effectus can be arranged into a PCM.
\end{point}
\begin{point}[dfn-pcm]{Definition}%
    A \Define{partial commutative monoid} (\Define{PCM})~$M$
        is a set~$M$ together with distinguished element~$0 \in M$
        and a partial binary operation~$\ovee$ such that
        for all~$a,b,c \in M$ 
        --- writing~$a \perp b$ whenever~$a \ovee b$ is defined
        --- we have
\begin{enumerate}
    \item \emph{(partial commutativity)}
        if $a \perp b$, then~$b \perp a$ and~$a \ovee b = b \ovee a$;
    \item \emph{(partial associativity)}
        if $a \perp b$ and~$a \ovee b \perp c$,
        then~$b \perp c$, ~$a \perp b \ovee c$
            and~$(a \ovee b) \ovee c = a \ovee (b \ovee c)$ \emph{and}
    \item \emph{(zero)}
        $0 \perp a$ and~$0 \ovee a = a$.
\end{enumerate}
We say~$a\mathrel{\Define{\leq}} b$
    whenever~$a \ovee c = b$ for some~$c \in M$.
\end{point}
\begin{point}[pcm-preorder]{Exercise}%
Show a PCM is preordered by~$\leq$.
% \begin{point}{Proof}%
% Reflexivity is easy:~$a \ovee 0 = 0 \ovee a = a$
%     by the partial commutativity and zero axiom, so~$a \leq a$.
% For transitivity, assume~$a \leq b$ and~$b \leq c$.
% Pick~$d,e \in M$
%     with~$a \ovee d = b$ and~$b \ovee e = c$.
% Then by partial
% associativity~$c = b \ovee e = (a \ovee d) \ovee e = a \ovee (d \ovee e)$
% so~$a \leq c$.
% \end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[dfn-ea]{Definition}%
A PCM~$E$ together with distinguished element~$1 \in E$
is an \Define{effect algebra} (\Define{EA}) \cite{ea}
    provided
\begin{enumerate}
\item
    \emph{(orthocomplement)}
    for every~$a$
    there is a unique~$a^\perp$
   with~$a \ovee a^\perp = 1$ \emph{and}
\item
    \emph{(zero--one)}
    if~$a \perp 1$, then~$a = 0$.
\end{enumerate}
A map~$f\colon E \to F$
between effect algebras~$E$ and~$F$
is called an \Define{effect algebra homomorphism}
if
\begin{enumerate}
    \item \emph{(additivity)}
    $a \perp b$ implies $f(a) \perp f(b)$ and~$f(a)\ovee f(b) = f(a\ovee b)$
        \emph{and}
    \item \emph{(unital)}
    $f(1) = 1$.
\end{enumerate}
Write~$\Define{\textsf{EA}}$ for the category
    of effect algebras these homomorphisms.
\end{point}
\begin{point}{Examples}%
There are many examples of effect algebras
    --- we only give a few.
\begin{enumerate}
\item
The unit interval
$[0,1]$ with partial addition is an effect algebra ---
i.e.:~$x \perp y$
        whenever~$x +y \leq 1$, $x \ovee y = x + y$
        and~$a^\perp = 1-a$.
\item
Generalizing the previous:
if~$G$ is an ordered group
with distinguished element~$1$,
then the order interval~$[0,1]_G \equiv \{x;\ x\in G;\ 0 \leq x\leq 1\}$
is an effect algebra
with~$x \perp y$ whenever~$x +y \leq 1$;
$x \ovee y = x + y$ and~$x^\perp = 1-x$.
\item
In particular,
    if~$\scrA$ is any von Neumann algebra,
    then the set of \Define{effects}~$[0,1]_\scrA$
    forms an effect algebra
    with~$a \perp b$ whenever~$a +b \leq 1$;
    $a \ovee b = a + b$ and~$a^\perp = 1-a$.
The `effect' in effect algebra originates from this example.
\item
Any orthomodular lattice~$L$
    is an effect algebra
    with the same orthocomplement,
    $x \perp y$ whenever~$x \leq y^\perp$
    and~$x \ovee y = x \vee y$.  (See e.g.~\cite[Prop.~27]{basmsc}.)
\item
In particular,
    any Boolean algebra~$L$
    is an effect algebra
    with complement as orthocomplement,
    ~$x \perp y$ whenever~$x \wedge y = 0$ and
    $x \ovee y = x \vee y $.
\item
The one-element Boolean algebra~$1 \equiv \{0=1\}$
    is the final object in \textsf{EA}
    and the two-element Boolean algebra~$2 \equiv \{0,1\}$
    is the initial object in \textsf{EA}.
\end{enumerate}
\end{point}

\begin{point}[ea-product]{Exercise}%
Assume~$E$ and~$F$ are effect algebras.
First show that the cartesian products~$E \times F$
    is an effect algebra with componentwise operations.
Show that this is in fact the categorical product of~$E$ and~$F$
    in \textsf{EA}.
To finish, show that~\textsf{EA} has initial
    object~$\{0,1\}$
    and final object~$\{0=1\}$.
(The category \textsf{EA} is in fact complete and cocomplete;
    for this and more categorical properties,
        see \cite{corefl}.)
\end{point}

\begin{point}{Exercise}%
There is a small redundancy in our definition of effect algebra:
show that the zero axiom ($x \ovee 0 = x$)
follows from the remaining axioms (partial commutativity,
partial associativity, orthocomplement and zero--one.)
\end{point}

\begin{point}{Proposition}%
In any effect algebra~$E$, we have
\begin{enumerate}
    \item \emph{(involution)}
        $a^{\perp\perp} = a$;
    \item
        $1^\perp= 0$ and~$0^\perp = 1$;
    \item \emph{(positivity)}
        if~$a\ovee b = 0$, then~$a = b= 0$;
    \item \emph{(cancellation)}
        if~$a\ovee c = b\ovee c$, then~$a = b$;
    \item $\leq$ partially orders~$E$;
    \item $a \leq b$ if and only if $b^\perp \leq a^\perp$;
    \item if~$a \leq b$ and~$b \perp c$, then~$a \perp c$
        and~$a \ovee c \leq b \ovee c$ \emph{and}
    \item $a \perp b$ if and only if~$a \leq b^\perp$.
\end{enumerate}
\begin{point}{Proof}%
By partial commutativity and definition
of orthocomplement both~$a^\perp \ovee a = 1$
and~$a^\perp \ovee  a^{\perp\perp} = 1$.
So by uniqueness of orthocomplement,
    we must have~$a= a^{\perp\perp}$, which is point 1.
Clearly~$0 \ovee 1 = 1$,
    so~$1^\perp = 0$ and~$0^\perp = 1$,
    which is point 2.
For point 3, assume~$a \ovee b = 0$.
Then~$a \ovee b \perp 1$
    and so by partial associativity~$b \perp 1$.
    By zero--one, we get~$b = 0$.
    Similarly~$a=0$, which shows point 3.
For point 4, assume~$ a \ovee c = b \ovee c$.
From partial associativity, we get
\begin{equation*}
    ((a \ovee b)^\perp\ovee a) \ovee c \ =\  
    ((a \ovee b)^\perp\ovee a) \ovee b \ = \ 1
\end{equation*}
and so by uniqueness of
orthocomplement~$c = ((a\ovee b)^\perp\ovee a)^\perp = b$,
    which is point 4.
By \sref{pcm-preorder},
    we only need to show that~$\leq$ is antisymmetric
    for point 5.
So assume~$a \leq b$ and~$b \leq a$.
Pick~$c,d \in E$ with~$a \ovee c = b$ and~$b \ovee d = a$.
Then~$a = (a \ovee c) \ovee d = a \ovee (c \ovee d)$.
By cancellation~$c \ovee d = 0$.
So by positivity~$c = d= 0$.
Hence~$a = b$.
For point 6, assume~$a\leq b$.
Pick~$c \in E$ with~$a \ovee c = b$.
Clearly~$a \ovee a^\perp = 1 = b \ovee b^\perp = a \ovee c \ovee b^\perp$,
so by cancellation~$a^\perp = c \ovee b^\perp$,
    which is to say~$b^\perp \leq a^\perp$.
For point 7, assume~$a \leq b$ and~$b \perp c$.
Pick~$d$ with~$a \ovee d = b$.
By partial associativity and commutativity
    we have~$b \ovee c = (a \ovee d) \ovee c = (a \ovee c) \ovee d$,
    so~$a \ovee c$ and~$a \ovee c \leq b \ovee c$.
For point 8, first assume~$a \perp b$.
Then~$a \ovee b \ovee (a \ovee b)^\perp = 1 = b \ovee b^\perp$.
So by cancellation~$b^\perp = a \ovee (a \ovee b)^\perp$,
hence~$a \leq b^\perp$.
For the converse, assume~$a \leq b^\perp$.
Then~$a \ovee c = b^\perp$ for some~$c$.
Hence~$a \ovee c \perp b$
    and so  by partial associativity and commutativity,
        we get~$a \perp b$, as desired.
    \qed
\end{point}
\end{point}
\end{parsec}%

\begin{parsec}%
\begin{point}{Definition}%
Suppose~$E$ is an effect algebra.
Write~$\Define{b \ominus a}$
for the (by cancellation) unique element (if it exists)
such that~$a \ovee (b \ominus a) = b$.
\end{point}
\begin{point}{Exercise}%
Show that for any effect algebra~$E$, we have
\begin{enumerate}
    \item[(D1)]~$a \ominus b$ is defined if and only if~$b \leq a$;
    \item[(D2)]~$a \ominus b \leq a$ (if defined);
    \item[(D3)]~$a \ominus (a \ominus b) = b$ (if defined) \emph{and}
    \item[(D4)]~if $a \leq b \leq c $,
                then~$c \ominus b \leq c \ominus a$
                and~$(c \ominus a) \ominus (c \ominus b) = b \ominus a$.
\end{enumerate}
\begin{point}%
Assume~$E$ is a poset with maximum element~$1$
    and partial binary operation~$\ominus$
    satisfying~(D1)--(D4).
Define~$a \ovee b = c \Leftrightarrow c \ominus b = a$
    and~$a^\perp = 1 \ominus a$.
Show that this turns~$E$ into an effect algebra
    with compatible order and~$\ominus$.
\end{point}
\begin{point}{Remark}%
Such a structure~$(E,\ominus,1)$ is called a difference-poset
    (D-poset) and is, as we have just seen,
    an alternative way to axiomatize effect algebras.
\end{point}
\end{point}

\begin{point}{Exercise}%
Show that for an effect algebra homomorphism~$f\colon E \to F$,
    we have
    \begin{enumerate}
        \item~\emph{(preserves zero)} $f(0) = 0$;
        \item~\emph{(order-preserving)} if $a \leq b$, then~$f(a) \leq f(b)$
                        \emph{and}
        \item~if~$a\ominus b$ is defined,
            then $f(a \ominus b) = f(a) \ominus f(b)$.
    \end{enumerate}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[ea-modularity-prop]{Proposition}%
Suppose~$E$ is an effect algebra.
If the infimum~$a \wedge b$
    exists for some~$a,b \in E$ with~$a \perp b$,
    then their supremum~$a \vee b$ exists as well and
\begin{equation*}
    a \ovee b \ = \ (a \wedge b) \,\ovee\, (a \vee b).
\end{equation*}
\begin{point}{Proof}%
The result follows from this lemma:
    if~$(x \ominus c) \wedge (x \ominus d)$ exists,
    then~$c \vee d$ exists as well
    and~$(x \ominus c) \wedge (x \ominus d)
        = x \ominus (c \vee d)$.
Indeed:
\begin{equation*}
    a \wedge b \ = \ 
        ((a \ovee b) \ominus a) \wedge ((a \ovee b) \ominus b) \ = \ 
        (a \ovee b) \ominus (a \vee b)
\end{equation*}
    and so~$(a \wedge b) \ovee (a \vee b) = a \ovee b$, as desired.
\begin{point}%
Now we show the lemma.
Assume~$(x \ominus c) \wedge (x \ominus d)$ exists.
Note~$x \ominus c = (x^\perp \ovee c)^\perp$.
As~$z \mapsto z^\perp$ is an order anti-isomorphism,
    we see~$(x^\perp \ovee c) \vee (x^\perp \ovee d)$
        exists and~$(x^\perp \ovee c) \vee (x^\perp \ovee d)
                                    = ((x \ominus c)\wedge (x \ominus d))^\perp$.
Clearly~$ (x^\perp \ovee c) \vee
        (x^\perp \ovee d) \geq x^\perp$.
    Write~$r := ((x^\perp \ovee c) \vee
        (x^\perp \ovee d)) \ominus x^\perp$.
We will show~$r = c \vee d$.
It is easy to see~$r \geq c$ and~$r \geq d$.
Assume~$s$ is another element with~$s \geq c$ and~$s \geq d$.
Note~$x^\perp \ovee s \geq x^\perp \ovee c$
and~$x^\perp \ovee s \geq x^\perp \ovee d$,
    hence~$x^\perp \ovee s \geq (x^\perp \ovee c) \vee (x^\perp \ovee d)$
    and so~$ s \geq  r$.
We have shown~$r = c \vee d$.
Consequently~$ (x \ominus c)\wedge (x \ominus d)
        = ((x^\perp \ovee c) \vee (x^\perp \ovee d))^\perp
        = (r \ovee x^\perp)^\perp = 
            x \ominus (c \vee d) $, as promised. \qed
\end{point}    
\end{point}
\end{point}
\end{parsec}

\subsection{Effect monoids}
\begin{parsec}%
\begin{point}%
In \sref{dfn-mandso}, we will see that the scalars of an effectus
form an effect monoid:
\end{point}
\begin{point}[dfn-effect-monoid]{Definition}%
An \Define{effect monoid}~$M$ \cite{probdistrconv}
    is an effect algebra
    together with a binary operation~$\odot$
    such that for all~$a,b,c,d \in M$, we have
\begin{enumerate}
    \item \emph{(unit)}
    $1 \odot a = a \odot 1 = a$;
\item \emph{(associativity)}
    $(a \odot b) \odot c 
    =a \odot (b \odot c)$ \emph{and}
\item \emph{(distributivity)}
    $(a \ovee b) \odot (c \ovee d)
            = (a \odot c) \ovee (b \odot c) \ovee
            (a \odot d) \ovee (b \odot d)$
            whenever~$a \perp b$ and~$c \perp d$.
\end{enumerate}
(Phrased categorically:
    an effect monoid is a monoid in \textsf{EA}
    with the obvious tensor product, see \cite{corefl,probdistrconv}.)
An effect monoid~$M$ is said to be \Define{commutative}
    if we have~$a\odot b = b\odot a$ for all~$a,b \in M$.
\end{point}
\begin{point}[eff-monoid-examples]{Examples}%
Effect monoids are less abundant.
\begin{enumerate}
\item The effect algebra~$[0,1]$
        is a commutative effect monoid with the usual product.
        (This is the only way to turn~$[0,1]$ into an effect monoid
                \cite[Prop.~41]{basmsc}.)
\item We saw earlier that every Boolean algebra is an effect algebra
        with~$x \ovee y = x \vee y$ defined iff~$x \wedge y = 0$.
    The Boolean algebra is turned into an effect monoid
        with~$x \odot y \equiv x \wedge y$.
    Every finite (\emph{a priori} non-commutative) effect monoid
    is of this form \cite[Prop.~40]{basmsc}.
\item
In particular: the two-element Boolean algebra~$2$
    is an effect monoid.
\item There is a non-commutative effect monoid
        based on the lexicographically ordered vector space~$\R^5$,
        see ~\cite[Cor.~51]{basmsc}.
\item Assume~$M$ is an effect monoid.
    Write~$M^{\mathsf{op}}$
        for the effect monoid~$M$ with the opposite multiplication
            --- that is: $a \odot_M b = b \odot_{M^\mathsf{op}} a$.
\end{enumerate}
\end{point}
\begin{point}[emond-lemma-for-conv]{Exercise}%
Assume~$M$ is an effect monoid
with~$a_1, \ldots, a_n, b_1, \ldots, b_n \in M$
such that~$\bigovee_i a_i = 1$
and~$\bigovee_i a_i \odot b_i = 1$.
Prove~$a_i \odot b_i = a_i$ for every~$1 \leq i \leq n$.
\end{point}
\end{parsec}

\subsection{Effect modules}
\begin{parsec}%
\begin{point}%
An effect algebra of predicates in an effectus
    will have an action of the effect monoid of the scalars,
    turning them into an effect module (see \sref{dfn-mandso}):
\end{point}
\begin{point}[dfn-effect-module]{Definition}%
Suppose~$M$ is an effect monoid.
An \Define{effect module} $E$ over~$M$ \cite{corefl}
    is an effect algebra together with an operation
            $M \times E \to E$
            denoted by~$(\lambda, a) \mapsto \lambda \cdot a$
    such that for all~$a,b \in E$ and~$\lambda,\mu \in M$, we have
\begin{enumerate}
\item
    $(\lambda \odot \mu) \cdot a = \lambda \cdot (\mu \cdot a)$;
\item
    if~$a \perp b$,
     then~$\lambda \odot a \perp \lambda \odot b$
     and~$(\lambda \odot a) \ovee (\lambda\odot b) = \lambda \odot(a \ovee b)$;
\item
    if~$\lambda \perp \mu$,
     then~$\lambda \odot a \perp \mu \odot a$
     and~$(\lambda \odot a) \ovee (\mu \odot a) = (\lambda \ovee \mu) \odot a$
            \emph{and}
\item
    $1 \odot a = a$.
\end{enumerate}
(Categorically: an effect module over~$M$
    is an~$M$-action.)
An effect algebra homomorphism~$f\colon E \to F$
    between effect modules over~$M$
    is an $M$-\Define{effect module homomorphism}
    provided~$\lambda \cdot f(a) = f(\lambda \cdot a)$
    for all~$\lambda \in M$ and~$a \in E$.
Write~$\Define{\mathsf{EMod}_M}$
    for the category of effect modules over~$M$
    with effect module homomorphisms between them.
\end{point}
\begin{point}{Examples}%
There are many effect modules.
\begin{enumerate}
\item
Every effect algebra is an effect module over
    the two-element effect monoid $2$.
    (In fact $\mathsf{EA} \cong \mathsf{EMod}_{2}$.)
The only effect module over the one-element effect monoid~$1$,
    is the one-element effect algebra~$1$ itself.
\item
If~$V$ is an ordered real vector space with positive order unit~$u$,
    then~$[0,u]$ is an effect module over~$[0,1]$.
In fact, every effect module over~$[0,1]$
    is of this form \cite{gudder1998representation}.
See also \cite[Thm.~3]{jacobs2016expectation}
    for the stronger categorical equivalence.
\end{enumerate}
\end{point}
\end{parsec}

\section{Effectus}
An effectus comes in two guises:
    axiomatizing either a category of total maps
    or a category of partial maps.
We will start of with the total form as it has the simplest axioms.
Later we will prefer to work with the partial form.
\begin{parsec}%
\begin{point}{Definition}%
A category $C$ is said to be an \Define{effectus in total form}
    \cite{effintro,newdirections,statesofconvexsets}
    if
\begin{enumerate}
\item $C$ has finite coproducts and a final object~$1$;
\item all diagrams of the following form are pullbacks
\begin{equation}\label{pullbacks}
\xymatrix{
    X+Y \ar[r]^{\id+!} \ar[d]_{!+\id} & X+1\ar[d]^{!+\id} \\
    1+Y\ar[r]_{\id+!} & 1+1
    }
    \qquad
\xymatrix{
    X \ar[r]^{!} \ar[d]_{\kappa_1} & 1 \ar[d]^{\kappa_1} \\
    X+Y\ar[r]_{!+!} & 1+1
    }
\end{equation}
\item\label{eff-joint-monicity} and the following two arrows are jointly monic
    \begin{equation*}
        \xymatrix@C+2pc  {
            1+1+1  \ar@/^/[r]^{[\kappa_1,\kappa_2,\kappa_2]}
                    \ar@/_/[r]_{[\kappa_2,\kappa_1,\kappa_2]} & 1+1.
        }
    \end{equation*}
\end{enumerate}
An arrow~$X \to Y+1$ is called a \Define{partial map}
$X \mathrel{\Define{\pto}} Y$.
\begin{point}%
One interested in physics, should think of the objects
    of an effectus as physical systems and its arrows as
    the physical operations between them.
    The final object~$1$ is the physical system with a single state.
The coproduct~$X+Y$ is the system that can be prepared as~$X$ or as~$Y$.

Studying programming languages, one would do better thinking of
    the objects of an effectus as data types and
    its arrows as the allowed operations between them (semantics of programs).
The final object~$1$ is the unit data type.
The coproduct~$X + Y$ is the union data type of~$X$ and~$Y$.
\end{point}
\begin{point}%
Our main example of an effectus in total form
    is the category~$\op{\vN}$
    of von Neumann algebras with completely positive normal unital
    maps in the opposite direction.
(To see~$\op\vN$ is an effectus in total form,
    adapt the proof of \sref{emod-effectus}.)
The partial maps correspond to contractive maps.
We list more examples later on.
Let~$C$ be an effectus in total form.
Given two arrows~$f\colon X \to Y+1$
and~$g \colon Y \to Z+1$ (i.e.~partial maps~$X \pto Y$ and~$Y \pto Z$)
    their composition as partial maps
    is defined as~$g \hafter f \equiv  [g, \kappa_2] \after f$.
Write~$\Define{\Par C}$ for the \Define{category of partial maps},
    which has the same objects
    as~$C$, but as arrows~$X \to Y$ in~$\Par C$
    we take arrows of the form~$X \to Y+1$ in~$C$,
    which we compose using~$\hafter$
    and with identity on~$X$ in~$\Par C$
    given by~$\kappa_1 \colon X \to X+1$.\footnote{In categorical
            parlance: $\Par C$ is the Kleisli category of
            the monad~$(\ )+1\colon C \to C$.}
The category~$\Par C$ is not an effectus in total form --- instead it
    is an effectus \emph{in partial form}.
\end{point}
\end{point}
\begin{point}{Definition}%
A category~$C$ is called an \Define{effectus in partial form}
    \cite{effintro,kentapartial} if
\begin{enumerate}
\item
    $C$ is a finPAC \cite{kentapartial} (cf.~\cite{arbib}) --- that is:
    \begin{enumerate}
        \item 
            $C$ has finite coproducts $(+,0)$;
        \item $C$ is PCM-enriched --- that is:
            \begin{enumerate}
            \item
            every homset $C(X,Y)$ has a partial binary operation~$\ovee$
                    and distinguished~$0 \in C(X,Y)$
                    that turns~$C(X,Y)$ into a partial commutative monoid,
                    see \sref{dfn-pcm}, and
            \item
            if $f \perp g$ then both
                $(h \after f) \perp (h \after g)$ and
                $(f \after k) \perp (g \after k)$ \emph{and}
            \begin{equation*}
                 h \after (f \ovee g) = 
                (h \after f) \ovee (h \ovee g)\qquad
                (f \ovee g) \after k = 
                (f \after k) \ovee (g \after k)
            \end{equation*}
                for any~$f,g \in X \to Y$,
                $h\colon Y \to Y'$
                and~$k \colon X'\to X$;
            \end{enumerate}
        \item
            (compatible sum)
            for any~$b\colon X \to Y + Y$ we have
            $\pproj_1 \after b \perp \pproj_2 \after b$,
            where~$\Define{\pproj_i}\colon Y + Y \to Y$
            are \Define{partial projectors} defined
            by~$\pproj_1 \equiv [\id, 0]$
            and~$\pproj_2 \equiv [0, \id]$ \emph{and}
        \item
            (untying) if~$f\perp g$,
            then~$\kappa_1\after f \perp \kappa_2 \after g$ \emph{and}
    \end{enumerate}
    \item it has effects --- that is: there is a distinguished object~$I$
            such that
    \begin{enumerate}
        \item for each object~$X$, the PCM~$C(X,I) \equiv \Define{\Pred X}$
            is an effect algebra, see \sref{dfn-ea}
            --- in particular~$C(X,I)$
                has a maximum element~$1$;
        \item if~$1 \after f \perp 1 \after g$,
            then~$f \perp g$ \emph{and}
        \item if~$1 \after f = 0$ then~$f = 0$.
    \end{enumerate}
\end{enumerate}
A map~$f\colon X \to Y$ is called \Define{total} if~$1 \after f = 1$.
\begin{point}{Remark}%
The untying axiom is redundant: it follows from the others.
We include it, as it is part
    of the definition of a finPAC.
\end{point}
\begin{point}%
At first glance an effectus in partial form seems
    to have a much richer structure than an effectus in total form.
This is not the case ---
    effectuses in total and partial form are two views
    on the same thing: \cite{kentapartial,effintro}
\end{point}
\end{point}
\begin{point}[cho-thm]{Theorem (Cho)}%
Let~$C$ be an effectus in total form
and~$D$ be an effectus in partial form.
\begin{enumerate}
\item
The category~$\Par C$ is an effectus in partial form
        with~$I = 1$.
\item
The total maps of~$D$ form an effectus in total form~$\Tot D$.
\item
    Nothing is lost:
    $\Par \Tot D \cong D$ and~$\Tot \Par C \cong C$.
\end{enumerate}
\begin{point}%
We postpone the proof to \sref{proof-cho-thm}.
\end{point}
\end{point}
\end{parsec}
\subsection{From partial to total}
\begin{parsec}%
\begin{point}%
We will first show that the subcategory of
    total maps of an effectus in partial form
    is an effectus in total form.
This proof and especially the demonstration
    that the squares in \eqref{pullbacks} are pullbacks,
    will elucidate the axioms of an effectus in total form
    and will make the proof in the opposite direction more palatable.
\end{point}
\begin{point}[coproj-total]{Lemma}%
In an effectus in partial form,
    coprojections are total.
\begin{point}{Proof}%
Note
$1 = 1 \after \id = (1 \after [\id, 0]) \after \kappa_1
                    \leq 1 \after \kappa_1 \leq 1$.
Indeed~$1 \after \kappa_1 = 1$. \qed
\end{point}
\end{point}
\begin{point}[cotupl-pcm]{Proposition}%
In an effectus in partial form,
the cotupling bijection~$(f,g) \mapsto [f,g]$
    is a PCM-isomorphism ---
    that is:
\begin{enumerate}
\item
    $[f,g] \perp [f',g']$ if and only if
        $f \perp f'$ and~$g \perp g'$;
\item
    if~$[f,g] \perp [f', g']$,
    then~$[f,g] \ovee [f',g'] = [f \ovee f', g\ovee g']$ \emph{and}
\item
    $[0,0] = 0$.
\end{enumerate}
Furthermore~$[1,1]=1$ for maps into~$I$,
so the cotupling map is an effect algebra
isomorphism~$\Pred (X) \times \Pred (Y) \cong \Pred (X+Y) $.
\begin{point}{Proof}%
First we show~$[h,l] = [h,0] \ovee [0,l]$.
By the compatible sum axiom
\begin{equation*}
    [h, 0] \ = \ 
    \pproj_1 \after (h + l)
    \ \perp\  \pproj_2 \after (h + l)
    \ = \ [0, l].
\end{equation*}
By PCM-enrichtment
$([h, 0] \ovee [0, l]) \after \kappa_1
         =  ([h, 0] \after \kappa_1) \ovee
        ([0, l] \after \kappa_1)  = h$.
Similarly~$([h, 0] \ovee [0, l]) \after \kappa_2 = l$.
Thus indeed~$[h,l] = [h,0] \ovee [0,l]$.

Assume~$[f,g] \perp [f',g']$.
    By PCM-enrichment
    we have~$f = [f,g] \after \kappa_1 \perp [f',g'] \after \kappa_1 = f'$.
Similarly~$g \perp g'$.
Conversely, assume~$f \perp f'$ and~$g \perp g'$.
Again, by PCM-enrichment~$
[f,0] = f  \after \pproj_1 \perp f' \after \pproj_1 = [f', 0]$
    and~$[f\ovee f', 0 ] = [f,0] \ovee [f', 0]$.
Similarly~$[0,g \ovee g'] = [0,g] \ovee [0,g']$.
Putting it all together
\begin{align*}
[f, g] \ovee [f', g']
&\ = \ 
 [f, 0] \ovee [0,g] \ovee [f', 0] \ovee [0, g'] \\
 &\ = \ 
 [f\ovee f', 0]\ovee [0, g\ovee g'] \\
 &\ = \ 
 [f\ovee f', g \ovee g'].
\end{align*}
To show cotupling is a PCM-isomorphism,
    it only remains to be shown~$[0,0]=0$.
As~$0 \after \kappa_1 = 0$
    and~$0 \after \kappa_2 = 0$,
    we indeed have~$0 = [0,0]$.
Similarly by \sref{coproj-total} we have~$1 \after \kappa_1 = 1$
    and~$1 \after \kappa_2 = 1$,
    so~$1 = [1,1]$. \qed
\end{point}
\end{point}

\begin{point}%
The coproduct in an effectus in partial form
is almost a (bi)product:
\end{point}

\begin{point}[coprod-prod]{Proposition}%
In an effectus in partial form, we have a correspondence
\begin{prooftree}
\AxiomC{$h\colon Z \to X+Y$}
\doubleLine
\UnaryInfC{$f\colon Z \to X \quad g\colon Z \to Y \quad 1 \after f \perp 1 \after g$}
\end{prooftree}
as follows:
\begin{quote}
for every~$f\colon Z \to X$
    and~$g\colon Z \to Y$
    with~$1 \after f \perp 1 \after g$,
    there is a unique map~$\Define{\langle f, g\rangle} \colon Z \to X +Y$
    such that~$\pproj_1 \after \langle f, g \rangle = f$
    and~$\pproj_2 \after \langle f, g \rangle = g$,
    where~$\pproj_1 = [\id,0]$ and~$\pproj_2=[0,\id]$.
In fact~$\langle f, g\rangle = (\kappa_1 \after f) \ovee (\kappa_2 \after g)$.
\end{quote}
Conversely~$h = \langle \pproj_1 \after h, \pproj_2 \after h \rangle$
    for any~$h \colon Z \to X+Y$.
\begin{point}{Proof}%
Assume~$f\colon Z \to X$ and~$g\colon Z \to Y$ with~$1\after f \perp 1\after g$.
By \sref{coproj-total},
we have~$1 \after \kappa_1 \after f = 1 \after f \perp 1 \after g =
        1 \after \kappa_2 \after g$.
Thus~$\kappa_1 \after f \perp \kappa_2 \after g$.
Define~$\langle f, g\rangle = (\kappa_1 \after f) \ovee (\kappa_2 \after g)$.
By the PCM-enrichedness, we have
\begin{align*}
\pproj_1 \after \langle f, g\rangle 
&\  =\  [\id, 0] \after ((\kappa_1 \after f) \ovee (\kappa_2 \after g)) \\
 &\  =\  ([\id, 0] \after \kappa_1 \after f) \ovee 
    ([\id, 0] \after \kappa_2 \after g) \\
    & \ =\  f \ovee (0 \after g) \ = \ f.
\end{align*}
Similarly~$\pproj_2 \after \langle f, g \rangle = g$.
To show uniqueness, assume~$f = \pproj_1 \after h$
    and~$g = \pproj_2 \after h$ for some (other)
    $h\colon Z \to X+Y$.
Note~$\kappa_1 \after \pproj_1 = [\kappa_1, 0]$
and~$\kappa_2 \after \pproj_2 = [0, \kappa_2]$,
so by~\sref{cotupl-pcm} we have~$(\kappa_1 \after \pproj_1)
    \ovee (\kappa_2 \after \pproj_2) = [\kappa_1, \kappa_2] = \id$,
    hence
\begin{align*}
    \langle f, g\rangle & \ = \ 
    \langle \pproj_1 \after h, \pproj_2 \after h \rangle \\
    & \ = \ (\kappa_1 \after\pproj_1 \after h) 
    \ovee (\kappa_2 \after\pproj_2 \after h)  \\
    & \ = \ ((\kappa_1 \after\pproj_1 )
    \ovee (\kappa_2 \after\pproj_2 ))  \after h \\
    & \ = \  h,
\end{align*}
which demonstrates uniqueness.

Finally, let~$h\colon Z\to X+Y$ be any map.
Note~$1 \after \pproj_1 = [1,0]$
    and~$1 \after \pproj_2 = [0,1]$.
So by PCM-enrichment~$1 \after \pproj_1 \after h \perp 1 \after \pproj_2 \after h$ and so~$\pproj_1 \after h \perp \pproj_2 \after h$.
By the previous
$\langle \pproj_1 \after h, \pproj_2 \after h\rangle
= (\kappa_1 \after \pproj_1 \after h) \ovee
 (\kappa_2 \after \pproj_2 \after h) 
 = h $ as desired.\qed
\end{point}
\end{point}

\begin{point}[eff-prod-rules]{Exercise}%
Show that in an effectus in partial form, we have
\begin{enumerate}
    \item~$[a,b] \after \langle f, g \rangle = (a \after f) \ovee (b \after g)$;
    \item~$1 \after \langle f, g\rangle = (1 \after f) \ovee(1 \after g)$;
    \item~$(k+l) \after \langle f, g\rangle
        = \langle k \after f, l \after g \rangle$ \emph{and}
    \item~$\langle f, g\rangle \after k = \langle f \after k,
                                g \after k \rangle$.
\end{enumerate}
\end{point}

\begin{point}[eff-partial-to-total]{Theorem}%
Let~$C$ be an effectus in partial form.
The total maps of~$C$ are an effectus in total form.
\begin{point}{Proof}%
The total maps form a subcategory: $1 \after \id = 1$
    and $1 \after f \after g = 1 \after g = 1$ for composable total~$f,g$.
In \sref{coproj-total} we saw coprojections are total.
By \sref{cotupl-pcm}
    we have~$1 \after [f,g] = [1 \after f, 1 \after g] = [1,1] = 1$
    for total~$f\colon X \to Z$ and~$g\colon Y \to Z$,
    so~$\Tot C$ has binary coproducts.
The unique map~$!\colon 0 \to X$ must be total
    as~$1 \after ! = 1$ is the unique map~$0 \to I$,
    so~$\Tot C$ has initial object~$0$, hence all finite coproducts.
\end{point}
\begin{point}[one-m-is-id]%
To show~$I$ is the final object of~$\Tot C$,
    we need~$\id_I = 1$.
As~$C(I,I)$ is an effect algebra~$1 = \id \ovee \id^\perp$
    for some~$\id^\perp$.
So by PCM-enrichtment~$1 = 1 \after 1 = (1 \after \id) \ovee (1 \after\id^\perp) = 
1 \ovee (1 \after \id^\perp)$.
By the zero--one axiom~$1 \after \id^\perp = 0$.
So~$\id^\perp = 0$ and indeed~$\id = 1$.
To show~$I$ is final in~$\Tot C$, pick any object~$X$ in~$\Tot C$.
We claim~$1 \colon X \to I$ is the unique total map.
Indeed, by the previous $1 = \id_I \after 1 = 1 \after 1$, so~$1$ is total
and if~$h\colon X \to I$ is total, then~$1=1 \after h = \id_I \after h = h$.
\end{point}
\begin{point}%
To show the square on the left of \eqref{pullbacks} is a pullback
    in~$\Tot C$,
assume~$f\colon Z \to X+I$ 
and~$g\colon Z \to I+Y$
are total maps with~$(\id+1) \after g = (1+\id) \after f$.
By~\sref{coprod-prod}, $f = \langle \alpha, a \rangle$
    and~$g = \langle b, \beta \rangle$
    for some maps~$\alpha\colon Z \to X$, $\beta\colon Z \to Y$
        and~$a,b\colon Z \to I$ in~$C$.
\begin{equation*}
\xymatrix@C+1pc@R-1pc{ 
Z \ar@/^1pc/[rrd]^{\langle\alpha,a \rangle}
    \ar@/_1pc/[rdd]_{\langle b, \beta\rangle}
    \ar@{.>}[rd]|{\langle \alpha, \beta\rangle}
    \\
    &  X+Y \ar[r]^{\id+1} \ar[d]_{1+\id} & X+I\ar[d]^{1+\id} \\
    &I+Y\ar[r]_{\id+1} & I+I
    }
\end{equation*}
By~\sref{eff-prod-rules},
    we have~$1 = 1 \after f = 1 \after \langle \alpha, a\rangle
                = (1 \after \alpha) \ovee a$
        and so~$a^\perp = 1\after \alpha$.
Similarly~$b^\perp = 1 \after \beta$.
Again, using~\sref{eff-prod-rules},
    we see
\begin{equation*}
    \langle b, 1 \after \beta \rangle \ =\ 
    (\id + 1) \after \langle b, \beta \rangle \ =\ 
    (\id + 1) \after g \ =\ 
    (1 + \id) \after f
               \  = \ \langle 1 \after \alpha, a\rangle,
\end{equation*}
so~$1 \after \beta = a = (1 \after \alpha)^\perp$,
hence~$1 \after \beta \perp 1 \after \alpha$,
so~$\langle \alpha,\beta\rangle \colon Z \to X+Y$ exists
    and is total as~$1 \after \langle \alpha,\beta\rangle = 
        (1 \after \alpha) \ovee (1 \after \beta) = 1$.
We compute~$(\id + 1) \after \langle\alpha, \beta\rangle = \langle \alpha,
    1 \after \beta\rangle = \langle \alpha, a\rangle = f$.
    Similarly~$(1 + \id) \after \langle \alpha, \beta\rangle = g$.
    Assume~$h\colon Z \to X+Y$ is any (other) map with~$(1 +\id) \after h
        = g$ and~$(\id+1) \after h = f$.
Say~$h = \langle h_1, h_2 \rangle$.
Then~$\langle \alpha, a\rangle = f= (\id + 1)\after h = \langle h_1, 1 \after h_2 \rangle$, so~$\alpha = h_1$. Similarly~$\beta=h_2$.
Thus~$h = \langle \alpha, \beta\rangle$,
    which shows our square is indeed a pullback.
\end{point}
\begin{point}%
To show the square on the right of \eqref{pullbacks} is a pullback
    in~$\Tot C$,
assume (using \sref{coprod-prod})
$\langle \alpha, \beta \rangle\colon Z \to X+Y$
is some total map
with~$(1+1) \after \langle\alpha,\beta\rangle = \kappa_1 \after 1$.
    \begin{equation*}
\xymatrix@C+1pc@R-1pc{ 
    Z \ar@{.>}@/^1pc/[rrd]^{1}
    \ar@/_1pc/[rdd]_{\langle \alpha,\beta\rangle}
    \ar@{.>}[rd]|{\alpha}\\
    &X \ar[r]^{1} \ar[d]_{\kappa_1} & I \ar[d]^{\kappa_1} \\
    &X+Y\ar[r]_{1+1} & I+I
    }
    \end{equation*}
With \sref{eff-prod-rules},
we see~$\langle 1 \after \alpha, 1 \after \beta \rangle
        = (1 + 1) \after \langle \alpha, \beta \rangle
        = \kappa_1 \after 1
        = \langle 1, 0 \rangle$.
So~$\alpha$ is total and~$\beta=0$.
Hence~$\langle \alpha, \beta\rangle = \langle \alpha, 0\rangle
        = \kappa_1 \after \alpha$ as desired.
\end{point}
\begin{point}%
    Finally, to show~$m_1\equiv [\kappa_1,\kappa_2,\kappa_2], m_2 \equiv [\kappa_1,\kappa_2,\kappa_2]\colon
    I+I+I \to I+I$ are jointly monic,
    let~$f_1 \equiv \langle a_1,b_1,c_1\rangle,f_2\equiv \langle a_2,b_2,c_2\rangle\colon X\to I+I+I$ be any total maps
    with~$m_1 \after f_1 = m_1 \after f_2$
    and~$m_2 \after f_1 = m_2 \after f_2$.
Then
\begin{equation*}
    a_1 \ = \ [\id, 0, 0] \after f_1
        \ = \ \pproj_1 \after m_1 \after f_1
        \ = \ \pproj_1 \after m_1 \after f_2
        \ = \ a_2.
\end{equation*}
and similarly from the equality involving~$m_2$, we get~$b_1 = b_2$.
As~$f_1$ is total, we have~$1 = 1 \after f_1=  a_1 \ovee b_1 \ovee c_1$,
    so~$c_1 = (a_1 \ovee b_1)^\perp$.
With the same reasoning~$c_2 = (a_2 \ovee b_2)^\perp$.
Thus~$c_1 = c_2$ and so~$f_1 = f_2$, as desired. \qed
\end{point}
\end{point}
\end{parsec}

\subsection{From total to partial}
\begin{parsec}%
\begin{point}%
Let~$C$ be an effectus in total form.
In this section we will show that~$\Par C$ is an effectus in partial form.
Before we get to work, it is helpful to discuss the axioms
    of an effectus in total form, now we have some experience
    with an effectus in partial form.
\begin{enumerate}
\item
In \sref{coprod-prod} we saw that the coproduct in an effectus
    (in partial form) is almost a biproduct.
This structure is hidden (for the most part)
    in the left pullback square of
    \eqref{pullbacks}, which
    allows the formation of~$\langle \alpha, \beta \rangle$ given
    partial maps~$\alpha,\beta$.
\item
The right pullback square of \eqref{pullbacks}
    is used to extract a total map in~$C$
    from a partial map~$f$ in~$\Par C$ that is total (i.e.~$1 \hafter f = 1$).
\item
The joint-monicity
    of~$[\kappa_1,\kappa_2,\kappa_2]$
    and~$[\kappa_2,\kappa_1,\kappa_2]$
    will imply the joint monicity of~$\pproj_1$ and $\pproj_2$,
    which is required for uniqueness of the partial sum of partial maps.
\end{enumerate}
To prove the theorem, we need to study pullbacks:
    first in any category,
    then in an effectus~$C$ in total form
    and finally in~$\Par C$.
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
    We start with two classic facts about pullbacks.
\end{point}
\begin{point}{Exercise}%
Show that if we have any pullback square --- say
\begin{equation*}
    \vcenter{\vbox{\xymatrix@R-1pc{
        {P\ } \pullback \ar[r]^{m_1} \ar[d]_{m_2}
        & B \ar[d]^f
                \\ {A\ } \ar[r]_{g}
    & X}}} \text{,}
\end{equation*}
then~$m_1$ and~$m_2$ are jointly-monic.
\end{point}

\begin{point}[pullback-lemma]{Exercise}%
Show the \Define{pullback lemma} --- that is:
    if we have a commuting diagram
\begin{equation*}
    \vcenter{\vbox{\xymatrix@R-1pc{
                A \ar[r]^f \ar[d]_k
                & B \ar[r]^g \ar[d]_l
                & C \ar[d]^m
                \\ X \ar[r]_{f'}
                & Y \ar[r]_{g'}
                & Z
    }}} \text{,}
\end{equation*}
\end{point}
then we have the following two implications.
\begin{enumerate}
\item
If the left and right inner squares are pullbacks,
    then so is the outer square.
\item
If the outer square is a pullback
    and~$l$ and~$g$ are jointly monic,
    then the left inner square is a pullback.
\end{enumerate}
\end{parsec}

\begin{parsec}%
\begin{point}%
It is well-known that monos are stable under pullbacks ---
that is:
\begin{equation*}
    \text{if} \quad
    \vcenter{\vbox{\xymatrix@R-1pc{
                {P\ } \pullback \ar[r]^n \ar[d]_g
        & X \ar[d]^f
                \\ {A\ } \ar@{>->}[r]_{m}
    & B}}} ,
    \quad \text{then} \quad
    \vcenter{\vbox{\xymatrix@R-1pc{
                {P\ } \pullback \ar@{>->}[r]^n \ar[d]_g
        & X \ar[d]^f
                \\ {A\ } \ar@{>->}[r]_{m}
    & B}}}.
\end{equation*}
We will need an analogous result for jointly monic maps.
\end{point}
\begin{point}[joint-monicity-stable]{Lemma}%
If the pairs~$(m_1,m_2)$, $(n_1,g_1)$, $(n_2,g_2)$ and~$(h_1,h_2)$
in the following commuting diagram
are jointly-monic (for instance: if they span pullback squares),
then~$(n_1 \after h_1, n_2 \after h_2)$ is jointly-monic as well.
\begin{equation*}
    \xymatrix@C+1pc{
        P \ar[r]^{h_1} \ar[d]_{h_2}
        &P_1\ar[r]^{n_1} \ar[d]^{g_1}
        &X_1 \ar[d]^{f_1}
        \\ P_2\ar[r]_{g_2} \ar[d]_{n_2}
        & A \ar[r]_{m_1} \ar[d]^{m_2}
        & B_1 
        \\ X_2 \ar[r]_{f_2}
        & B_2
    }
\end{equation*}
\begin{point}{Proof}%
To show joint monicity of~$n_1 \after h_1$ and~$n_2 \after h_2$,
assume~$\alpha_1,\alpha_2  \colon Z \to P$
    are maps with~$
        n_1 \after h_1 \after \alpha_1
        = n_1 \after h_1 \after \alpha_2$
    and~$n_2 \after h_2 \after \alpha_1
        = n_2 \after h_2 \after \alpha_2$.
To start
\begin{equation*}
    m_1 \after g_1 \after h_1 \after \alpha_2
    \ =\  f_1 \after n_1 \after h_1 \after \alpha_2 
    \ =\  f_1 \after n_1 \after h_1 \after \alpha_1 
            \ =\  m_1 \after g_1 \after h_1 \after \alpha_1.
\end{equation*}
Reasoning on the other side of the diagram, we find
\begin{align*}
    m_2 \after g_1 \after h_1 \after \alpha_2
    &\ =\  m_2 \after g_2 \after h_2 \after \alpha_2 \\ 
    &\ =\  f_2 \after n_2 \after h_2 \after \alpha_2 \\ 
    &\ =\  f_2 \after n_2 \after h_2 \after \alpha_1 \\ 
    &\ =\  m_2 \after g_2 \after h_2 \after \alpha_1 \\ 
    &\ =\  m_2 \after g_1 \after h_1 \after \alpha_1.
\end{align*}
So by joint monicity of~$m_1$ and~$m_2$,
    we conclude~$g_1 \after h_1 \after \alpha_2
                = g_1 \after h_1 \after \alpha_1$.
So by the joint monicity of~$n_1$ and~$g_1$
    (and~$n_1 \after h_1 \after \alpha_2
    = n_1 \after h_1 \after \alpha_1$ by assumption),
    we conclude~$h_1 \after \alpha_1 = h_1 \after \alpha_2$.
Reasoning in the same way mirrored over the diagonal,
    we find~$h_2 \after \alpha_1 = h_2 \after \alpha_2$.
Thus, by joint monicity of~$h_1$ and~$h_2$, we conclude~$\alpha_1 = \alpha_2$, as desired. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[tot-pullbacks]{Proposition}%
The following squares are pullbacks in an effectus in total form.
\begin{equation*}
    \xymatrix{
        X+A \pullback \ar[r]^{\id+f} \ar[d]_{g + \id}
        & X+B \ar[d]^{g+\id}
        \\ Y+A \ar[r]_{\id+f}
        & Y+B
    } \qquad
    \xymatrix{
        X \pullback \ar[d]_{\kappa_1} \ar[r]^{f}
        & Y \ar[d]^{\kappa_1}
        \\
        X+A \ar[r]_{f+g}
        & Y+B
    }
\end{equation*}
\begin{point}{Proof}%
To start with the left square, consider the following commuting diagram.
\begin{equation*}
    \xymatrix{
        X+A \ar@{}[rd]|{(1)} \ar[r]^{\id+f} \ar[d]_{g + \id}
        & X+B \ar@{}[rd]|{(2)} \ar[d]^{g+\id} \ar[r]^{\id+!}
        & X+1 \ar[d]^{g+\id}
        \\ Y+A \ar@{}[rd]|{(3)} \ar[r]_{\id+f} \ar[d]_{!+\id}
        & Y+B \ar@{}[rd]|{(4)} \ar[r]_{\id+!} \ar[d]^{!+\id}
        & Y+1 \ar[d]^{!+\id}
        \\ 1+A \ar[r]_{\id+f}
        & 1+B \ar[r]_{\id+!}
        & 1+1
    }
\end{equation*}
We want to show (1) is a pullback.
The inner square~(4) and right rectangle~(2,4) are pullbacks by axiom.
Thus the inner square~(2) is also a pullback
    by the pullback lemma, see \sref{pullback-lemma}.
With the same reasoning, we see square (3) is a pullback.
Thus by the pullback lemma, it is sufficient to show that
    left rectangle (1,3) is a pullback.
The left rectangle is indeed a pullback
as both the outer square (1,2,3,4)
    and the right rectangle (2,4) are pullbacks.

For the right square, we consider the following diagram.
\begin{equation*}
    \xymatrix{
         X \ar[r]^f \ar[d]_{\kappa_1}
            %\ar@{}[rd]|{(1)}
        & Y \ar[r]^{!} \ar[d]^{\kappa_1}
            %\ar@{}[rd]|{(2)}
        &1 \ar[d]^{\kappa_1}
        \\ X+A \ar[r]_{f+g}
        & Y+B \ar[r]_{!+!}
        & 1+1
    }
\end{equation*}
The inner right and outer squares are pullbacks by axiom.
So the inner left square is also a pullback by the pullback lemma, as desired.
    \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}{Definition}%
Assume~$C$ is an effectus in total form.
For a map~$f\colon X \to Y$,
    write~$\hat{f} = \kappa_1 \after f \colon X \to Y+1$.
    (This is the Kleisli embedding~$C \to \Par C$.)
\end{point}
\begin{point}[par-c-coprod]{Exercise}%
Assume~$C$ is an effectus in total form.
Show that if
\begin{equation*}
\kappa_1 \colon X \to X+Y \leftarrow Y \colon \kappa_2
\end{equation*}
    is a coproduct in~$C$, then~
\begin{equation*}
    \hat\kappa_1 \colon X \pto X+Y \pfrom Y \colon \hat\kappa_2
\end{equation*}
    is a coproduct in~$\Par C$.
Show~$0$ is also the initial object of~$\Par C$.
\begin{point}{Beware}%
Cotupling in~$C$ and~$\Par C$ coincide:
$[f,g]_{C} = [f,g]_{\Par C}$
for any (properly typed) partial maps~$f,g$.
Also, we have the following rule for the sum of maps:
    $\widehat{f+_C g} = \hat{f} +_{\Par C} \hat{g}$.
    However, in general
    \begin{equation*}
    [\kappa_1 \after f, \kappa_2 \after g] \ =\  f+_C g \ \neq\  f +_{\Par C} g
        \ =\  [[\kappa_1,\kappa_3] \after f,
            [\kappa_2, \kappa_3] \after g].
    \end{equation*}
\end{point}
\end{point}
\begin{point}[par-pullbacks]{Proposition}%
Assume~$C$ is an effectus in total form.
The following squares are pullbacks in~$\Par C$.
\begin{equation*}
    \xymatrix{
        X+A \pullback \ar@^{>}[r]^{\id+\hat{f}} \ar@^{>}[d]_{\hat{g} + \id}
        & X+B \ar@^{>}[d]^{\hat{g}+\id}
        \\ Y+A \ar@^{>}[r]_{\id+\hat{f}}
        & Y+B
    } \qquad
    \xymatrix{
        A+X \pullback \ar@^{>}[r]^{\hat{f}+\id} \ar@^{>}[d]_{\pproj_1}
        & B+X \ar@^{>}[d]^{\pproj_1}
        \\ A \ar@^{>}[r]_{\hat{f}}
        & B
    }
\end{equation*}
\begin{point}{Proof}%
It is sufficient to show that the following squares
are pullbacks in~$C$.
\begin{equation*}
    \xymatrix{
        X+(A+1) \ar[r]^{\id + (f+\id)} \ar[d]_{g+ \id}
        & X+(B+1) \ar[d]^{g+\id}
        \\ Y+(A+1) \ar[r]_{\id+(f +\id)}
        & Y+(B+1)
    } \qquad
    \xymatrix{
        A+(X+1) \ar[r]^{f+\id} \ar[d]_{\id+!}
        & B+(X+1)  \ar[d]^{\id+!}
        \\ A+1 \ar[r]_{f+\id}
        & B+1
    }
\end{equation*}
These are indeed pullbacks by~\sref{tot-pullbacks}. \qed
\end{point}
\end{point}
\begin{point}[zero-and-one-parc]{Definition}%
Assume~$C$ is an effectus in total form.
For arbitrary objects~$X,Y$ in~$C$,
    write~$0 \equiv \kappa_2 \after !\colon X \to Y+1$
    and~$1 \equiv \kappa_1 \after ! \equiv \hat! \colon X \to 1+1$.
\end{point}
\begin{point}{Exercise}%
    Show~$0$ is a zero object in~$\Par C$
        with unique zero map
        as in \sref{zero-and-one-parc}.
\end{point}
\begin{point}[pardp]{Proposition}%
Assume~$C$ is an effectus in total form
    and~$f$ is a map in~$\Par C$.
\begin{enumerate}
\item
If~$1 \hafter f = 1$,
    then~$f = \hat{g}$ for a unique~$g$ in~$C$.
\item
If~$0 \hafter f = 0$, then~$f = 0$.
\end{enumerate}
\begin{point}{Proof}%
Both points follow from the right pullback square of~\eqref{pullbacks}
 as follows.
\begin{equation*}
    \xymatrix@R-.8pc{
    X \ar@{.>}[rd]|g
    \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_f
        \\& Y \pullback
        \ar[r]_{!}
        \ar[d]^{\kappa_1}
    & 1
        \ar[d]^{\kappa_1}
    \\& Y+1
        \ar[r]_{!+!}
&1+1
}
\qquad
    \xymatrix@R-.8pc{
        X \ar@{.>}[rd]|{!}
    \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_f
        \\& 1 \pullback
        \ar[r]_{!}
        \ar[d]^{\kappa_2}
    & 1
        \ar[d]^{\kappa_2}
    \\& Y+1
        \ar[r]_{!+!}
&1+1
}
\end{equation*}
If~$1 \hafter f = 1$, then~$(!+!)\after f = \kappa_1 \after !$
    and so there is a unique~$g$ with~$f = \kappa_1 \after g$
    as shown above on the left.
For the other point, if~$1 \hafter f = 0$,
    then~$(!+!)\after f = \kappa_2 \after !$
    and so~$f = \kappa_2 \after !$ as shown above on the right. \qed
\end{point}
\end{point}
\begin{point}[pproj-joint-monicity]{Proposition}%
    Assume~$C$ is an effectus in total form.
    The partial projectors~$\pproj_1 \equiv [\id,0]$
        and~$\pproj_2 \equiv [0, \id]$
        are jointly monic in~$\Par C$.
\begin{point}{Proof}%
Consider the following commuting diagram in~$\Par C$.
\begin{equation*}
\xymatrix {
    X+Y \pullback
    \ar@/^1.5pc/[rr]^{\pproj_1}
    \ar@/_3pc/[dd]_{\pproj_2}
        \ar@^{>}[r]^{\id+\hat!}
        \ar@^{>}[d]_{\hat! + \id}
& X+1 \pullback
        \ar@^{>}[r]^{\pproj_1}
        \ar@^{>}[d]^{\hat! + \id}
& X
        \ar@^{>}[d]^{\hat!}
\\ 1+Y \pullback
        \ar@^{>}[r]_{\id+\hat!}
        \ar@^{>}[d]_{\pproj_2}
& 1+1
        \ar@^{>}[r]_{\pproj_1}
        \ar@^{>}[d]^{\pproj_2}
& 1
\\ Y
        \ar@^{>}[r]_{\hat!}
& 1
}
\end{equation*}
Each of the inner squares is a pullback by~\sref{par-pullbacks}.
The maps~$\pproj_1,\pproj_2\colon 1 + 1 \pto 1$
    are jointly monic,
    which is a reformulation
    of the joint monicity axiom of an effectus in total form.
Thus by \sref{joint-monicity-stable}
    the outer~$\pproj_1$ and~$\pproj_2$ are jointly monic. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[eff-total-to-partial]{Theorem}%
If~$C$ is an effectus in total form,
then~$\Par C$ is an effectus in partial form.
\begin{point}{Proof}%
In \sref{par-c-coprod}, we saw that~$\Par C$ has finite coproducts.
\begin{point}{PCM-enrichment, I}%
Assume~$f,g \colon X \pto Y$.
We say~$f \perp g$
whenever there is a \Define{bound}~$b\colon X \pto Y+Y$
    with~$\pproj_1 \hafter b = f$
    and~$\pproj_2 \hafter b = g$.
    (By \sref{pproj-joint-monicity}
    this~$b$ is unique if it exists.)
In this case, define~$f \ovee g = \nabla \hafter b$,
where $\Define{\nabla} \equiv [\id,\id]$.
We will show~$\ovee$ with~$0$
    as defined in \sref{zero-and-one-parc}
    forms a PCM.
Partial commutativity is obvious.
The map~$\kappa_1 \hafter f\colon X \pto Y+Y$
    is a bound for~$f \perp 0$ and
    so~$f \ovee 0 = \nabla \hafter \kappa_1 \hafter f = f$,
    which shows~$0$
    is indeed a zero for~$\ovee$.
Only partial associativity remains.
Assume~$f \perp g$ via bound~$b$
and~$f \ovee g \perp h$ via bound~$c$.
Note~$\nabla \hafter b = f \ovee g = \pproj_1 \hafter c$
and thus by the right pullback square of \sref{par-pullbacks} (see diagram below),
    there is a unique~$d\colon X \pto (Y+Y)+Y$
    with~$\pproj_1 \hafter d = b$ and~$(\nabla +\id)\hafter d = c$.
\begin{equation*}
    \xymatrix@R-.8pc{
    X \ar@^{.>}[rd]|d
        \ar@/^1pc/[rrd]^c
        \ar@/_1pc/[rdd]_b
        \\& (Y+Y)+Y \pullback
        \ar@^{>}[r]_{\nabla+\id}
        \ar@^{>}[d]^{\pproj_1}
    & Y+Y
        \ar@^{>}[d]^{\pproj_1}
    \\& Y+Y
        \ar@^{>}[r]_{\nabla}
&Y
}
\end{equation*}
The map $(\pproj_2 + \id) \hafter d$
    is a bound for~$g \perp h$,
    indeed:
\begin{align*}
    \pproj_1 \hafter (\pproj_2 + \id) \hafter d
    & \ =\  \pproj_2 \hafter \pproj_1 \hafter d 
    & \pproj_2 \hafter (\pproj_2 + \id) \hafter d
    & \ =\  \pproj_2 \hafter d
    \\
    &\ =\  \pproj_2 \hafter b
    && \ =\  \pproj_2 \hafter (\nabla + \id) \hafter d
    \\
    & \ =\  g
    && \ = \ \pproj_2 \hafter c\\
    &&& \ = \ h.
\end{align*}
We need one more ---
    $[\id,\kappa_2]\hafter d$ is a bound for~$f \perp g \ovee h$:
\begin{align*}
    \pproj_1 \hafter [\id,\kappa_2] \hafter d
        & \ = \ \pproj_1 \hafter \pproj_1 \hafter d
    & \pproj_2 \hafter [\id,\kappa_2]\hafter d & \ =\ \nabla \hafter (\pproj_2 + \id) \hafter d \\
        & \ = \ \pproj_1 \hafter b
        && \ =\  g \ovee h \\
        & \ = \ f.
\end{align*}
Finally,
we compute
\begin{equation*}
f \ovee (g \ovee h)
\ = \ \nabla \hafter [\id, \kappa_2] \hafter d
\ = \ \nabla \hafter (\nabla+ \id) \hafter d
\ = \ \nabla \hafter c
\ = \ (f \ovee g) \ovee h,
\end{equation*}
which shows the partial associativity.
Homsets of~$\Par C$ are indeed PCMs.
\end{point}
\begin{point}{PCM-enrichment, II}%
Assume~$f \perp g$ with bound~$b$.
It is easy to see~$b \hafter k$
    is a bound for~$f \hafter k \perp g \hafter k$
    and consequently~$(f \hafter k) \ovee (g \hafter k)
                = \nabla \hafter b \hafter k = 
                (f \ovee g) \hafter k$.
For the other side:
$(h + h) \hafter b$ is a bound for~$h \hafter f \perp h \hafter g$,
    indeed
\begin{align*}
    \pproj_1 \hafter (h+h) \hafter b
    &\ = \ 
    h\hafter \pproj_1 \hafter b \ =\  h \hafter f \\
    \pproj_2 \hafter (h+h) \hafter b
    &\ = \ 
    h\hafter \pproj_2 \hafter b\  =\  h \hafter g.
\end{align*}
And so~$(h \hafter f) \ovee (h \hafter g)
            = \nabla \hafter (h+h) \hafter b
            = h \hafter \nabla \hafter b = h \hafter (f \ovee g)$.
\end{point}
\begin{point}{FinPAC}%
We just saw~$\Par C$ is PCM-enriched.
We already know~$\Par C$ has coproducts.
The compatible sum axiom holds by definition of~$\perp$.
To show~$\Par C$ is a finPAC, only the untying axiom remains to be proven.
If~$f \perp g$ with bound~$b$,
then~$(\kappa_1 + \kappa_2) \hafter b$ is a bound for~$\kappa_1 \hafter f
    \perp \kappa_2 \hafter g$,
    which proves the untying axiom.
\end{point}
\begin{point}{Effect algebra of predicates}%
Pick any predicate~$p \colon X \to 1+1$.
We define~$p^\perp = [\kappa_2,\kappa_1]\after p$.
($p^\perp$ is~$p$ with swapped outcomes.)
We compute
\begin{align*}
    \pproj_1 \hafter \hat{p}
    &\ = \ [\id,\kappa_2]\after\kappa_1 \after p
        \  = \ p \\
        \pproj_2 \hafter \hat{p}
    &\ = \ [[\kappa_2, \kappa_1],\kappa_2]\after\kappa_1 \after p
        \  = \ [\kappa_2,\kappa_1]\after p \\
    \nabla \hafter \hat{p}
    &\ = \ [[\kappa_1,\kappa_1],\kappa_2]\after\kappa_1 \after p
        \  = \ \kappa_1 \after ! \ = \ 1.
\end{align*}
So~$\hat{p}$ is a bound for~$p \perp p^\perp$
and~$p \ovee p^\perp = 1$.
To show~$p^\perp$ is the unique orthocomplement,
    assume~$p \ovee q = 1$ for some (other)~$q$ via a bound~$b$.
Note~$1 \hafter b =\nabla \hafter b = 1$
    and so by \sref{pardp}
    we know~$b = \hat{c}$ for some~$c\colon X \to 1+1$.
    And so~$p = \pproj_1 \hafter b = [\id, \kappa_2]\after \kappa_1 \after c
                    = c$
                    hence
\begin{equation*}
q \ =\  \pproj_2 \hafter b \ =\  [[\kappa_2, \kappa_1],\kappa_2] \after
    \kappa_1\after c \ =\  [\kappa_2,\kappa_1]\after p \ =\  p^\perp.
\end{equation*}
To show~$\Pred X$ is an effect algebra,
it only remains to be proven that the zero--one axiom holds.
So assume~$1 \perp p$ via some bound~$b$. We want to show~$p=0$.
By the following instance of the right pullback square of~\eqref{pullbacks},
    we see~$b = \kappa_1 \after \kappa_1 \after !$.
\begin{equation*}
    \xymatrix@R-.8pc{
        X \ar@{.>}[rd]|{!}
    \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_b
        \\& 1 \pullback
        \ar@{=}[r]
        \ar[d]^{\kappa_1\after\kappa_1}
    & 1
        \ar[d]^{\kappa_1}
        \\& (1+1)+1
        \ar[r]_{[\id,\kappa_2]}
&1+1
}
\end{equation*}
Hence~$p = \pproj_2 \hafter b = [[\kappa_2,\kappa_1],\kappa_1]\after
                        \kappa_1 \after \kappa_1 \after ! = \kappa_2 \after ! = 0$.
\end{point}
\begin{point}{Final axioms}%
In \sref{pardp} we proved that~$f = 0$ whenever~$f = 0$.
It only remains to be shown that~$f \perp g$
    provided~$1 \after f \perp 1 \after g$.
As assume~$b$ is a bound for~$1 \after f \perp 1 \after g$.
We apply the right pullback square of \sref{par-pullbacks}
    twice  in succession as follows
    (using~$\pproj_2 \hafter c
                = \pproj_2 \hafter (\hat{!} + \id) \hafter c
                = \pproj_2 \hafter b = 1\hafter g$ for the right one.)
\begin{equation*}
    \xymatrix@R-.8pc{
        X \ar@^{.>}[rd]|{c}
    \ar@/^1pc/[rrd]^{b}
        \ar@/_1pc/[rdd]_f
        \\& Y+1 \pullback
        \ar@^{>}[r]^{\hat! + \id}
        \ar@^{>}[d]^{\pproj_1}
    & 1+1
        \ar@^{>}[d]^{\pproj_1}
        \\& Y
        \ar@^{>}[r]_{\hat!}
&1
} \qquad
    \xymatrix@R-.8pc{
        X \ar@^{.>}[rd]|{d}
    \ar@/^1pc/[rrd]^{c}
        \ar@/_1pc/[rdd]_g
        \\& Y+Y \pullback
        \ar@^{>}[r]^{\id + \hat!}
        \ar@^{>}[d]^{\pproj_2}
    & Y+1
        \ar@^{>}[d]^{\pproj_2}
        \\& Y
        \ar@^{>}[r]_{\hat!}
&1
}
\end{equation*}
Clearly~$\pproj_2 \hafter d = g$
    and~$
    \pproj_1 \hafter d
     =  \pproj_1 \hafter (\id + \hat! )\hafter d
     =  \pproj_1 \hafter c  =  f$, so~$d$ is a bound for~$f \perp g$,
     as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
We are ready to show the equivalence of effectuses in partial and total form.
\begin{point}[proof-cho-thm]{Proof of \sref{cho-thm}}%
The first point is shown in \sref{eff-total-to-partial}
    and the second in \sref{eff-partial-to-total}.
\begin{point}{$\Par \Tot D \cong D$}%
Let~$D$ be an effectus in partial form.
A map~$f\colon X \to Y$ in~$\Par \Tot D$
    is by definition a map~$f\colon X \to Y+1$
        in~$D$ with~$1 \after f= 1$.
Let~$P \colon \Par \Tot D \to D$
    denote the identity-on-objects map~$f \mapsto \pproj_1 \after f$.
This is a functor: clearly~$P\hat\id = P\kappa_1 = \id $ and
    if~$g\colon Y \to Z$ in~$\Par\Tot D$, then
\begin{align*}
    \pproj_1 \after (g \hafter f) & \ = \ 
    \pproj_1 \after [g, \kappa_2] \after f \\
    & \ = \ [\pproj_1 \after g, \pproj_1 \after \kappa_2] \after f \\
    & \ = \ [\pproj_1 \after g,  0] \after 
                \langle \pproj_1 \after f, \pproj_2 \after f\rangle \\
                & \ = \ \pproj_1 \after g  \after \pproj_1 \after f.
\end{align*}
The functor~$P$ is an isomorphism with inverse~$P' f \equiv \langle f, (1 \after f)^\perp\rangle$.
Indeed, we have
    $P P' f = \pproj_1 \after \langle f, (1 \after f)^\perp \rangle = f $
and
\begin{equation*}
    P' P f  \ =\  \langle \pproj_1 \after f, (1 \after \pproj_1 \after f)^\perp\rangle \ =\  (\kappa_1 \after \pproj_1 \after f) \ovee (\kappa_2 \after \pproj_1 \after f)^\perp\ =\  f.
\end{equation*}
\begin{point}{$\Tot \Par C \cong C$}%
Assume~$C$ is an effectus in total form.
Recall~$1 \hafter \hat{g} = 1$
and~$\smash{\widehat{f \after g}} = \hat{f} \hafter \hat{g}$,
    so~$Q\colon C \to \Tot \Par C$
    given by~$Q g = \hat{g}$ is an identity-on-objects functor.
It is an isomorphism by the first part of \sref{pardp}:
    for every~$f$ in~$\Tot \Par C$,
    there is a unqiue~$g$ in~$C$
    with~$f = \hat{g}$. \qed
\end{point}
\end{point}
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[distinction-part-tot-eff]{Exercise}%
In this exercise we will
    distinguish effectuses in total and partial form.
\begin{enumerate}
\item
To start, show that the initial object of an effectus in total form is strict
    --- that is: show that any map into~$0$ is an isomorphism.
    (Hint: use the right pullback square of~\sref{tot-pullbacks}
        with~$X=Y=0$.)
\item
Conclude that if~$C$ is both an effectus in total and partial form,
that then every object in~$C$ is isomorphic to~$0$.
\end{enumerate}
\end{point}
\begin{point}[eff-convention]{Convention}%
For the remainder of this text, we will work with effectuses in partial form
    and we write~$1$ instead of~$I$.
To spare ink, a phrase like ``let $C$ be an \Define{effectus}''
should be read as~``let $C$ be an effectus in partial form''
and simply~``$C$ is an effectus'' means either ``$C$ is an effectus in total form''
    or ``$C$ is an effectus in partial form''.
(In non-trivial cases, this
    is unambiguous, as seen in \sref{distinction-part-tot-eff}.)
As before, when we took the effectus in partial form as base category,
    we will denote partial maps by~$f\colon X \to Y$
    (instead of~$f\colon X \pto Y$)
        and their composition as~$f \after g$
        (instead of~$f \hafter g$).
\end{point}
\end{parsec}

\subsection{Predicates, states and scalars}
\begin{parsec}%
\begin{point}[dfn-mandso]{Definition}%
Let~$C$ be an effectus.
\begin{enumerate}
\item
As alluded to before,
a \Define{predicate} on~$X$ is a map~$X \to 1$.
The set of predicates $\Pred X$ on~$X$ is (by definition) an effect algebra.
\item
A \Define{scalar} is a predicate on~$1$, that is: a map~$1 \to 1$.
Write~$\Define{\Scal C} \equiv \Define{M} \equiv \Pred 1$ for the set of scalars.
We multiply two scalars~$\lambda,\mu \colon 1 \to 1$
    simply by composing~$\lambda \odot \mu \equiv \lambda \after \mu$.
As~$1_M = \id_M$ (see \sref{one-m-is-id}) and~$C$ is PCM-enriched,
    the set of scalars~$M$ with~$\odot$
    is an effect monoid,
    see \sref{dfn-effect-monoid}.
\item
A \Define{real effectus} is an effectus
where the set of scalars~$M$ is isomorphic (as effect monoid) to~$[0,1]$.
\item
For a scalar~$\lambda\colon 1\to 1$ and a predicate~$p\colon X \to 1$,
we write~$\Define{\lambda \cdot p} \equiv \lambda \after p$.
Again due to PCM-enrichment and~$1_M = \id_M$,
this scalar multiplication
turns~$\Pred X$ into a~$M$-effect module, see \sref{dfn-effect-module}.
\item
For~$f\colon X \to Y$ in~$C$,
    define~$\Pred(f) \colon \Pred Y \to \Pred X$
    by~$\Pred(f)(p) = p \after f$.
It is easy to see
$\Pred(f)$ is an~$M$-effect module homomorphism
if~$f$ is total
and that, in fact,~$\Pred\colon \Tot C \to \mathsf{EMod}^{\mathsf{op}}_M$
is a functor.
\item
A \Define{substate} on~$X$ is a map~$\omega\colon 1 \to X$.
A \Define{state} is a total substate.
We denote the set of states on~$X$ by~$\Define{\Stat X}$.
\item
An effectus~$C$ has \Define{separating predicates}
    if~$\Pred X$ is jointly monic for every~$X$ in~$C$.
    Similarly, an effectus has \Define{seperating states}
    if~$\Stat X$ is jointly epic for every~$X$ in~$C$.
\end{enumerate}
\end{point}
\begin{point}{Example}%
The category~$\op\vN$ is a real effectus ($M \cong [0,1]$)
    with seperating states and predicates.
The predicates on a von Neumann algebra~$\scrA$
    is the set of effects~$[0,1]_\scrA$
    and~$\Stat \scrA$ is the convex set of normal states.
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
Does every effect monoid~$M$ occur as the effect monoid of scalars of some
    effectus?  Does every $M$-effect module occur as
        effect module of predicates?
\end{point}
\begin{point}[emod-effectus]{Theorem}%
    The category~$\EMod^{\mathsf{op}}_M$ is an effectus 
        (with scalars~$M$) for any effect monoid~$M$.
In fact: every effectus~$C$ (in total form)
    with scalars~$M$ and separating predicates
    is equivalent to a subcategory of~$\EMod^{\mathsf{op}}_M$.
\begin{point}{Proof}%
To show~$\EMod^{\mathsf{op}}_M$ is an effectus,
    we have to show the dual  axioms for~$\EMod_M$.
\begin{point}{Finite products and inital object}%
For every~$M$-effect module~$E$,
    there is a unique modulemap~$M \to E$,
    which is given by~$\lambda \mapsto \lambda \cdot 1$.
So~$M$ is the initial object of~$\EMod_M$.
The one-element $M$-effect module~$\{0=1\}$ is the final object.

If~$E$ and $F$ are~$M$-effect modules,
    then the set of pairs~$E \times F$
    with componentwise operations
    is again an~$M$-effect module.
The module~$E \times F$
    with obvious projections,
    is the categorical product of~$E$ and~$F$
    (as is the case with effect algebras, see \sref{ea-product}).
\end{point}
\begin{point}{Pushout diagrams}%
To show the pushout diagrams corresponding to \eqref{pullbacks} hold,
assume we are given $M$-effect modules~$E,F,G$
    with modulemaps~$\alpha,\beta,\delta$
    that make the  outer squares of the following diagrams commute.
\begin{equation*}
    \xymatrix{
    G\\
    & E \times F \ar@{.>}[lu]
    & E \times M \ar[l]^{\id\times !}
    \ar@/_1pc/[llu]_{\alpha}
    \\& M \times F \ar[u]_{! \times \id}
    \ar@/^1pc/[luu]^{\beta}
    & M \times M \ar[l]^{\id\times!} \ar[u]_{! \times \id}
    } \qquad
    \xymatrix{
    G\\
    & E \ar@{.>}[lu]
    & M \ar[l]^{!}
    \ar@/_1pc/[llu]_{!}
    \\& E \times F \ar[u]_{\pi_1}
    \ar@/^1pc/[luu]^{\delta}
    & M \times M \ar[l]^{!\times!} \ar[u]_{\pi_1}
    }
\end{equation*}
We start with the left diagram.
By assumption~$\alpha \after (! \times \id) = \beta \after (\id \times !)$,
    so in particular~$\alpha(1,0) = \beta(1,0)$.
    For any~$(x,y) \in E \times F$,
        we have~$\alpha(x,0) \leq \alpha(1,0) = \beta(1,0)
            \perp \beta(0,1) \geq \beta(0,y)$,
            so~$\alpha(x,0) \perp \beta(0,y)$.
Define~$f\colon E\times F \to G$
    by~$f(x,y) = \alpha(x,0) \ovee \beta(0,y)$.
It is easy to see~$f$ is additive
    and~$f(1,1) = \alpha(1,0) \ovee \beta(0,1) = \beta(1,1)=1$,
    so~$f$ is a modulemap.
We compute
\begin{equation*}
\alpha(x,0) \ovee \beta(0,\lambda \cdot 1)
\ = \ \alpha(x,0) \ovee \lambda \cdot \alpha(0, 1)
\ = \ \alpha(x,\lambda)
\end{equation*}
and so~$f \after (\id \times !) = \alpha$.
Similarly~$\beta = f \after (! \times \id)$.
It is easy to see~$f$
is the unique map with~$f \after (\id \times !) = \alpha$
and~$\beta = f \after (! \times \id)$
and so the left square of \eqref{pullbacks}
    is a pullback in~$\EMod_M^{\mathsf{op}}$.

Concerning the right diagram:
    as~$\delta \after (!\times!) = ! \after \pi_1$,
    we have~$\delta(\lambda \cdot 1, \mu \cdot 1) = \lambda \cdot 1$
    and so~$\delta(0, y) \leq \delta(0,1) = 0$.
    Hence~$\delta(x,y) = \delta(x,0)$.
Define~$g\colon E \to G$ by~$g(x) = \delta(x,0)$.
Clearly~$g$ is additive, $g(1) = \delta(1,0) = \delta(1,1) = 1$
    and~$\delta = g \after \pi_1$ by definition.
Obviously~$g$ is the unique such map.
Thus the right square of~\eqref{pullbacks}
    is a pullback in~$\EMod_M^{\mathsf{op}}$.
\end{point}
\begin{point}{Joint epicity}%
To show~$\EMod^{\mathsf{op}}_M$ is an effectus,
    it only remains to be shown
    that~$
    \langle \pi_1, \pi_2, \pi_2\rangle,
    \langle \pi_2, \pi_1, \pi_2\rangle\colon M \times M \to M \times M \times M
    $ are jointly epic.
So assume~$f,g\colon M \times M \times M \to E$
    are two $M$-effect module maps
    with~$
        f \after \langle \pi_1,\pi_2,\pi_2\rangle =
        g \after \langle \pi_1,\pi_2,\pi_2\rangle$
        and~$
        f \after \langle \pi_2,\pi_1,\pi_2\rangle =
        g \after \langle \pi_2,\pi_1,\pi_2\rangle$.
From the first equality, it follows that~$f(1,0,0) = g(1,0,0)$.
The other one implies~$f(0,1,0) = g(0,1,0)$.
Thus~$f(0,0,1) = f(1,1,0)^\perp = g(1,1,0)^\perp = g(0,0,1)$.
As for~$(\lambda_1,\lambda_2,\lambda_3) \in M^3$,
we have~$(\lambda_1,\lambda_2,\lambda_3)
            = \lambda_1 \cdot(1,0,0)
                \ovee \lambda_2\cdot (0,1,0)
                \ovee \lambda_3\cdot (0,0,1)$
    we get~$f=g$.
\end{point}
\begin{point}{Representation}%
Let~$C$ be an effectus in total form.
Clearly $\Pred f = \Pred g $ (for~$f,g\colon X \to Y$ in~$C$)
if and only if~$p \after f = (\Pred f)(p)= (\Pred g)(p) = p \after g$
for every~$p \in \Pred X$.
Thus the functor~$\Pred\colon C \to \EMod^{\mathsf{op}}_M$
    is faithful if and only if~$C$ has separating predicates.
So if~$C$ has separating predicates,
    $C$ is equivalent to the subcategory~$\Pred C$
    of~$\EMod_M^{\mathsf{op}}$.
\end{point}
    \qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
We studied the structure of predicates in an effectus.  What about the states?
They will turn out to be abstract~$M$-convex sets.
Before we define those, we introduce a generalized distribution monad.
\end{point}
\begin{point}{Definition}%
Let~$M$ be an effect monoid
    and~$X$ be any set.
A \Define{formal $M$-convex combination} over~$X$
    is a function~$p\colon X \to M$
    with finite support
    such that~$\bigovee_{x \in X} p(x) = 1$.
We use~$\Define{\lambda_1 \ket{x_1} \ovee \cdots \ovee \lambda_n \ket{x_n}}$
    as a shorthand for the formal $M$-convex combination~$p\colon X \to M$
    given by~$p(x) = \bigovee_{x_i = x} \lambda_i$.
    (So~$p(x_i) = \lambda_i$ if the~$x_i$ are distinct.)
We write~$\Define{\mathcal{D}_M} X$.
    for the set of all formal~$M$-convex combinations over~$X$.
\end{point}
\begin{point}{Exercise}%
    In this exercise we study~$\mathcal{D}_M$ as a monad.
    See \cite{probdistrconv,basmsc}.
\begin{enumerate}
\item
For~$f\colon X \to Y$,
    define~$\mathcal{D}_M f \colon \mathcal{D}_M X \to \mathcal{D}_M Y$
    by
    \begin{equation*}
    (\mathcal{D}_M f)(p)(y) \ =\  \bigovee_{x; f(x)=y} p(x).
    \end{equation*}
    (That is: $(\mathcal{D}_M f) (\lambda_1 \ket{x_1} \ovee \cdots
            \ovee \lambda_n \ket{x_n})
            = \lambda_1 \ket{f(x_1)} \ovee \cdots
            \ovee \lambda_n \ket{f(x_n)} $.)
Show that this turns~$\mathcal{D}_M$ into a functor~$\mathsf{Set} \to \mathsf{Set}$.
\item
Define~$\eta \colon X \to \mathcal{D}_M X$
    by~$\eta(x) = \ket{x}$
    and~$\mu\colon \mathcal{D}_M \mathcal{D}_M X \to \mathcal{D}_M X$ by
    \begin{equation*}
        \mu(\Phi)(x) \ = \ 
        \bigovee_{\varphi}
        \Phi(\varphi) \odot \varphi(x).
    \end{equation*}
Show that~$(\mathcal{D}_M, \eta,\mu)$
    is a monad.
\item
    Show that~$\Kl \mathcal{D}_M$,
    the Kleisli category of~$\mathcal{D}_M$
    (See e.g.~\cite[\S 2.6]{basmsc}.),
    is an effectus
    with~$M$ as scalars.
\end{enumerate}
\end{point}
\begin{point}{Definition}%
Let~$X$ be a set together
    with a map~$h\colon \mathcal{D}_M X \to X$.
We say~$(X,h)$ is an \Define{abstract $M$-convex set}
    provided~$h(\ket{x})=x$
    and
\begin{equation}\label{convex-mult}
    h \Bigl( \bigovee_{i,j} \sigma_i \odot \lambda_{ij} \ket{x_{ij}} \Bigr)
    \ = \ 
    h \Bigl( \bigovee_i \sigma_i \, \ket{
        h\bigl(\, \bigovee_j \lambda_{ij} \ket{x_{ij}}\, \bigr)
    } \, \Bigr)
\end{equation}
for every~$\bigovee_i \sigma_i \ket{\bigovee_j \lambda_{ij} \ket{x_{ij}}}$
    in~$\mathcal{D}_M \mathcal{D}_M X$.
(Equivalently: $h \after \mu = h \after \mathcal{D}_M h$
and~$h \after \eta = \id$.)
    We call~$h$ the convex structure on~$X$.
A map~$f\colon X \to Y$
    between abstract~$M$-convex sets
    is \Define{$M$-affine} if
\begin{equation*}
    f \bigl(h_X \bigl(\,\bigovee_i \lambda_i \ket{x_i}\, \bigr)\bigr)
     \ = \ 
     h_Y\bigl(\,\bigovee_i \lambda_i \ket{f(x_i)}\,\bigr)
\end{equation*}
for every~$\bigovee_i \lambda_i \ket{x_i}$ in~$\mathcal{D}_M X$.
(Equivalently: $h_X \after \mathcal{D}_M f = f \after h_Y$.)
Write~$\Define{\AConvM}$ for the category
    of abstract~$M$-convex sets with
    $M$-affine maps between them.
(Equivalently: $\AConvM$
    is the Eilenberg--Moore category
    of the monad~$\mathcal{D}_M$.)
We call an abstract $M$-convex set~$(X,h)$ \Define{cancellative}
provided
\begin{equation*}
    h(\lambda \ket{y} \ovee \lambda^\perp \ket{x_1})\  = \
    h(\lambda \ket{y} \ovee \lambda^\perp \ket{x_2})
    \quad\text{implies}\quad~x_1=x_2
\end{equation*}
    for any~$x_1,x_2,y \in X$ and~$\lambda \in M, \lambda \neq 0$.
\end{point}
\begin{point}{Examples}%
We give some examples of abstract convex sets.
\begin{enumerate}
\item
Every convex subset~$X \subseteq V$
    of some real vector space~$V$
    is a cancellative abstract~$[0,1]$-convex set
    with~$h(\lambda_1 \ket{x_1} \ovee \cdots \ovee \lambda_n \ket{x_n})
            = \lambda_1 x_1 + \cdots + \lambda_n x_n$.
\item
Not every abstract~$[0,1]$-convex set is
    a convex subset of a real vector space.
Consider~$T \subseteq [0,1]^2$
    defined by~$T \equiv \{ (x,y);\ x+y \leq 1\}$.
Say~$(x,y) \sim (x',y')$
    whenever~$x = x'$ and either $x\neq 0$ or~$y=y'$.
This equivalence relation~$\sim$
is a congruence (see \sref{aconv-cong}) for the convex structure on~$T$
    (inherited by~$\R^2$)
    and so~$T /_\sim$ is an abstract~$[0,1]$-convex set.
That is: we start of with a filled triangle
$T \equiv \begin{tikzpicture}[scale=0.2]
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
    \draw (1,0) -- (0,1) ; 
\end{tikzpicture}$,
identify all vertical lines
except for the y-axis
and are left with
$T/_\sim \equiv
\begin{tikzpicture}[scale=0.2]
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}$.
The abstract~$[0,1]$-convex set~$T/_\sim$
    is not cancellative:
\begin{equation*}
    h\Bigl( 
    \frac{1}{2}\ket{\begin{tikzpicture}[scale=0.2]
    \filldraw( 1,0) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}}
\ovee
    \frac{1}{2}\ket{\begin{tikzpicture}[scale=0.2]
    \filldraw( 0,1) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}} \Bigr)
\ = \
    \begin{tikzpicture}[scale=0.2]
    \filldraw( .5,0) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}
\ = \ 
h \Bigl(\frac{1}{2}\ket{\begin{tikzpicture}[scale=0.2]
    \filldraw( 1,0) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}}
\ovee
    \frac{1}{2}\ket{
        \begin{tikzpicture}[scale=0.2]
    \filldraw( 0,.5) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}
}\Bigr), \quad\text{but}\quad
        \begin{tikzpicture}[scale=0.2]
    \filldraw( 0,1) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture} \ \neq \ 
        \begin{tikzpicture}[scale=0.2]
    \filldraw( 0,.5) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}.
\end{equation*}
\item
Semilattices are exactly~abstract $2$-convex sets.
Furthermore, every semilattice~$(L, \vee)$
    is an abstract~$[0,1]$-convex set
    with
    \begin{equation*}
    h\bigl(\lambda_1 \ket{x_1} \ovee \cdots \ovee \lambda_n \ket{x_n}\bigr)
        \ =\  \bigvee_{i; \lambda_i \neq 0} x_i.
    \end{equation*}
    A semilattice is cancellative as abstract $[0,1]$-convex set
    if and only if~$x=y$ for all~$x,y\in L$.
    See \sref{neumann1970quasivariety}.
\item
Every cancellative~$[0,1]$-convex set
    is isomorphic to a convex subset of a real vector space.
    See e.g.~\cite[Thm.~8]{statesofconvexsets}.
\end{enumerate}
\begin{point}{Remarks}%
The study of
    convex subsets (of real vector spaces)
    as algebraic structures goes back a long time,
        see e.g.~\cite{stone1949postulates,neumann1970quasivariety,flood1981semiconvex,tz2009convex,gudder1979general}.
The more pathological abstract~$[0,1]$-convex sets have been studied before
    under different names:
    they are semiconvex sets in \cite{flood1981semiconvex,swirszcz1975monadic} and
    convex spaces in \cite{tz2009convex}.
The description of convex sets using Eilenberg--Moore algebras is probably
    due to \'Swirszcz \cite{swirszcz1975monadic}.
For the even more exotic abstract~$M$-convex
    sets, see \cite{effintro} or
        \cite{probdistrconv}.
\end{point}
\end{point}
\begin{point}{Proposition}%
Let~$C$ be an effectus with scalars~$M$.
For any object~$X$, the set of states
$\Stat X$ is an abstract $M^{\mathsf{op}}$-convex set
with~$h\colon \mathcal{D}_{M^{\mathsf{op}}} \Stat X \to \Stat X$
    defined by
    $h\bigl( \lambda_1 \ket{\varphi_1} \ovee \cdots \ovee \lambda_n \ket{\varphi_n} \bigr)
     =  [\varphi_1, \ldots, \varphi_n] \after \langle
                    \lambda_1, \ldots, \lambda_n\rangle$.
Furthermore,
    for any total map~$f\colon X \to Y$,
    the map~$ (\Stat f)(\varphi) \ = \ f \after \varphi$
    is an~$M^{\mathsf{op}}$-affine map~$\Stat X \to \Stat Y$ yielding a
    functor~$\Stat \colon \Tot C \to \mathsf{AConv}_{M^{\mathsf{op}}}$.
\begin{point}{Proof}%
Clearly~$h(\ket{\varphi}) = \varphi$.
To show the other axiom~\eqref{convex-mult},
assume we have any~$\bigovee^n_{i=1} \sigma_i \ket{\bigovee^{m_i}_{j=1} \lambda_{ij} \ket{\varphi_{ij}}}$
in~$\mathcal{D}_{M^\mathsf{op}} \mathcal{D}_{M^{\mathsf{op}}} \Stat X$.
Write~$\lambda_i \equiv \langle\lambda_{i1}, \ldots, \lambda_{im_i}\rangle$
and $\varphi_i \equiv [\varphi_{i1}, \ldots, \varphi_{i{m_i}}]$.
Then
\begin{align*}
    h \Bigl( \bigovee_i \sigma_i \, \ket{
        h\bigl(\, \bigovee_j \lambda_{ij} \ket{\varphi_{ij}}\, \bigr)
    } \, \Bigr)
    &\ = \ 
    [\varphi_1 \after \lambda_1, \ldots, 
    \varphi_n \after \lambda_n] \after \langle
    \sigma_1, \ldots, \sigma_n
    \rangle
    \\ & \ = \ 
    \bigovee_{i} \varphi_i \after \lambda_i \after \sigma_i
    \\ & \ = \ 
    \bigovee_{i} \bigl(\bigovee_j \varphi_{ij} \after \lambda_{ij}\bigr) \after \sigma_i
    \\ & \ = \ 
    \bigovee_{i,j} \varphi_{ij} \after (\lambda_{ij} \after \sigma_i)
    \\ & \ = \ 
    \bigovee_{i,j} \varphi_{ij} \after (\sigma_i \odot_{M^{\mathsf{op}}} \lambda_{ij})
    \\ & \ = \ 
    h \Bigl( \bigovee_{i,j} \sigma_i \odot_{M^{\mathsf{op}}} \lambda_{ij} \ket{\varphi_{ij}} \Bigr).
\end{align*}
So~$\Stat X$ is indeed an abstract~$M^{\mathsf{op}}$-convex set.
Let~$f\colon X \to Y$ be any total map.
To show~$\Stat f$ is affine,
it is sufficient to show that
for every~$\bigovee_i \lambda_i \ket{\varphi_i}$
 in~$\mathcal{D}_{M^{\mathsf{op}}}$,
 we have
        $f \after \bigovee_i  \varphi_i \after \lambda_i 
         = 
        \bigovee_i f \after  \varphi_i \after \lambda_i$,
        which is clearly true.
    Functoriality of~$\Stat$ is obvious. \qed
\end{point}
\end{point}
\end{parsec}

\subsection{More on abstract $M$-convex sets}\label{more-aconvm}
\begin{parsec}%
\begin{point}%
For our next project,
    we indulge ourselves in a tangent:
    we investigate whether the category~$\AConvM$ is an effectus.
We can show~$\AConvM$ is an effectus, if~$M$ has a certain partial division.
Unfortunately it will remain unclear if~$\AConvM$ is an effectus in general.
The case~$M=[0,1]$ is much easier and has already been delt with
        in \cite{statesofconvexsets}. 
The first step is to uncover the coproduct in~$\AConvM$.
To construct the coproduct, we will need to know
    about quotients of abstract~$M$-convex sets.
\end{point}
\begin{point}[aconv-cong]{Exercise}%
In this exercise we construct the quotient of an
    abstract~$M$-convex sets by a congruence.
Assume~$(X,h)$ is an abstract~$M$-convex set
    and~$\sim \subseteq X^2$ is an equivalence relation.
Write~$X/_\sim$ for the equivalence classes
    of~$\sim$
    and~$q\colon X \to X/_\sim$
    for~$q(x) = [x]_\sim$.
For~$\varphi,\psi \in \mathcal{D}_M X$,
    we write~$\varphi \sim \psi$
    provided~$(\mathcal{D}_M q)(\varphi) = (\mathcal{D}_M q)(\psi)$.
We say~$\sim$ is a \Define{congruence} for~$(X,h)$
if~$\varphi \sim \psi$ implies~$h(\varphi) \sim h(\psi)$.
\begin{enumerate}
\item
Prove that~$q$, $\mathcal{D}_M q$ and~$\mathcal{D}_M \mathcal{D}_M q$
    are all surjective.
\item
Show that the following are equivalent.
\begin{enumerate}
\item
$\sim$ is a congruence.
\item
There is a map~$h_\sim \colon \mathcal{D}_M X_\sim \to X/_\sim$
    such that~$h_\sim \after \mathcal{D}_M q = q \after h$.
\end{enumerate}
By the previous point $h_\sim$ is unique, if it exists.
\item
Assume~$\sim$ is a congruence.
Use the previous two points to show
\begin{equation*}
h_\sim \after \mathcal{D}_M h_\sim \after \mathcal{D}_M \mathcal{D}_M q
            \ =\  h_\sim \after \mu \after \mathcal{D}_M \mathcal{D}_M q.
\end{equation*}
Conclude~$(X/_\sim,h_\sim)$ is an abstract~$M$-convex set.
\end{enumerate}
\end{point}
\begin{point}[affine-kernel-cong]{Exercise}%
Assume~$f\colon X \to Y$ is an affine map between abstract
    $M$-convex sets.
Show that the kernel~$\{(x,y);\ f(x) = f(y)\}$ of~$f$
    is a congruence.
\end{point}
\begin{point}[least-conv-cong]{Exercise}%
Assume~$(X,h)$ is an abstract~$M$-convex set and~$R \subseteq X^2$
    is some relation.
It is easy to see there is a least congruence containing~$R$.
We need to know a bit more than mere existence.
Write~$R^*$ for the reflexive symmetric transitive closure of~$R$
    (i.e.~the least equivalence relation containing~$R$).

For~$\psi_1,\psi_2 \in \mathcal{D}_M X$,
    we write~$\psi_1 \approx \psi_2$
    if there is a \emph{derivation}: a tuple~$\varphi_1, \ldots, \varphi_n \in \mathcal{D}_M X$
(say~$\varphi_i \equiv \bigovee^{n_i}_{j = 1}  \lambda_{ij}\ket{x_{ij}}$)
such that~$\varphi_1 = \psi_1$, $\varphi_n = \psi_2$ 
    and for each~$1 \leq i<n$ one of the following two conditions holds.
\begin{enumerate}
\item
    $n_i = n_{i+1}$
    and for all~$1 \leq j \leq n_i$ we have
    $x_{ij} \mathrel{R^*} x_{(i+1)j}$
    and~$\lambda_{ij}  = \lambda_{(i+1)j}$.
\item
    $h (\varphi_i) = h(\varphi_{i+1})$.
\end{enumerate}
We will show that~$\sim$
    given by~$x \sim y \iff \eta (x) \approx \eta(y)$
    is the least congruence containing~$R$:
\begin{enumerate}
\item
To start, show that~$\eta ( h(\psi)) \approx \psi $
    and so~$\varphi \approx \psi$ implies~$h(\varphi) \sim h(\psi)$.
\item
Show that if~$\varphi \approx \psi$,
    then
    \begin{equation*}
    \mu \Bigl(\lambda_0 \ket{\psi} \ovee \bigovee_{j=1}^n \lambda_j \ket{\chi_j}\Bigr)
    \ \approx  \ 
    \mu \Bigl(\lambda_0 \ket{\varphi} \ovee \bigovee_{j=1}^n \lambda_j \ket{\chi_j}\Bigr).
    \end{equation*}
    for any~$\bigovee_j \lambda_j=1$  in~$M$ and~$\chi_1,\ldots, \chi_n \in \mathcal{D}_M X$.
\item
    Use the previous point to show that~$\varphi \sim \psi$
        implies~$\varphi \approx \psi$.
Conclude~$\sim$ is the smallest congruence containing~$R$.
\end{enumerate}
\end{point}
\begin{point}[aconv-coprod]{Proposition}%
Assume~$(X,h_X)$ and~$(Y,h_Y)$
    are abstract~$M$-convex sets.
    We will construct their coproduct.
Note that~$\mu$ turns~$\mathcal{D}_M (X+Y)$
    into an abstract~$M$-convex set.
Let~$\sim$ denote the least congruence on~$\mathcal{D}_M (X+Y)$
with
\begin{equation}
    (\mathcal{D}_M \kappa_1) (\varphi)
    \ \sim \ \eta(\kappa_1 ( h_X (\varphi)))
    \quad \text{and} \quad
    (\mathcal{D}_M \kappa_2) (\psi)
    \ \sim \ \eta(\kappa_2 ( h_Y (\psi))) \label{congruence-coprod-conv}
\end{equation}
    for all~$\varphi \in \mathcal{D}_M X$
    and~$\psi \in \mathcal{D}_M Y$.
Write~$q\colon \mathcal{D}_M (X+Y) \to C$
    for the quotient of~$\mathcal{D}_M(X+Y)$ by~$\sim$, see~\sref{aconv-cong}.
    Denote the convex structure on~$C$ by~$h$.
Define~$c_1 \colon X \to C$ and~$c_2 \colon Y \to C$
    by~$c_1 \equiv q \after \eta \after \kappa_1$
    and~$c_2 \equiv q \after \eta \after \kappa_2$.

Then: $c_1 \colon X \to C \leftarrow Y \colon c_2$
is a coproduct of~$X$~and~$Y$ in~$\AConvM$.
\begin{point}{Proof}%
We start with the affinity of the coprojections:
\begin{alignat*}{2}
    c_1 \after h_X & \ = \ 
    q \after \eta \after \kappa_1 \after h_X \\
    &\ =\  q \after \mathcal{D}_M \kappa_1
        &\qquad& \text{by dfn.~of~$\sim$}
    \\
    & \ =\  q \after \mu \after \mathcal{D}_M \eta \after \mathcal{D}_M \kappa_1. \\
    & \ =\  \mu \after \mathcal{D}_Mq \after \mathcal{D}_M \eta \after \mathcal{D}_M \kappa_1. \\
    & \ =\  \mu \after \mathcal{D}_M c_1,
\end{alignat*}
so~$c_1$ is affine. With the same reasoning, we see~$c_2$ is affine.
\begin{point}%
Assume~$f\colon X \to Z$ and~$g\colon Y \to Z$
    are two affine maps to some abstract~$M$-convex set~$(Z,h_Z)$.
We want to show~$h_Z \after \mathcal{D}_M [f,g]$
    lifts to~$C$.
With an easy calculation,
    one sees~$h_Z \after \mathcal{D_M} [f,g]$ is affine.
We compute
\begin{align*}
    h_Z \after \mathcal{D}_M [f,g] \after \mathcal{D}_M \kappa_1
     & \ = \ 
    h_Z \after \mathcal{D}_M f \\
     & \ = \ f \after h_X \\
     & \ = \ h_Z \after \eta \after [f,g] \after \kappa_1 \after h_X \\
     & \ = \ h_Z \after \mathcal{D}_M [f,g] \after \eta \after \kappa_1 \after h_X.
\end{align*}
So~$
(\,(\mathcal{D}_M \kappa_1) (\varphi), \,
\ \eta(\kappa_1 ( h_X (\varphi)))\,)$
is in the kernel (see \sref{affine-kernel-cong})
of~$h_Z \after \mathcal{D}_M [f,g]$
for~$\varphi \in \mathcal{D}_M$.
Similarly~$(\,(\mathcal{D}_M \kappa_2) (\psi), \,
\ \eta(\kappa_2 ( h_Y (\psi)))\,)$
is also in the kernel of~$h_Z \after \mathcal{D}_M [f,g]$
for all~$\psi \in \mathcal{D}_M$.

As kernels of affine maps are congruences
    and~$\sim$ is the least congruence that contains these pairs,
    we conclude~$\sim$ is a subset of the kernel
    of~$h_Z \after \mathcal{D}_M [f,g]$.
Thus there is a unique affine~$k\colon C \to Z$
    fixed by~$k \after q = h_Z \after \mathcal{D}_M [f,g]$.
Now
\begin{align*}
    k \after c_1 
    &\ = \ k \after q \after \eta \after \kappa_1 \\
    &\ = \ h_Z \after \mathcal{D}_M [f,g]
                            \after \eta\after \kappa_1 \\
    &\ = \ h_Z \after \eta \after  [f,g]
                            \after \kappa_1 \\
    &\ = \  f
\end{align*}
and similarly~$k \after c_2 = g$.
\end{point}
\begin{point}%
Only uniqueness of~$k$ remains to be shown.
So assume~$k'\colon C \to Z$ is an affine map
    such that~$k' \after c_1 = f$
    and~$k' \after c_2 = g$.
We turn the wheel:
\begin{align*}
    k' \after q
    & \ = \ k' \after q \after \mu \after \mathcal{D}_M \eta \\
    & \ = \ k' \after h \after \mathcal{D}_M (q \after \eta) \\
    & \ = \ h_Z \after \mathcal{D}_M (k' \after q \after \eta) \\
    & \ = \ h_Z \after \mathcal{D}_M 
    [ k' \after q \after \eta \after \kappa_1,
    k' \after q \after \eta \after \kappa_2]  \\
    & \ = \ h_Z \after \mathcal{D}_M 
    [ k' \after c_1,
    k' \after c_2]  \\
    & \ = \ h_Z \after \mathcal{D}_M [ f, g] \\
    & \ = \ k \after q.
\end{align*}
So~$k = k'$ by surjectivity of~$q$. \qed
\end{point}
\end{point}
\begin{point}[elements-coprod-conv]{Remark}%
By construction,
    every~$z \in X+Y$
    is of the
    form
\begin{equation*}
    z \ =\  h 
    \Bigl( \bigovee^n_{i=1} \lambda_i \ket{c_1(x_i)}
    \ovee \bigovee^m_{i=1} \sigma_i \ket{c_2(y_i)} \Bigr)
\end{equation*}
for some~$\lambda_i,\sigma_i \in M $, 
$x_i \in X$ and~$y_i \in Y$.
In general these are not unique.
Indeed
using \sref{least-conv-cong}, we see that
\begin{equation*}
     h 
     \Bigl( \bigovee^n_{i=1} \lambda_i \ket{c_1(x_i)}
     \ovee \bigovee^m_{i=1} \sigma_i \ket{c_2(y_i)} \Bigr) 
     \ = \ 
     h 
     \Bigl( \bigovee^{n'}_{i=1} \lambda'_i \ket{c_1(x'_i)}
     \ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{c_2(y'_i)} \Bigr)
\end{equation*}
iff there is a \emph{derivation}~$\Phi_1, \ldots, \Phi_l \in \mathcal{D}^2_M(X+Y)$,
say $\Phi_i \equiv \bigovee_j \zeta_{ij} \ket{\varphi_{ij}}$,
with
\begin{equation*}
\Phi_1 \ =\  
\ket {\bigovee^n_{i=1} \lambda_i \ket{\kappa_1(x_i)}
\ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_2(y_i)}}
, \quad
 \Phi_l \ =\  
 \ket {\bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_1(x_i)}
 \ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_2(y_i)}}
\end{equation*}
and for each~$1 \leq i < l$ either
\begin{enumerate}
    \item $\mu(\Phi_i) = \mu(\Phi_{i+1})$
        or
    \item
        for each~$j$ we have~$\zeta_{ij} = \zeta_{(i+1)j}$
        and one of the following.
        \begin{enumerate}
        \item
    $\varphi_{ij} = \varphi_{(i+1)j}$.
\item
    $\varphi_{ij} = (\mathcal{D}_M\kappa_1) (\chi)$
and~$\varphi_{(i+1)j} = (\mathcal{D}_M\kappa_1) (\chi')$
        for some~$\chi,\chi' \in \mathcal{D}_M X$
        with~$h_X( \chi) = h_X(\chi')$.
\item
    $\varphi_{ij} = (\mathcal{D}_M\kappa_2) (\chi)$
and~$\varphi_{(i+1)j} = (\mathcal{D}_M\kappa_2) (\chi')$
        for some~$\chi,\chi' \in \mathcal{D}_M Y$
        with~$h_Y( \chi) = h_Y(\chi')$.
        \end{enumerate}
\end{enumerate}
\end{point}
\end{point}
\begin{point}[n-times-one-aconvm]{Exercise}%
Show that the one-element set is an abstract~$M$-convex set
    and, in fact, the final object of~$\AConvM$.
To continue, show that in~$\AConvM$
\begin{equation*}
    n \cdot 1 \ \equiv \ \underbrace{1 + \cdots + 1}_{\text{$n$ times}}
    \ \cong \ \mathcal{D}_M \{1, \ldots, n\}.
\end{equation*}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[aconvalmosteffectus]{Proposition}%
The category~$\AConvM$ obeys all the axioms of an effectus in total
form except for the left pullback-square of~\eqref{pullbacks}.
\begin{point}{Proof}%
In \sref{aconv-coprod} we proved~$\AConvM$ has binary coproducts
    and in \sref{n-times-one-aconvm}
    that the one-element set~$1$ is its final object.
As~$\mathcal{D}_M \emptyset = \emptyset$,
    the empty set trivially also an abstract~$M$-convex set
    and in fact the initial object of~$\AConvM$.
\end{point}
\begin{point}%
We continue with joint-monicity
    of~$[\kappa_1,\kappa_2,\kappa_2],
    [\kappa_2,\kappa_1,\kappa_2]\colon 1+1+1 \to 1+1$.
We can represent the convex set~$1+1+1$
    as the set of triplets~$(a,b,c) \in M^3$
    with~$a\ovee b \ovee c = 1$
    with the obvious convex structure,
    cf.~\sref{n-times-one-aconvm}.
Similarly, we identify~$1+1$
    with pairs~$(a,a^\perp) \in M^2$.
    The maps at hand are given by
\begin{equation}\label{conv-jointly-monic}
    (a,b,c) \ \mapsto\  (a , b\ovee c)\quad \text{and} \quad
    (a,b,c) \ \mapsto\  (b, a\ovee c).
\end{equation}
Assume~$
(a, b \ovee c) = 
(a', b' \ovee c') $
and
$(b, a \ovee c) = 
(b', a' \ovee c') $
for~$a,a',b,b',c,c' \in M$ with~$a \ovee b \ovee c= 1$
and~$a' \ovee b' \ovee c'= 1$.
Then clearly~$a=a'$,~$b=b'$
    and so~$c = (a\ovee b)^\perp = (a' \ovee b')^\perp = c'$.
Thus the maps~\eqref{conv-jointly-monic} are jointly injective,
    hence jointly monic.
\end{point}
\begin{point}%
Finally, we prove that the square on the right of \eqref{pullbacks}
    is a pullback in~$\AConvM$.
\begin{equation*}
\xymatrix{
    Z \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_\alpha
        \ar@{.>}[rd]|\gamma\\
        &X \ar[r]^{!} \ar[d]^{\kappa_1}
        & 1\ar[d]^{\kappa_1} \\
        &X+Y\ar[r]_{!+!} & 1+1
    }
\end{equation*}
So assume~$\alpha \colon Z \to X+Y$
    is a map in~$\AConvM$
    with~$(!+!) \after \alpha = \kappa_1 \after !$.
We have to show~$\alpha = \kappa_1 \after \gamma$,
    for a unique~$\gamma\colon Z \to X+Y$ in~$\AConvM$.
For the moment, assume~$\kappa_1$ is injective.
Then~$\gamma$, if it exists, is unique.
Pick~$z \in Z$.
We know
\begin{equation*}
    \alpha(z) \ =\  h 
    \Bigl( \bigovee^n_{i=1} \lambda_i \ket{\kappa_1(x_i)}
    \ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_2(y_i)} \Bigr)
\end{equation*}
for some~$\lambda_i,\sigma_i \in M $, 
$x_i \in X$ and~$y_i \in Y$,
where~$h$ is the convex structure on~$X+Y$.
As~$(!+!) \after \alpha = ! \after \kappa_1$,
    we must have~$\bigovee_i \sigma_i = 0$
    and so~$\alpha(z) = \kappa_1(x_z)$
    for some~$x_z \in X$.
This~$x_z$ is unique by injectivity of~$\kappa_1$.
    Define~$\gamma(z) = x_z$.
By definition~$\kappa_1 \after \gamma = \alpha$.
To see~$\gamma$ is affine, pick any~$\varphi \in \mathcal{D}_M (Z)$.
We have
$
\kappa_1 ( \gamma ( h_Z (\varphi )))
    = \alpha(h_Z (\varphi))
    = h(\mathcal{D}_M\alpha(\varphi))
    = h(\mathcal{D}_M\kappa_1 ( \mathcal{D}_M \gamma(\varphi)))
    = \kappa_1  (h_X( \mathcal{D}_M \gamma(\varphi)))
$ and
so indeed~$\gamma(h_Z(\varphi)) = h_X(\mathcal{D}_M \gamma (\varphi))$
    --- i.e.~$\gamma$ is affine.
\end{point}
\begin{point}%
Finally, we will show that~$\kappa_1$ is indeed injective.
Assume~$\kappa_1(x_0) = \kappa_1(x'_0)$
for some~$x_0,x'_0 \in X$.
    Let~$\Phi_1, \ldots, \Phi_l \in \mathcal{D}_M^2{(X+Y)}$
    be a derivation
    of~$\kappa_1(x_0) = \kappa_1(x'_0)$
    as in \sref{elements-coprod-conv}.
The remainder of the proof is, in essence, a simple induction
    over~$1 \leq i < l$, which has been complicated
    by a technicality.
Define
\begin{equation*}
    \mathrm{IH}(i) \ \equiv \ \text{``}
    \bigovee_y \mu(\Phi_i)(\kappa_2 (y)) = 0
        \text{ and }
        h_X\Bigl(\bigovee_{x} \mu(\Phi_i)(\kappa_1(x)) \ket{x}\Bigr)
        =    x_0 \text{''}.
\end{equation*}
Clearly~$\mathrm{IH}(1)$ holds
    and if~$\mathrm{IH}(l)$ should hold,
    then~$x_0 = x_0'$ as desired.
So, to prove the inductive step, assume~$\mathrm{IH}(i)$ holds.
There are two possible derivation steps, see \sref{elements-coprod-conv}.
In the first case (i.e.~$\mu(\Phi_i) = \mu(\Phi_{i+1})$)
    it is obvious~$\mathrm{IH}(i+1)$ holds.
So we continue with the other case,
where (among others) we have~$\zeta_{ij} = \zeta_{(i+1)j}$.
Without loss of generality, we may assume~$\zeta_{ij} \neq 0$.
For each~$j$ there are three possibilities, see \sref{elements-coprod-conv}.
The third does not occur:
if~$\varphi_{ij_0} = (\mathcal{D}_M \kappa_2) (\chi)$
    for some~$\chi \in \mathcal{D}_M Y$ and~$j_0$,
    then we reach a contradiction:
\begin{equation*}
    0\ = \ 
    \bigovee_y \mu(\Phi_i)(\kappa_2(y))
    \ = \ \bigovee_{y,j} \zeta_{ij} \odot \varphi(\kappa_2(y))
    \ \geq \ \bigovee_y \zeta_{ij_0} \odot \chi(y)\  \neq\  0.
\end{equation*}
We are left with two possibilities ---
    to distinguish those,
    write~$j \in J$ if~$\varphi_{ij} = \varphi_{(i+1)j}$
    and~$j \notin J$
    if~$\varphi_{ij} = (\mathcal{D}_M \kappa_1)(\chi)$
    and~$\varphi_{(i+1)j} = (\mathcal{D}_M \kappa_1)(\chi')$
    for some~$\chi,\chi' \in \mathcal{D}_M X$
    with~$h_X (\chi) = h_X(\chi')$.

    We will show the first part of~$\mathrm{IH}(i+1)$.
Pick any~$y \in Y$.
If~$j \in J$, then~$\zeta_{(i+1)j}\odot \varphi_{(i+1)j}(\kappa_2(y))
= \zeta_{(i+1)j} \odot \varphi_{(i+1)j}(\kappa_2(y)) = 0$.
In the other case, if~$j \notin J$,
then clearly~$\zeta_{(i+1)j}\odot \varphi_{(i+1)j}(\kappa_2(y)) = 0$
    as~$\varphi_{(i+1)j} = \mathcal{D}_M(\chi')$.
So, we have~$\bigovee_y \mu(\Phi_{i+1})(\kappa_2(y))
= \bigovee_{y,j} \zeta_{(i+1)j} \odot \varphi_{(i+1)j} (\kappa_2(y)) = 0 $.

Write~$r_{ij} = (\bigovee_x \varphi_{ij}(\kappa_1(x)))^\perp$.
The remainder of the proof is complicated
    by the fact that in general~$r_{ij} \neq 0$.
    We do have~$\bigovee_j \zeta_{ij} \odot r^\perp_{ij} = 1$
        and~$\bigovee_j \zeta_{ij} = 1$
        so by \sref{emond-lemma-for-conv}
        we see~$\zeta_{ij} \odot r^\perp_{ij} = \zeta_{ij}$,
        which  forces~$\zeta_{ij} \odot r_{ij} = 0$.
We compute
\begin{align*}
    h_X\Bigl(\bigovee_x \mu(\Phi_i) (\kappa_1(x)) \ket{x}\Bigr) 
    &\ = \ 
    h_X \Bigl( \bigovee_{x,j} \zeta_{ij} \odot \varphi_{ij}
        (\kappa_1(x)) \ket{x} \Bigr) \\
        &\ = \ 
    h_X \Bigl(
    \bigovee_{j} \zeta_{ij} \odot r_{ij} \ket{x_0} \ovee \bigovee_x
    \zeta_{ij} \odot \varphi_{ij}
        (\kappa_1(x)) \ket{x} \Bigr) \\
        & \ = \ h_X \Bigl(
    \mu\Bigl( \bigovee_j \zeta_{ij} \ket{
        r_{ij} \ket{x_0} \ovee \bigovee_x \varphi_{ij} (\kappa_1 (x)) \ket{x}
    }
    \Bigr)
    \Bigr) \\
        & \ = \ h_X \Bigl(
    \bigovee_j \zeta_{ij} \ket{
        h_X\Bigl(
        r_{ij} \ket{x_0} \ovee \bigovee_x \varphi_{ij} (\kappa_1 (x)) \ket{x}
    \Bigr)
}
    \Bigr).
\end{align*}
So, if we show that for each~$j$,
    we have
\begin{multline}\label{eqkappainj}
        h_X\Bigl(
        r_{ij} \ket{x_0} \, \ovee \,\bigovee_x \varphi_{ij} (\kappa_1 (x)) \ket{x}
    \Bigr) \\
    \  = \  
        h_X\Bigl(
        r_{(i+1)j} \ket{x_0} \,\ovee \,\bigovee_x \varphi_{(i+1)j} (\kappa_1 (x)) \ket{x}
    \Bigr),
\end{multline}
then
\begin{equation*}
    x_0 \ = \ h_X\Bigl(\bigovee_x \mu(\Phi_i) (\kappa_1(x)) \ket{x}\Bigr) 
    \ =\  h_X\Bigl(\bigovee_x \mu(\Phi_{i+1}) (\kappa_1(x)) \ket{x}\Bigr),
\end{equation*}
as desired.
If~$j \in J$,
then~$\varphi_{ij} = \varphi_{(i+1)j}$
and so~$r_{ij} = r_{(i+1)j}$
and obviously~\eqref{eqkappainj}.
So assume~$j \notin J$.
Then clearly~$r_{ij} = 0 = r_{(i+1)j}$
as~$\varphi_{ij} = (\mathcal{D}_M \kappa_1)(\chi))$
    and~$\varphi_{(i+1)j} = (\mathcal{D}_M \kappa_1) (\chi')$.
Now~\eqref{eqkappainj} follows from~$h_X(\chi) = h_X(\chi')$. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[dfn-effect-divisoid]{Definition}%
An \Define{effect divisoid}
    is an effect monoid~$M$
    with partial binary operation~$(a,b) \mapsto \rfrac{a}{b}$
    that is defined iff~$a \leq b$ and
        satisfies the following axioms.
\begin{enumerate}
\item~$\rfrac{a}{b}$
        is the unique element of~$M$
        with~$\rfrac{a}{b} \leq \rfrac{b}{b}$
        and~$b\odot \rfrac{a}{b} \ =\  a$
\item~$a \ \leq \ \rfrac{a}{a}$
\item~$\rfrac{(\rfrac{a}{a})}{(\rfrac{a}{a})} \ =\  \rfrac{a}{a}$
\end{enumerate}
\begin{point}{Remark}%
The element~$\rfrac{a}{a}$ behaves like a support-projection for~$a$.
\end{point}
\end{point}
\begin{point}{Examples}%
Almost all effect monoids we encountered
    are effect divisoids.
\begin{enumerate}
\item
The effect monoid~$[0,1]$
    is an effect divisoid with~$\rfrac{a}{b} = \frac{a}{b}$
        if~$b \neq 0$ and~$\rfrac{0}{0}=0$.
With the same partial division, we see the two-element effect monoid~$2$
    is also an effect divisoid.
\item
More interestingly,
    if~$M_1$ and~$M_2$
    are effect divisoids,
    then~$M_1 \times M_2$
    is an effect divisoid
    with~$\rfrac{(a_1,a_2)}{(b_1,b_2)} =
    (\rfrac{a_1}{b_1}, \rfrac{a_2}{b_2})$.
In particular~$[0,1]^n$ is an effect divisoid
    with component-wise partial division.
\item
Later, in \sref{andthen-effect-divisoid},
    we will see that if~$C$ is a~$\&$-effectus,
then~$(\Scal C)^{\mathrm{op}}$ (the scalars with multiplication in the
    opposite direction)
    is an effect divisoid.
\item
If~$M$ is a division effect monoid as in \cite[Dfn.~6.3]{kentapartial},
then~$M^{\textrm{op}}$ is an effect divisoid in the obvious way.
\item
The effect monoid on the unit interval of~$C[0,1]$
    is \emph{not} an effect divisoid,
    but the effect monoid on the unit interval of~$L^\infty[0,1]$
    is, see \sref{basic-divisoid-equiv}.
\end{enumerate}
\end{point}
\begin{point}[basic-divisoid-equiv]{Exercise}%
Let~$X$ be a compact Hausdorff space.
In this exercise we will show
    that the unit interval of~$C(X)$
    is an effect divisoid
    if and only if~$X$
    is \Define{basically disconnected}
    \cite[1H]{gillman2013rings}
    --- that is: if~$\overline{\supp f}$ is open
    for every~$f \in C(X)$.
Equivalently:
$C(X)$ is~$\sigma$-Dedekind complete
    \cite[3N.5]{gillman2013rings}
(i.e.~$C(X)$ has countable infima and suprema).
\begin{enumerate}
\item
    Let~$C(X)$ is an effect divisoid
        together with some~$f \in C(X), 0 \leq f \leq 1$.
    Pick any~$y \notin \overline{\supp f}$.
    Show, using Urysohn's lemma,
    that there is a~$g \in C(X), 0\leq g \leq \rfrac{f}{f}$
    with~$g(y) = 0$ and $g(x) = 1$ for all~$x \in \overline{\supp f}$.
    Show that this implies~$(\rfrac{f}{f})(y) = 0$
        and so~$\rfrac{f}{f}$ is the characteristic function
    of~$\overline{\supp f}$.  Conclude~$X$ is basically disconnected.
\item
Assume~$X$ is basically disconnected.
Let~$f,g\in C(X)$ with~$0 \leq f \leq g \leq 1$.
For~$n > 0$,
show that~$U_n \equiv \{ x;\ g(x) > \frac{1}{n} \}$
has open closure and so
\begin{equation*}
    h_n \ \equiv \  \begin{cases}
        \frac{f(x)}{g(x)} & x \in \overline{U_n}\\
        0 & \text{otherwise}.
    \end{cases}
\end{equation*}
is continuous.
Note~$h_1 \leq h_2 \leq \ldots $
    and define~$\rfrac{f}{g} = \sup_n h_n$.
Show~$\rfrac{f}{f}$ is the characteristic function
    of~$\overline{\supp f}$ and
    $\rfrac{f}{g} \leq \rfrac{g}{g}$.
Prove that this partial division turns the unit interval of~$C(X)$
    into an effect divisoid.
\end{enumerate}

\end{point}
\begin{point}{Exercise}%
Show that for an effect divisoid~$M$, the following holds.
\begin{enumerate}
\item
    $\rfrac{0}{0}=0$, $\rfrac{1}{1}=1$, $\rfrac{a}{1}=a$, $\rfrac{a}{a} \odot \rfrac{a}{a} = \rfrac{a}{a}$ and
    $\rfrac{a \odot b}{a} = \rfrac{a}{a }\odot b$.
\item
    For any~$a \leq b \leq c$,
    we have~$\rfrac{b}{c} \odot \rfrac{a}{b} = \rfrac{a}{c}$.
\end{enumerate}
\end{point}
\begin{point}{Proposition}%
If $a \perp b$ and~$a \ovee b \leq c$ in an effect divisoid,
then~$\rfrac{a \ovee b}{c } = \rfrac{a}{c} \ovee \rfrac{b}{c}$.
\begin{point}{Proof}%
We will first show that if~$c \odot a \perp c \odot b$,
    then~$\rfrac{c}{c} \odot a \perp \rfrac{c}{c}\odot b$.
To start,
    note~$c \odot b^\perp \leq c \odot b^\perp \ovee c^\perp
        = (c \odot b)^\perp \leq c \odot a$
        and so
\begin{equation*}
     \rfrac{c \odot a}{c} 
     \ = \ 
            \rfrac{c \odot b^\perp}{c} \odot
            \rfrac{c \odot a}{c \odot b^\perp}
     \ = \ 
            \rfrac{c}{c} \odot b^\perp \odot
            \rfrac{c \odot a}{c \odot b^\perp}
    \ \leq \ \rfrac{c}{c} \odot b^\perp.
\end{equation*}
Hence~$(\rfrac{c}{c}\odot b)^\perp
            \geq \rfrac{c}{c} \odot b^\perp
            \geq \rfrac{c}{c \odot a}
            = \rfrac{c}{c} \odot a $.
    Indeed:~$\rfrac{c}{c}\odot a \perp \rfrac{c}{c} \odot b$.
\begin{point}%
Assume~$a\perp b$ and~$a\ovee b \leq c$. 
Clearly~$c \odot \rfrac{a}{c}  = a \perp b = c \odot \rfrac{b}{c}$.
By our initial lemma, we get
    $\rfrac{a}{c } =
    \rfrac{c}{c} \odot \rfrac{a}{c} \perp
    \rfrac{c}{c} \odot \rfrac{b}{c} =
    \rfrac{b}{c }
$.
Clearly~$c \odot (\rfrac{a}{c} \ovee \rfrac{b}{c}) = a \ovee b$, so
\begin{equation*}
    \rfrac{a \ovee b}{c} \ = \  
    \rfrac{c \odot (\rfrac{a}{c} \ovee \rfrac{b}{c})}{c} \ = \ 
\rfrac{c}{c} \odot (\rfrac{a}{c} \ovee \rfrac{b}{c}) \ = \ 
\rfrac{c}{a} \ovee \rfrac{c}{b},
\end{equation*}
as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
The following is a generalization
of~\cite[Prop.~C.3]{kentapartial}.
See also~\cite[Prop.~15]{statesofconvexsets}.
\end{point}
\begin{point}{Theorem}%
If~$M$ is an effect divisoid,
    then~$\AConvM$ is an effectus.
\begin{point}{Proof}%
It only remains to be shown that the square on the left
    of \eqref{pullbacks} is a pullback in~$\AConvM$
    --- the other axioms are proven in \sref{aconvalmosteffectus}.
\begin{equation*}
\xymatrix{
    Z \ar@/^1pc/[rrd]^\beta
        \ar@/_1pc/[rdd]_\alpha
        \ar@{.>}[rd]|\gamma\\
        &X+Y \ar[r]^{\id+!} \ar[d]^{!+\id} & X+1\ar[d]^{!+\id} \\
        &1+Y\ar[r]_{\id+!} & 1+1
    }
\end{equation*}
To this end, assume~$\alpha\colon Z \to X+1$
and~$\beta\colon Z \to Y+1$
are maps in~$\AConvM$
with~$(! + \id) \after \beta = (\id+!)\after \alpha$.
We have to show there is a unique~$\gamma\colon Z \to X+Y$ in~$\AConvM$
with~$(\id+!)\after \gamma =\beta$
and~$(!+\id) \after \gamma =\alpha$.
Pick any~$z \in Z$.
Write~$\cdot$ for the unique element of~$1$.
By construction of the coproduct, see \sref{aconv-coprod},
we have
\begin{align*}
    \alpha(z) &\ =\  h_1\Bigl(\lambda_0 \ket{\kappa_1(\cdot)}
    \ovee \bigovee^n_{i=1} \lambda_i \ket{\kappa_2(y_i)}\Bigr) \\
        \beta(z) &\ =\  h_2 \Bigl(\sigma_0 \ket{\kappa_2(\cdot)}
        \ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)}\Bigr)
\end{align*}
for some~$\lambda_i, \sigma_i \in M$,
    $x_i \in X$ and $y_i \in Y$,
    where~$h_1$ and~$h_2$ are the convex structures
    on~$1+Y$ and~$X+1$, respectively.
Unfolding definitions
    (and identifying~$1+1 \cong M$ with~$\kappa_1 (\cdot) = 1$),
    it is easy to
    see that by assumption
\begin{equation}\label{aconv-epb-ass}
    \bigovee^m_{i=1} \sigma_i \ = \ 
    (!+\id)(\beta(z))  \ = \ 
    (\id + !)(\alpha(z)) \ =\  \lambda_0
    \ = \ \Bigl(\bigovee^n_{i=1} \lambda_i\Bigr)^\perp.
\end{equation}
So we are tempted to define
\begin{equation}\label{aconvmexpuldefgamma}
    \gamma(z) \ = \  h_3 \Bigl(
    \bigovee^n_{i=1} \lambda_i \ket{\kappa_2(y_i)}
        \ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)}\Bigr),
\end{equation}
where~$h_3$ is the convex structure on~$X+Y$.
To show this a proper definition,
let~$n',m'\in \N$, $\lambda'_i, \sigma'_i \in M$,
$x'_i \in X$ and $y'_i \in Y$ be (other) elements such that
\begin{align*}
    \alpha(z) &\ =\ 
    h_1\Bigl(\lambda'_0 \ket{\kappa_1(\cdot)}
    \ovee \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}\Bigr) \\
        \beta(z) &\ =\  h_2 \Bigl(\sigma'_0 \ket{\kappa_2(\cdot)}
    \ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)}\Bigr).
\end{align*}
\begin{point}%
We have to show
\begin{multline}\label{convexpulgoal}
    h_3 \Bigl(
    \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
    \,\ovee\, \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)}\Bigr) \\
    \ = \ 
    h_3 \Bigl(
    \bigovee^n_{i=1} \lambda_i \ket{\kappa_2(y_i)}
        \,\ovee\, \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)}\Bigr).
\end{multline}
Without loss of generality,
    we may assume~$n,n',m,m' \geq 1$
    (as we allow, for instance,~$\lambda_1=0$).
Due to \eqref{aconv-epb-ass},
 it is clear~$\lambda_0 = \lambda_0'$ and~$\sigma_0=\sigma_0'$.
By \sref{elements-coprod-conv}
    we know there
    are derivations~$\Phi_1, \ldots, \Phi_l \in \mathcal{D}_M^2 (1+Y)$
    and~$\Psi_1, \ldots, \Psi_k \in \mathcal{D}_M^2 (X+1)$,
    say~$\Phi_i \equiv \bigovee_j \zeta_{ij} \ket{\varphi_{ij}}$,
    $\Psi_i \equiv \bigovee_j \xi_{ij} \ket{\psi_{ij}}$
    with
\begin{align*}
    \Phi_1 &\ = \ \ket{\,
    \lambda_0 \ket{\kappa_1(\cdot)}
\ovee \bigovee^{n}_{i=1} \lambda_i \ket{\kappa_2(y_i)} \,} &
    \Phi_l &\ = \ \ket{\,
    \lambda_0 \ket{\kappa_1(\cdot)}
\ovee \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)} \,} \\
    \Psi_1 &\ = \ \ket{\,
    \sigma_0 \ket{\kappa_2(\cdot)}
\ovee \bigovee^{m}_{i=1} \sigma_i \ket{\kappa_1(x_i)} \,} &
    \Psi_k &\ = \ \ket{\,
    \sigma_0 \ket{\kappa_2(\cdot)}
\ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)} \,}.
\end{align*}
We are going to combine the~$\Phi_i$ and~$\Psi_i$
into a single derivation of~\eqref{convexpulgoal}
    by first `applying' the $\Phi_i$ and then
    the~$\Psi_i$.
Define~$\Omega_1, \ldots, \Omega_{l+k} \in \mathcal{D}_M^2 (X+Y)$ by
\begin{align*}
    \Omega_i  &\ = \ \bigovee_j\zeta_{ij} \ket{\omega_{ij}}
        &&\text{for $1 \leq i \leq l$}
    \\
    \Omega_{i+l}  &\ = \ \bigovee_j \xi_{ij} \ket{\omega_{(i+l)j}}
        &&\text{for $1 \leq i \leq k$,}
\end{align*}
where~$\omega_{ij} \in \mathcal{D}_M(X+Y)$
are given by
\begin{align*}
    \omega_{ij} (\kappa_2 (y)) &\ =\ \varphi_{ij}(\kappa_2(y))  \\
    \omega_{ij} (\kappa_1(x)) &\ = \ 
    \varphi_{ij}(\kappa_1(\cdot))\odot
    ( \rfrac{\psi_{11}(\kappa_1(x))}{\lambda_0}
    \ovee r(\kappa_1(x)))
    \\
    \omega_{(i+l)j} (\kappa_1(x)) &\ =\ \psi_{ij}(\kappa_1(x)) \\
    \omega_{(i+l)j} (\kappa_2 (y)) &\ =\ 
    \psi_{ij}(\kappa_2(\cdot)) \odot (
    \rfrac{\varphi_{l1}(\kappa_2(y))}{\sigma_0}
    \ovee r(\kappa_2(y))) \\
    r(z) & \ = \ 
    \begin{cases}
        (\rfrac{\lambda_0}{\lambda_0})^\perp & z = \kappa_1(x_1) \\
        (\rfrac{\sigma_0}{\sigma_0})^\perp & z = \kappa_2(y_1) \\
        0 & \text{otherwise},
    \end{cases}
\end{align*}
    where on the first two lines~$1 \leq i \leq l$
    and on the second two~$1 \leq i \leq k$.
Before we continue, we check whether the~$\omega_{ij}$
    are distributions, as claimed.
For~$1 \leq i \leq l$
    this amounts to $\bigovee_x \omega_{ij}(\kappa_1(x))
= \varphi_{ij}(\kappa_1(\cdot))$.
Indeed
\begin{align*}
\bigovee_x
    \omega_{ij}(\kappa_1(x))
    & \  =\  \varphi_{ij}(\kappa_1(\cdot)) \odot r(\kappa_1(x_1))
            \,\ovee\, \bigovee_x 
        \varphi_{ij}(\kappa_1(\cdot)) \odot
        \rfrac{\psi_{11}(\kappa_1(x))}{\lambda_0} \\
        & \  =\  \varphi_{ij}(\kappa_1(\cdot)) \odot (\rfrac{\lambda_0}{\lambda_0})^\perp
            \,\ovee \,
        \varphi_{ij}(\kappa_1(\cdot)) \odot
        \rfrac{\bigovee_x \psi_{11}(\kappa_1(x))}{\lambda_0} \\
        & \  =\  \varphi_{ij}(\kappa_1(\cdot)) \odot (\rfrac{\lambda_0}{\lambda_0})^\perp
            \,\ovee \,
        \varphi_{ij}(\kappa_1(\cdot)) \odot
        \rfrac{\lambda_0}{\lambda_0} \\
        & \  =\  \varphi_{ij}(\kappa_1(\cdot)).
\end{align*}
With an analogous argument, one checks~$\omega_{(i+l)j}$
    is a distribution for~$1 \leq i \leq k$.

To show~$\Omega_i$ is
    a derivation (in the sense of \sref{elements-coprod-conv}),
    first pick any~$1 \leq i < l$.
We distinguish between the two allowable derivation steps.
If~$ \mu(\Phi_i) = \mu(\Phi_{i+1}) $,
    then~$\mu(\Omega_i) = \mu(\Omega_{i+1})$
    by a straight-forward computation
    and so~$\Omega_i$ has a valid step.
In the other case, we have~$\zeta_{ij} = \zeta_{(i+1)j}$ and
    for each~$j$ we have three possibilities.
In the first case, if~$\varphi_{ij} = \varphi_{(i+1)j}$,
    then clearly~$\omega_{ij} = \omega_{(i+1)j}$ as well.
    For the second case, assume~$\varphi_{ij} = (\mathcal{D}_M \kappa_2) (\chi)$
    and~$\varphi_{(i+1)j} = (\mathcal{D}_M \kappa_2) (\chi')$
    for some~$\chi,\chi' \in \mathcal{D}_M Y$
    with~$h_Y(\chi) = h_Y(\chi')$.
    Clearly~$\varphi_{ij}(\kappa_1(\cdot)) = 0$
    and so~$\omega_{ij} = (\mathcal{D}_M \kappa_2)(\chi)$.
    Similarly~$\omega_{(i+1)j} = (\mathcal{D}_M \kappa_2)(\chi')$.
    The third case is trivial.
    So~$\Omega_i$ also makes a valid step of the second kind.

With the same kind of argument, we cover
    $\Omega_{i+l}$ for~$1 \leq i < k$.
The only step left to check is the one
    from~$\Omega_l$ to~$\Omega_{l+1}$.
Note~$\zeta_{l1}=1$,~$\varphi_{l1}(\kappa_1(\cdot)) = \lambda_0$
and~$\lambda_0 \odot  (\rfrac{\lambda_0}{\lambda_0})^\perp = 0$,
so with some easy manipulation, we find
\begin{equation*}
    \Omega_l \ = \  \ket{
        \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
\, \ovee\,  \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)} }.
\end{equation*}
and in a similar fashion
\begin{align*}
    \Omega_{l+1} & \ = \  \ket{
        \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
    \, \ovee\,  \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)} } \\
    \Omega_{1} & \ = \  \ket{
        \bigovee^{n}_{i=1} \lambda_i \ket{\kappa_2(y_i)}
\,\ovee\, \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)} } \\
    \Omega_{l+k} & \ = \  \ket{
        \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
    \,\ovee\, \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)} }.
\end{align*}
So~$\Omega_i$ is a valid derivation of \eqref{convexpulgoal}.
\end{point}
\begin{point}%
We are in the home stretch now.
Define~$\gamma(z)$ as in \eqref{aconvmexpuldefgamma}.
It is easy to see~$\gamma$
    is the unique map with~$(\id+!) \after \gamma = \beta$
    and~$(!+\id)\after \gamma = \alpha$.
It remains to be shown~$\gamma$ is affine.
Write
\begin{equation*}
q_1\colon \mathcal{D}_M(X+Y) \to X+Y \quad
q_2\colon \mathcal{D}_M(1+Y) \to 1+Y \quad
q_3\colon \mathcal{D}_M(X+1) \to X+1
\end{equation*}
for the quotient-maps used in the construction of the coproducts.
We worked hard to show
that
for all~$z \in Z$, $\varphi \in \mathcal{D}_M Y$,
$\psi \in \mathcal{D}_M X$, 
and~$\chi \in \mathcal{D}_M (X+Y)$
with~$\chi(\kappa_1 (y)) = \varphi(\kappa_1(y))$
and~$\chi(\kappa_2 (x)) = \psi(\kappa_2(x))$,
we have
\begin{equation*}
    \left.\begin{array}{ll}
    \alpha(z)\ =\ q_1(\varphi) \\
    \beta(z)\ =\ q_2(\psi)
    \end{array}\right] \quad \implies \quad
    \gamma(z) = q_3(\chi).
\end{equation*}
Assume~$z = h_Z(\bigovee_i \lambda_i \ket{z_i})$.
We want to show~$\gamma(z) = h_3(\bigovee_i \lambda_i \ket{\gamma(z_i)})$.
To this end, pick~$\varphi_i$, $\psi_i$, $\chi_i$
with~$\alpha(z_i) = q_1(\varphi_i)$,
$\beta(z_i) = q_2(\psi_i)$,
$\chi_i(\kappa_1(y)) = \varphi_i(\kappa_1(y))$
and $\chi_i(\kappa_2(x)) = \psi_i(\kappa_2(x))$.
So $\gamma(z_i) = q_3(\chi_i)$.
Define~$\varphi,\psi,\chi$ as follows.
\begin{align*}
\varphi &\ \equiv\  \mu\bigl(\bigovee_i \lambda_i \ket{\varphi_i}\bigr)&
\psi &\ \equiv\  \mu\bigl(\bigovee_i \lambda_i \ket{\psi_i}\bigr) &
\chi &\ \equiv\  \mu\bigl(\bigovee_i \lambda_i \ket{\chi_i}\bigr)
\end{align*}
Note
$q_1(\varphi)
    = h_1(\bigovee_i \lambda_i \ket{q_1(\varphi_i)})
    = h_1(\bigovee_i \lambda_i \ket{\alpha(z_i)})
    = \alpha(\bigovee_i \lambda_i \ket{z_i})
    = \alpha(z)$.
Similarly~$q_2(\psi) = \beta(z)$.
For any~$y \in Y$,
    we have
    $
    \chi(\kappa_1(y))
    = \bigovee_i \lambda_i \odot \chi_i(\kappa_1(y))
    = \bigovee_i \lambda_i \odot \varphi_i(\kappa_1(y))
    = \varphi(\kappa_1(y))
    $.
Similarly~$\chi(\kappa_2(x)) = \psi(\kappa_2(x))$ for any~$x \in X$.
So~$\gamma(z) = q_3(\chi)$ and consequently
\begin{equation*}
    \gamma(z) \ = \ q_3(\chi)
    \ = \ h_3\bigl(\bigovee_i \lambda_i\ket{q_3(\chi_i)} \bigr)
    \ = \ h_3\bigl(\bigovee_i \lambda_i\ket{\gamma(z_i)} \bigr),
\end{equation*}
as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}

\section{Quotient}
\begin{parsec}%
\begin{point}%
We are ready to introduce our first additional axiom:
    the existence of quotients.
\end{point}
\begin{point}{Definition}%
Let~$C$ be an effectus.
We say~$C$ is an \Define{effectus with quotients}
    if for each predicate~$p \colon X \to 1$,
    there exists a map~$\xi_p \colon X \to X/_p$
    with~$1 \after \xi_p \leq p^\perp$
    satisfying the following universal property:
\begin{quote}
    for any (other) map~$f\colon X \to Y$
        with~$1 \after f \leq p^\perp$,
        there is a unique map~$f' \colon X/_p \to Y$
        such that~$f' \after \xi_p = f$.
\end{quote}
Any  map with this universal property
    is called a \Define{quotient} for~$p$.
\end{point}
\begin{point}{Example}%
In~$\op{\vN}$ quotients are exactly the same thing
    as contractive filters,
    see~\sref{dils-def-filter}, \sref{filter}
    and~\sref{canonical-filter}.
An example of a quotient-map for~$1-a \in \scrA$ is given
    by~$\xi\colon \ceil{a}\scrA \ceil{a} \to \scrA$
    with~$\xi(b) = \sqrt{a} b \sqrt{a}$.
\end{point}
\begin{point}[quotient-basics]{Exercise}%
Show the following basic properties of quotients.
\begin{enumerate}
    \item If~$\xi\colon X \to Y$ is a quotient for~$p$
                and~$\vartheta\colon Y \to Z$ is an isomorphism,
                then~$\vartheta \after \xi$ is a quotient for~$p$
                as well.
    \item Conversely, if~$\xi_1$ and~$\xi_2$
            are both quotients for~$p$,
            then there is unique a isomorphism~$\vartheta$
            with~$\xi_1 = \vartheta \after \xi_2$.
    \item Isomorphisms are quotients (for 0).
    \item Zero-maps are quotients (for 1).
    \item If~$\xi$ is a quotient for~$p$, then~$1\after \xi = p^\perp$
                (Hint: apply the universal property to $p^\perp$).
    \item Quotients are epi.
\end{enumerate}
\begin{point}%
The following proposition is easy to prove,
    but shows an important property of quotients:
    any map~$f$ factors as a total map after a quotient
    for~$(1\after f)^\perp$.
\end{point}
\end{point}
\begin{point}[quotient-total]{Proposition}%
Assume~$\xi_{p^\perp} \colon X \to X/_{p^\perp}$ is a quotient for~$p^\perp$.
For any~$f\colon X \to Z$
    with~$1 \after f = p$,
    there is a unique \emph{total} $g\colon X/_{p^\perp} \to Z$
    with~$f = g \after \xi_{p^\perp}$.
\begin{point}{Proof}%
By definition of quotient, there is a unique~$g\colon X/_{p^\perp} \to Z$
    with~$g \after \xi_{p^\perp} = f$.
Note~$1 \after g \after \xi_{p^\perp} = 1 \after f = p = 1 \after \xi_{p^\perp}$.
Thus, as~$\xi_{p^\perp}$ is epi (\sref{quotient-basics}),
    we conclude~$1 \after g = 1$.
That is: $g$ is total. \qed
\end{point}
\end{point}
\begin{point}[quotients-composition]{Proposition}%
In an effectus with quotients,
    quotients are closed under composition.
\begin{point}{Proof}%
Assume~$\xi_1\colon X \to Y$ is a quotient for~$p^\perp$
    and~$\xi_2\colon Y \to Z$ is a quotient for~$q^\perp$.
We will prove~$\xi_2 \after \xi_1$
    is a quotient for~$(q \after \xi_1)^\perp$.
As our effectus has quotients,
    we can pick a quotient~$\xi \colon X \to X/_{(q \after \xi_1)^\perp}$
        of~$(q \after \xi_1)^\perp$.
First, some preparation.
Note~$1 \after \xi = q \after \xi_1 \leq 1 \after \xi_1 = p$.
Thus by the universal property of~$\xi_1$,
there is a unique map~$h_1\colon Y \to X/_{(q \after \xi_1)^\perp}$
        with~$h_1 \after \xi_1 = \xi$.
As~$1 \after h_1 \after \xi_1 = 1 \after \xi = q \after \xi_1$
    and~$\xi_1$ is epi, we see~$1 \after h_1 = q$.
Thus by \sref{quotient-total},
there is a unique total map~$h_2 \colon Z \to X/_{(q \after \xi_1)^\perp}$
    with~$h_2 \after \xi_2 = h_1$.
Let~$g\colon X/_{(q \after \xi_1)^\perp} \to Z$
    be the unique map such that~$g \after \xi = \xi_2 \after \xi_1$.
We are in the following situation.
\begin{equation*}
    \xymatrix@C+2pc{
        X  \ar[r]^{\xi_1} \ar@/_/[rrd]_{\xi}
        & Y \ar[r]^{\xi_2} \ar@{.>}[rd]_{h_1}
        & Z \ar@{.>}@/^/[d]^{h_2} \\
        && X/_{(q \after \xi_1)^\perp} \ar@{.>}@/^/[u]^{g}
    }
\end{equation*}
We claim~$g$ is an isomorphism with inverse~$h_2$.
Indeed: from $g \after h_2 \after \xi_2 \after \xi_1= g \after \xi = \xi_2 \after \xi_1$
    we get~$g \after h_2 = \id$
    and from~$h_2 \after g \after \xi = h_2 \after \xi_2 \after \xi_1 = \xi$
    we find~$h_2 \after g = \id$.
Thus~$\xi_2 \after \xi_1 = g \after \xi$ for an isomorphism~$g$,
which shows~$\xi_2 \after \xi_1$ is a quotient, see \sref{quotient-basics}. \qed
\end{point}
\end{point}
\begin{point}{Exercise}
By \sref{quotient-total} we know that each
    map~$f$ factors as~$t \after \xi$
    for some total map~$t$ and quotient~$\xi$.
Show that this forms an orthogonal factorization system ---
    that is: prove that if~$t' \after \xi' = t \after \xi$
    for some (other) quotient~$\xi'$ and total map~$t'$,
    then there is a unique isomorphism~$\vartheta$
    with~$\xi' = \vartheta \after \xi$
    and~$t = t' \after \vartheta$.
\end{point}
\end{parsec}

\section{Comprehension and images}
\begin{parsec}%
\begin{point}{Definition}%
Let~$C$ be an effectus.
We say~$C$ \Define{has comprehension}
    if for each predicate~$p \colon X \to 1$,
    there exists a map~$\pi_p \colon \cmpr{X}{p} \to X$
    with~$p \after \pi_p = 1 \after \pi_p$
    satisfying the following universal property:
\begin{quote}
    for any (other) map~$g\colon Z \to X$
        with~$p \after g = 1 \after g$,
        there is a unique map~$g' \colon Z \to \cmpr{X}{p}$
        such that~$\pi_p \after g' = g$.
\end{quote}
Any  map with this universal property
    is called a \Define{comprehension} for~$p$.
\begin{point}{Beware}%
    We do not assume comprehensions are total
    (in contrast to \cite{effintro}).
\end{point}
\begin{point}[compr-not]{Notation}%
Unless otherwise specified~$\pi_p$ will be some
    comprehension of~$p$.
\end{point}
\end{point}
\begin{point}{Example}%
In~$\op{\vN}$ comprehensions are exactly the same thing
    as corners, see \sref{dils-corner} or \sref{corner}.
An example of a comprehension for~$a \in \scrA$
    is given by~$\pi\colon \scrA \to \floor{a}\scrA\floor{a}$
    with~$\pi(b) = \floor{a}b\floor{a}$
    as proven in \sref{prop-corner}.
\end{point}
\begin{point}[compr-basics]{Exercise}%
Show the following basic properties of comprehensions.
\begin{enumerate}
    \item If~$\pi\colon X \to Y$ is a comprehension for~$p$
                and~$\vartheta\colon Z \to X$ is an isomorphism,
                then~$\pi \after \vartheta$ is a comprehension for~$p$
                as well.
    \item Conversely, if~$\pi_1$ and~$\pi_2$
            are both comprehensions for~$p$,
            then there is unique a isomorphism~$\vartheta$
            with~$\pi_1 = \pi_2 \after \vartheta$.
    \item Isomorphisms are comprehensions (for 1).
    \item Zero-maps are comprehensions (for 0).
    \item Comprehensions are mono.
    \item $p^\perp \after \pi = 0$ if~$\pi$ is a comprehension of~$p$.
\end{enumerate}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
Comprehensions and kernels are very similar.
\end{point}
\begin{point}{Definition}%
Let~$C$ be a category with a zero object.
A \Define{kernel}~of an arrow~$f$
    (in symbols: $\Define{\ker f}$)
    is an equalizer of~$f$ with the zero-map.
(That is: $f \after (\ker f) = 0$
    and for every~$g$ with~$f \after g = 0$,
    there exists a unique~$g'$ with~$(\ker f) \after g' = g$.)
We will use \Define{$\cok f$}
    to denote a cokernel of~$f$
    --- that is: a kernel of~$f$ in~$\op{C}$.
\end{point}
\begin{point}[effectus-kernels]{Proposition}%
An effectus with comprehension has all kernels.
    The kernel of a map~$f$ is given by
        a comprehension~$\pi_{(1 \after f)^\perp}$
        of~$(1 \after f)^\perp$.
\begin{point}{Proof}%
Clearly~$1 \after f \after \pi_{(1 \after f)^\perp} = 0$
    and so~$f \after \pi_{(1 \after f)^\perp} = 0$.
Assume~$g$ is some other map with~$f \after g = 0$.
Then~$1 \after f \after g = 0$
    and so~$(1 \after f)^\perp \after g = 1 \after g$.
Thus there exists a unique~$g'$
    with~$\pi_{(1 \after f)^\perp} \after g' = g$. \qed
\end{point}
\end{point}
\begin{point}[compr-is-kernel]{Exercise}%
Show that in an effectus,
    a map~$f$ is a comprehension for~$p$
    if and only if it is a kernel of~$p^\perp$.
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
We are ready to define purity in effectuses.
\end{point}
\begin{point}{Definition}%
In an effectus a map~$f$ is called \Define{pure}
    if~$f = \pi \after \xi$
    for some comprehension~$\pi$
    and quotient~$\xi$.
\end{point}
\begin{point}{Example}%
In $\op{\vN}$
the pure maps~$\scrB(\scrH) \to \scrB(\scrK)$
    are exactly the maps of the form~$\ad_T$
    where~$T$ is a contractive map~$\scrK \to \scrH$. \TODO{ref}
\end{point}
\begin{point}%
We do not have a good handle on the structure of pure maps in
    an arbitrary effectus.  We will need a few additional assumptions.
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}{Definition}%
Let~$C$ be an effectus.
\begin{enumerate}
\item
We say~$C$ has \Define{images}
    if for each map~$f\colon X \to Y$,
    there is a least predicate~$\Define{\IM f}$ on~$Y$
        with the property~$(\IM f) \after f = 1 \after f$ ---
        that is, 
    for every (other) predicate~$p$ on~$Y$
    with~$p \after f = 1 \after f$,
    we must have~$\IM f \leq p$.
For brevity, write~$\Define{\IMperp f} \equiv (\IM f)^\perp$. 
Note~$\IMperp f$ is the greatest predicate
with the property~$(\IMperp f) \after f = 0$.
\item
We say a map~$f\colon X \to Y$ is \Define{faithful}
    if~$\IM f = 1$.
That is: $f$ is faithful if and only if
    $p \after f = 0$ implies~$f = 0$
    for every predicate~$p$.
\end{enumerate}
\begin{point}{Notation}%
The expression~$\IM f \after g$
    is read as~$\IM (f \after g)$.
\end{point}
\begin{point}%
The predicate~$\IM f$ will play for comprehension the same role
    as~$1 \after f$ plays for quotients.
Similarly faithful is the analogue of total.
\end{point}
\end{point}
\begin{point}{Example}%
In $\op{\vN}$ the image of a map~$f\colon \scrA \to \scrB$
    is given by the least projection~$e \in \scrA$
    with the property~$f(1-e) = 0$.
This~$e$ is the complement of the projection onto the kernel of~$f$.
The map~$f$ is faithful if and only
    if~$f(a^*a)=0$ implies~$a^*a = 0$
    for all~$a\in \scrA$.
\end{point}
\begin{point}[im-ineq]{Exercise}%
Show~$\IM f \after g \leq \IM f$.
Conclude~$\IM f \after \alpha = \IM f$
    for any iso~$\alpha$.
\end{point}
\begin{point}{Exercise}%
Show that in an effectus, any quotient is faithful.
\end{point}
\begin{point}%
In contrast to quotients,
    it is not clear at all whether (without additional assumptions)
    comprehensions are total;
    they are part of a factorization system
    or are closed under composition.
\end{point}
\begin{point}[compr-total]{Lemma}%
In an effectus with quotients, comprehensions are total.
\begin{point}{Proof}%
Assume~$\pi$ is some comprehension for~$p$.
Let~$\xi$ be a quotient for~$(1 \after \pi)^\perp$.
There is a total~$\pi_t$ with~$\pi = \pi_t \after \xi$.
As~$ 1 \after \pi_t \after \xi
        = 1 \after \pi
        = p \after \pi
        = p \after \pi_t \after \xi$
        and~$\xi$ is epi,
        we see~$1 \after \pi_t = p \after \pi_t$.
Thus, as~$\pi$ is a comprehension for~$p$,
    there exists an~$f$ with~$\pi_t = \pi \after f$.
Now~$\pi = \pi_t \after \xi = \pi \after f \after \xi$
    and so~$\id = f \after \xi$, since~$\pi$ is mono.
Hence~$1 = 1 \after \id =1 \after f \after \xi \leq 1 \after \xi = 1 \after \pi$
    and so~$\pi$ is total. \qed
\end{point}
\end{point}
\end{parsec}
\subsection{Sharp predicates}
\begin{parsec}%
\begin{point}{Definition}%
Let~$C$ be an effectus with comprehension and images.
\begin{enumerate}
\item
    We say a predicate~$p$ is (image) \Define{sharp}
        if~$p = \IM f$ for some map~$f$.
    Write~$\SPred X$ for the set of all sharp predicates on~$X$.
\item
We define~$\Define{\floor{p}} = \IM \pi_p$,
    where~$\pi_p$ is some comprehension for~$p$.
(Comprehensions for the same predicate have the same image
    by \sref{im-ineq}.)
Also write~$\Define{\ceil{p}} = \floor{p^\perp}^\perp$.
\end{enumerate}
\begin{point}{Beware}%
In \cite{effintro} $p$ is called sharp whenever~$p \wedge p^\perp=0$.
In general this is weaker than image-sharpness, which we use in this text.
In~\sref{floor-basics}
    we will see~$\floor{p}$ is sharp.
It is unclear whether~$\ceil{p}$ is sharp (without additional
    assumptions).
\end{point}
\end{point}
\begin{point}{Example}%
In $\op{\vN}$ the sharp predicates are the projections.
For a predicate~$a \in \scrA$,
    the sharp predicate~$\ceil{a}$
    is the least projection above~$a$.
\end{point}
\begin{point}[floor-basics]{Lemma}%
In an effectus with comprehension and images, we have
\begin{multicols}{2}
\begin{enumerate}
\item
    $\floor{p} \leq p$
\item
    $\pi_p = \pi_{\floor{p}} \after \alpha$
        for some iso~$\alpha$;
\item
    $\floor{\floor{p}} = \floor{p}$;
\item
    $p \leq q$ $\implies$ $\floor{p} \leq \floor{q}$;
\item
    $\ceil{p} \after f \leq \ceil{p \after f}$ \emph{and}
\item
    $\ceil{p} \after f =0$ iff~$p \after f = 0$,
\end{enumerate}
\end{multicols}
\noindent for any map~$f\colon X \to Y$,
    predicates~$p,q$ on~$X$ and
$\pi_p$ and~$\pi_{\floor{p}}$
    comprehensions for~$p$ and~$\floor{p}$ respectively.
\begin{point}{Proof}%
We will prove the statements in listed order.
\begin{point}{Ad 1}%
    Let~$\pi$ be a comprehension for~$p$.
    By definition~$p \after \pi = 1 \after \pi$.
    Thus~$\floor{p} = \IM \pi \leq p$, as desired.
\end{point}
\begin{point}{Ad 2}%
It is sufficient to show~$\pi_p$ is a comprehension for~$\floor{p}$.
First, note~$\floor{p}\after \pi_p = (\IM \pi_p) \after \pi_p = 1 \after \pi_p$.
To show the universal property,
    assume~$g\colon Z \to X$
    is some map with~$\floor{p} \after g = 1 \after g$.
Then~$1 \after g = \floor{p} \after g \leq p \after g \leq 1 \after g$
    and so~$1 \after g = p \after g$.
As~$\pi_p$ is a comprehension for~$p$,
    there is a unique~$g'$ with~$\pi_p \after  g' = g$
    and so~$\pi_p$ is indeed a comprehension for~$\floor{p}$ as well.
\end{point}
\begin{point}{Ad 3}%
Follows from the previous and \sref{im-ineq}.
\end{point}
\begin{point}{Ad 4}%
Pick a comprehension~$\pi_p$ for~$p$ and~$\pi_q$ for~$q$.
Note~$1 \after \pi_p = p \after \pi_p
                \leq q \after \pi_p \leq 1 \after \pi_p $
so~$q \after \pi_p = 1 \after \pi_p$
and thus~$\pi_p = \pi_q \after f$ for some~$f$.
By~\sref{im-ineq}
    we see~$\floor{p} = \IM \pi_p = \IM \pi_q \after f \leq \IM \pi_q = \floor{q}$.
\end{point}
\begin{point}{Ad 5}%
Clearly~$p \after f \after \pi_{(p \after f)^\perp} = 0$.
(Recall our convention \sref{compr-basics} for $\pi$'s.)
Thus there is some~$h$
with~$f \after \pi_{(p \after f)^\perp} = \pi_{p^\perp}\after h$.
By point 2 there is some (isomorphism)~$\alpha$
    with~$\pi_{p^\perp} =\pi_{\floor{p^\perp}} \after \alpha$.
    We compute
\begin{equation*}
    \ceil{p} \after f \after \pi_{(p \after f)^\perp}
        = \ceil{p} \after \pi_{p^\perp}\after h
        = \ceil{p} \after \pi_{\floor{p^\perp}}\after \alpha\after h
    = \ceil{p} \after \pi_{\ceil{p}^\perp}\after \alpha\after h
    = 0.
\end{equation*}
Thus~$\ceil{p} \after f \leq \IMperp \pi_{(p \after f)^\perp}
= \lfloor(p \after f)^\perp\rfloor^\perp = \ceil{p \after f}$, as promised.
\end{point}
\begin{point}{Ad 6}%
Assume~$\ceil{p}\after f = 0$.
From~$p \leq \ceil{p}$
it follows~$p \after f \leq \ceil{p} \after f = 0$.
Thus~$p \after f = 0$.
For the converse, assume~$p \after f = 0$.
Then~$\ceil{p \after f} = \ceil{0} = (\IM \id)^\perp = 0$
    as~$\id$ is a comprehension for~$1$.
    Thus~$\ceil{p} \after f \leq \ceil{p \after f} = 0$. \qed
\end{point}
\end{point}
\end{point}
\begin{point}[img-of-compr]{Exercise}%
Let~$C$ be an effectus with comprehension and images.
Show that~$p$ is sharp if and only if~$\floor{p}= p$.
Conclude~$\IM \pi_s = s$ for sharp~$s$.
\end{point}
\begin{point}[ceiling-within-ceiling]{Exercise}%
Show that in an effectus with comprehension and images
    we have the equality
    $\ceil{\ceil{p}\after f} = \ceil{p \after f}$
    for any map~$f\colon X \to Y$ and predicate~$p$ on~$X$.
\end{point}
\begin{point}[compr-is-full]{Lemma}%
In an effectus with comprehension and images
    we have
\begin{equation*}
    s \leq t
    \quad \iff \quad
    \pi_s = \pi_t \after h
    \quad \text{for some $h$},
\end{equation*}
for all sharp predicates~$s,t$ on the same object.
\begin{point}{Proof}%
Assume~$\pi_s = \pi_t \after h$.
Then
\begin{equation*}
    s \ \overset{\sref{img-of-compr}}{=}\  \floor{s} \ =\  \IM \pi_s \  = \ \IM \pi_t \after h
    \ \overset{\sref{im-ineq}}{\leq} \ \IM \pi_t = \floor{t} 
            \ \overset{\sref{img-of-compr}}{=} \ t.
\end{equation*}
as desired.
Conversely assume~$s \leq t$.
Then~$t^\perp \after \pi_s \leq s^\perp \after \pi_s = 0$
    and so~$\pi_s = \pi_t \after h$
    for some~$h$ by the universal property of~$\pi_t$. \qed
\end{point}
\end{point}
\begin{point}{Lemma}%
In an effectus with images,
    we have~$\IM [f,g] = (\IM f) \vee (\IM g)$.
\begin{point}{Proof}%
We get~$\IM[f,g] \geq \IM f$ and~$\IM[f,g] \geq \IM  g$
    from
\begin{align*}
    [1 \after f, 1 \after g] 
        &\ =\  1 \after [f,g]  \\ 
        &\ =\ (\IM [f,g]) \after [f,g] \\
        & \ = \  [(\IM [f,g]) \after f, (\IM [f,g]) \after g].
\end{align*}
To show~$\IM [f,g]$ is the least upper-bound,
assume~$p \geq \IM f$ and~$p \geq \IM g$.
Then
\begin{equation*}
    1 \after [f,g] \ \geq\ p \after [f,g] \ =\  [p \after f, p \after g]
                    \ \geq\  [(\IM f) \after f, (\IM g)\after g]
                    \ = \ 1 \after [f,g],
\end{equation*}
    hence~$1 \after [f,g] = p \after [f,g]$
    and so~$p \geq \IM [f,g]$, as desired. \qed
\end{point}
\begin{point}[lattice-compr]{Corollary}%
In an effectus with comprehension and images,
we have for any sharp~$s,t$
    a supremum (among all predicates)
    given by~$s \vee t = \IM[\pi_s, \pi_t]$.
    In particular:~$s \vee t$ is sharp.
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
In \sref{compr-is-kernel} we saw that comprehensions
    are precisely kernels of predicates.
What about cokernels and quotients?
\end{point}
\begin{point}[effectus-cokernels]{Proposition}%
An effectus with quotient and images has all cokernels.
A cokernel of a map~$f$
    is given by a quotient~$\xi_{\IM f}$ of~$\IM f$.
\begin{point}{Proof}%
As~$0 = (\IMperp f) \after f = 1 \after \xi_{\IM f} \after f$,
        we have~$\xi_{\IM f} \after f = 0$.
    Assume~$g$ is any (other) map with~$g \after f = 0$.
Then~$1 \after g \leq \IMperp f$
    and so~$g = g' \after \xi_{\IM f}$
    for a unique~$g'$.
Thus indeed, $\xi_{\IM f}$ is a cokernel of~$f$. \qed
\end{point}
\end{point}
\begin{point}{Exercise}%
Show that in an effectus with comprehension and images,
    a map~$f$ is a quotient of sharp~$s$
    if and only if~$f$ is a cokernel
    of a comprehension~$\pi_s$ of~$s$.
\end{point}
\end{parsec}

\section{$\diamond$-effectus}
\begin{parsec}%
\begin{point}%
In quantum physics it is not uncommon to restrict one's attention
    to sharp predicates (i.e.~projections).
Does this restriction hurt the expressivity?
A partial answer is given by Gleason's famous theorem \cite{gleason1957measures}:
    it states that every (normal) state on~$\scrB(\scrH)$
    is determined by its values on projections
    (if~$\dim \scrH \geq 3$).
We take the idea of restricting oneself to projections
    one step further: we also want to restrict to projections
    for our outcomes.
It is rare for quantum processes to send projections to projections
    (see \sref{exa-sharp-vn}),
    so instead we consider the least projection above the outcome.
The simple idea of taking the restriction to sharp predicates
    seriously, leads to a host of interesting new notions.
We will give these right of the bat and study their relevance later on.
\end{point}
\begin{point}{Definition}%
A~\Define{$\diamond$-effectus}
    is an effectus with quotient, comprehension and images
    such that~$s^\perp$ is sharp for every sharp predicate~$s$.
In a~$\diamond$-effectus
    we define for any map~$f\colon X \to Y$
    the following restrictions to sharp predicates
    \begin{equation*}
        \xymatrix{
            \SPred X  \ar@/^/[r]^{f_\diamond}
            & \SPred Y \ar@/^/[l]^{f^\diamond}}
            \quad \text{by} \quad
            \Define{f^\diamond(s)} = \ceil{s \after f}
            \quad
            \text{and}
            \quad
            \Define{f_\diamond(s)} = \IM f \after \pi_s.
    \end{equation*}
    \begin{enumerate}
        \item
    We say maps~$f \colon X \leftrightarrows Y\colon g$
        are~\Define{$\diamond$-adjoint}
        if~$f^\diamond = g_\diamond$.
    \item
    An endomap~$f\colon X \to X$ is \Define{$\diamond$-self-adjoint}
        if~$f$ is $\diamond$-adjoint to itself.
    \item
    Two maps~$f,g\colon X \to Y$
        are~\Define{$\diamond$-equivalent}
        if~$f^\diamond = g^\diamond$.
    \item
        A pure endomap~$f$ is~\Define{$\diamond$-positive}
            if $f = g\after g$ for some~$\diamond$-self-adjoint~$g$.
    \end{enumerate}
For brevity, write $\Define{f^\BOX(s)} = f^\diamond(s^\perp)^\perp$.
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
Let's investigate the basic properties of~$(\ )^\diamond$, $(\ )_\diamond$
    and $(\ )^\BOX$.
\end{point}
\begin{point}{Exercise}%
Show that in a~$\diamond$-effectus
    both~$f^\diamond$ and~$f^\BOX$ are order preserving maps.
\end{point}
\begin{point}[diamond-adjunction]{Proposition}%
For~$f\colon X \to Y$ in a~$\diamond$-effectus we have
\begin{equation}
    f^\diamond(s) \ \leq\  t^\perp
    \quad \iff
    \quad f_\diamond(t) \ \leq\  s^\perp \label{diamond-main-lemma}
\end{equation}
for all sharp~$s,t$.
In other words: $f_\diamond$ is the left order-adjoint of~$f^\BOX$.
\begin{point}{Proof}%
To start, let's prove the order-adjunction reformulation
\begin{equation*}
    f_\diamond(s) \leq t
    \ \overset{\eqref{diamond-main-lemma}}{\iff} \ 
    f^\diamond(t^\perp) \equiv f^\BOX(t)^\perp \leq s^\perp
            \ \iff \
    s \leq f^\BOX(t).
\end{equation*}
To prove \eqref{diamond-main-lemma},
first assume~$f^\diamond(s) \leq t^\perp$.
Then~$s \after f \leq \ceil{s \after f} = f^\diamond(s) \leq t^\perp
= \IMperp \pi_t$, where the last equality is
due to \sref{img-of-compr}.
Thus~$s \after f \after \pi_t = 0$
    which is to say~$s \leq \IMperp f \after \pi_t$,
    so~$f_\diamond(t) = \IM f \after \pi_t \leq s^\perp$.

For the converse, assume
    $f_\diamond(t) \leq s^\perp$.
Then as before (but in the other direction)
    we find~$s \after f \after \pi_t = 0$
    and so~$s \after f \leq t^\perp$.
    Hence~$f^\diamond(s) =  \ceil{s \after f} \leq \lceil t^\perp\rceil
                = \floor{t}^\perp = t^\perp$, as desired. \qed
\end{point}
\end{point}
\begin{point}[order-adj-basics]{Exercise}%
Use the fact that there is an
order adjunction between~$f_\diamond$ and $f^\BOX$
to show that in a~$\diamond$-effectus
\begin{multicols}{2}
\begin{enumerate}
    \item $f_\diamond$ is order-preserving;
    \item $f_\diamond$ preserves suprema;
    \item $f^\BOX$ preserves infima;
    \item $f^\diamond$ preserves suprema;
    \item $f_\diamond \after f^\BOX \after f_\diamond = f_\diamond$ \emph{and}
    \item $f^\BOX \after f_\diamond \after f^\BOX = f^\BOX$.
\end{enumerate}
\end{multicols}
\end{point}
\begin{point}[diamond-functor]{Lemma}%
In a~$\diamond$-effectus,
we have
\begin{multicols}{3}
\begin{enumerate}
\item
$(\id)^\diamond = \id$,
\item
$(f\after g)^\diamond
            =   g^\diamond \after f^\diamond$,
\item
$(\id)^\BOX = \id$,
\item
$(f\after g)^\BOX
            =   g^\BOX \after f^\BOX$,
\item
$(\id)_\diamond= \id$ and
\item
            $(f \after g)_\diamond = f_\diamond \after g_\diamond$.
\end{enumerate}
\end{multicols}
\begin{point}{Proof}%
We get~$(\id)^\diamond = \id$
directly from~\sref{img-of-compr}.
For 2 we only need a single line:
\begin{equation*}
(f\after g)^\diamond(s)
    \ =\  \ceil{s \after f \after g}
    \ \overset{\sref{ceiling-within-ceiling}}{=}\ 
    \ceil{\ceil{s \after f} \after g}
    \ =\  g^\diamond(f^\diamond(s)).
\end{equation*}
Note that we used that ceilings are sharp.
Point 3 and 4 follow easily from~1 and 2 respectively.
The identity~$(\id)_\diamond = \id$ is again~\sref{img-of-compr}.
We claim~$f_\diamond \after g_\diamond$
    is left order-adjoint to~$(f\after g)^\BOX$,
     indeed
\begin{equation*}
    f_\diamond (g_\diamond(s)) \leq t
        \ \iff\  g_\diamond(s) \leq f^\BOX (t)
        \ \iff\  s \leq g^\BOX (f^\BOX (t)) = (f \after g)^\BOX(t).
\end{equation*}
Thus by uniqueness of order adjoints, we find
$(f\after g)_\diamond = f_\diamond \after g_\diamond$. \qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}[diamond-ortholattice]{Proposition}%
In a~$\diamond$-effectus,
the poset~$\SPred X$ of sharp predicates on any object~$X$,
    is an ortholattice.
\begin{point}{Proof}%
Let~$C$ be a~$\diamond$-effectus with some object~$X$.
\begin{point}[spred-infimum]{Infima}%
Let~$s,t$ be sharp predicates on~$X$.    
We will show~$(\pi_s)_\diamond (\pi_s^\BOX (t))$
is the infimum of~$s$ and~$t$.
It is easy to see
$(\pi_s)_\diamond (\pi_s^\BOX (t))$ is a lower bound:
$(\pi_s)_\diamond (\pi_s^\BOX (t)) \leq t$
and~$(\pi_s)_\diamond (\pi_s^\BOX (t)) \leq (\pi_s)_\diamond(1)
    = \IM \pi_s = s$.
We have to show $(\pi_s)_\diamond (\pi_s^\BOX (t))$ is the greatest lower bound.
Let~$r$ be any sharp predicate with~$r \leq s$ and~$r \leq t$.
By~\sref{compr-is-full}
    we have~$\pi_r = \pi_s \after h$ for some~$h$.
Thus
\begin{equation*}
    (\pi_r)_\diamond
        \ = \  (\pi_s)_\diamond \after h_\diamond
        \ =\  (\pi_s)_\diamond \after \pi_s^\BOX  
            \after (\pi_s)_\diamond \after h_\diamond
        \ =\  (\pi_s)_\diamond \after \pi_s^\BOX \after (\pi_r)_\diamond.
\end{equation*}
Hence~$r = (\pi_r)_\diamond(1)  
=((\pi_s)_\diamond \after \pi_s^\BOX \after (\pi_r)_\diamond )(1)
=  (\pi_s)_\diamond ( \pi_s^\BOX (r))
\leq  (\pi_s)_\diamond ( \pi_s^\BOX (t))$.
\end{point}
\begin{point}[spred-ortholattice]{Ortholattice}%
Thanks to the order anti-isomorphism~$(\ )^\perp$
suprema (satisfying De Morgan's laws) come for free:
    $s \vee t = (s^\perp \wedge t^\perp)^\perp$.
Now note
\begin{equation*}
\pi_s^\BOX(s^\perp) \ =
    \  \ceil{s \after \pi_s}^\perp 
    \ =\  \ceil{1 \after \pi_s}^\perp 
    \ \overset{\sref{compr-total}}{=}\ \ceil{1}^\perp \ =\   0
\end{equation*}
and so~$s\wedge s^\perp = 0$.
We have shown~$\SPred X$ with~$(\ )^\perp$ is an ortholattice. \qed
\end{point}
\end{point}
\end{point}
\begin{point}[image-sharp-is-order-sharp]{Lemma}%
In a $\diamond$-effectus,
sharp predicates are \Define{order sharp} ---
    that is:
    for any predicate~$p$
    and sharp predicate~$s$
    with~$p \leq s$ and~$p \leq s^\perp$,
    we must have~$p = 0$.
\begin{point}{Proof}%
Note~$\ceil{p} \leq \ceil{s} = s$
    and~$\ceil{p} \leq \lceil s^\perp\rceil = s^\perp$.
So by~\sref{compr-is-full},
there is an~$h$ with~$\pi_{\ceil{p}} = \pi_s \after h$.
We compute
\begin{equation*}
    1 \after \pi_{\ceil{p}} \ =\  \ceil{p} \after \pi_{\ceil{p}}  \ = \
    \ceil{p} \after \pi_s \after h \ \leq \ 
        s^\perp \after \pi_s \after h \ = \ 0.
\end{equation*}
Thus~$\pi_{\ceil{p}} = 0$
and so~$p \leq \ceil{p} = \IM\pi_{\ceil{p}} = 0$, as desired.\qed
\end{point}
\end{point}
\begin{point}[spred-sup]{Exercise}%
Show that in a~$\diamond$-effectus,
we have
        $\xi^\BOX \after \xi_\diamond (t) = s \vee t$
    for sharp~$s,t$ and  quotient~$\xi$ of~$s$,
    where~$s \vee t$ denotes the supremum
    of~$s$ and~$t$ in~$\SPred X$.
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
We turn to~$\diamond$-adjointness.
\end{point}
\begin{point}{Exercise}%
Show the following basic properties of~$\diamond$-adjointness
\begin{enumerate}
    \item
$f^\diamond = g_\diamond$
    ($f$ is $\diamond$-adjoint to~$g$)
    if and only if~$f_\diamond = g^\diamond$.
    \item
If~$f$ and~$g$ are~$\diamond$-adjoint,
    then~$\IM f = \ceil{1 \after g}$.
\end{enumerate}
\end{point}
\begin{point}[diamond-squares]{Exercise}%
Show in order:
\begin{enumerate}
\item
If~$f$ is~$\diamond$-self-adjoint,
    then~$f \after f$ is~$\diamond$-self-adjoint.
\item
If~$f$ is~$\diamond$-positive,
    then~$f$ is~$\diamond$-self-adjoint.
\item
If~$f$ is~$\diamond$-positive,
    then~$f \after f$ is~$\diamond$-positive.
\end{enumerate}
\end{point}
\begin{point}[iso-diamond-adjoint]{Lemma}%
Let~$\alpha$ be an isomorphism in a~$\diamond$-effectus.
Then
\begin{enumerate}
\item
    $s\after\alpha$ is sharp for sharp predicates~$s$ \emph{and}
\item
    $\alpha^\diamond(s) = s \after \alpha$
    and~$\alpha_\diamond(s) = s\after \alpha^{-1}$
    (so~$\alpha$ and~$\alpha^{-1}$ are~$\diamond$-adjoint).
\end{enumerate}
\begin{point}{Proof}%
Let~$s$ be a sharp predicate. Then~$s = \IM \pi_s$.
Note~$\IM \alpha^{-1}\after \pi_s = s \after \alpha$
    --- indeed, $s \after \alpha \after \alpha^{-1} \after \pi_s=1$
    and when~$p \after \alpha^{-1} \after \pi_s=1$,
    we must have~$p \after \alpha^{-1} \geq s$,
    which gives~$p \geq s \after \alpha$ as desired.
    So~$s \after \alpha$ is indeed sharp.

So~$\alpha^\diamond(s) = \ceil{s \after \alpha} = s\after \alpha$
    and~$\alpha_\diamond(s) = \IM \alpha \after \pi_s = s \after \alpha^{-1}$
    as promised. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[sharp-map]{Definition}%
A map~$f$ in a~$\diamond$-effectus is a~\Define{sharp map}
    provided~$s \after f$ is sharp for all sharp predicates~$s$.
\end{point}
\begin{point}[sharp-ceil]{Exercise}%
Show that the following are equivalent.
\begin{enumerate}
    \item $f$ is a sharp map.
    \item $\ceil{p \after f} = \ceil{p}\after f$
            for every predicate~$p$.
\end{enumerate}
\end{point}

\begin{point}[exa-sharp-vn]{Example}%
In~$\op{\vN}$ the sharp maps are exactly the~mni-maps
(i.e.~the normal $*$-homomorphisms).
See \sref{sharp-multiplicative}.
\end{point}
    
\end{parsec}

\section{$\&$-effectus}
\begin{parsec}%
\begin{point}%
In a~$\diamond$-effectus
    quotient and comprehension are not tied together by its axioms.
    With two additional axioms, we will see quotient and comprehension
    become tightly interwoven.
\end{point}
\begin{point}{Definition}%
An~\Define{$\&$-effectus} (``andthen effectus'')
is a $\diamond$-effectus
such that
\begin{enumerate}
\item
    for each object~$X$
    and each predicate on~$p$,
    there is a unique $\diamond$-positive map~$\Define{\asrt_p}\colon X \to X$
    with~$1 \after \asrt_p = p$ \emph{and}
\item
    for every quotient~$\xi \colon X \to Y$
    and comprehension~$\pi \colon Y \to Z$
    the composite~$\pi \after \xi$ is pure.
\end{enumerate}
In an $\&$-effectus,
we define~$\Define{\andthen{p}{q}} = q \after \asrt_p$
    and~$\Define{p^2} = \andthen{p}{p}$.
\end{point}
\begin{point}[vn-is-andthen-eff]{Example}%
The category~$\op{\vN}$ is an~$\&$-effectus
    with~$\asrt_a\colon b \mapsto \sqrt{a}b\sqrt{a}$.
The first axiom is proven in \sref{positive-map-uniqueness}
    and the second in \sref{pure-fundamental}.
\end{point}
\begin{point}[sharp-prop]{Proposition}%
For a predicate~$p$ in an $\&$-effectus the following are equivalent.
\begin{enumerate}
\item $p$ is sharp,
\item $\andthen{p}{p}=p$ and
\item $\asrt_p \after \asrt_p = \asrt_p$.
\end{enumerate}
\begin{point}{Proof}%
First we prove that~$p$ is sharp if and only if~$\andthen{p}{p}=p.$
So, assume~$p$ is sharp.
As $\diamond$-positive maps are~$\diamond$-self-adjoint
    we have~$\IM \asrt_p = \ceil{1 \after \asrt_p} = \ceil{p} = p$.
Thus~$\andthen{p}{p} = p \after \asrt_p = 1 \after \asrt_p = p$.
For the converse, assume~$\andthen{p}{p}=p$.
From~$\IM \asrt_p = \ceil{1 \after \asrt_p} = \ceil{p}$,
we get~$\ceil{p} \after \asrt_p = \andthen{p}{\ceil{p}} = 1 \after \asrt_p = p$.
By assumption~$\andthen{p}{p}=p$.
So~$\andthen{p}{(\ceil{p} \ominus p)} = 0$.
Hence~$\ceil{p}\ominus p \leq \IMperp \asrt_p = \ceil{p}^\perp$.
However $\ceil{p}\ominus p \leq \ceil{p}$.
Thus by~\sref{image-sharp-is-order-sharp}
    get~$\ceil{p} \ominus p = 0$. So~$p$ is indeed sharp.

Clearly, if~$\asrt_p \after \asrt_p = \asrt_p$,
then~$p = 1 \after \asrt_p = 1\after\asrt_p\after\asrt_p = \andthen{p}{p}$.
It only remains to be shown~$\asrt_p \after \asrt_p = \asrt_p$
    whenever~$p$ is sharp.
So assume~$p$ is sharp.
By definition~$\asrt_p$ is pure: $\asrt_p = \pi \after \xi$
    for some quotient~$\xi$ and comprehension~$\pi$.
By assumption~$\xi \after \pi$ is pure as well,
    so there is a quotient~$\xi'$ and comprehension~$\pi'$
    with~$\xi \after \pi = \pi' \after \xi'$.
Note~$1 \after \xi = 1 \after \asrt_p = p$
and~$1 \after \asrt_p \after \asrt_p = \andthen{p}{p} = p = 1 \after \xi$,
hence
\begin{equation*}
 1\after \xi  
    \ =\  1 \after \asrt_p \after \asrt_p 
    \ =\  1 \after \pi \after \xi \after \pi \after \xi 
    \ =\  1 \after \pi \after \pi' \after \xi' \after \xi 
    \ =\  1 \after \xi' \after \xi,
\end{equation*}
so~$1 \after \xi' = 1$. Thus~$\xi'$ is an iso.
Also~$
    (\IM \pi') \after \xi \after \pi
    = (\IM \pi') \after \pi' \after \xi'
    = 1 \after \xi' = 1 $
    from which it follows~$p = \IM \pi \leq  (\IM \pi') \after \xi 
            \leq 1 \after \xi = p$.
Thus~$(\IM \pi') \after \xi = p = 1\after \xi$.
Hence~$\IM \pi' = 1$ and so~$\pi'$ is an isomorphism.
Now we know~$\pi \after \pi'$
    is a comprehension and~$\xi' \after \xi$ is a quotient,
    we see~$\asrt_p\after\asrt_p$ is pure.
As~$\asrt_p$ is $\diamond$-self-adjoint,
    we see~$\asrt_p\after\asrt_p$ is $\diamond$-positive.
By uniqueness of positive maps~$\asrt_p \after \asrt_p = \asrt_p$,
    as desired. \qed
\end{point}    
\end{point}
\begin{point}[prop-corr-zeta-pi]{Proposition}%
Let~$C$ be an~$\&$-effectus and~$s$
     be any sharp predicate.
There exist comprehension~$\pi_s$ of~$s$
        and quotient~$\zeta_s$ of~$s^\perp$ such that
\begin{equation*}
    \zeta_s \after \pi_s = \id \quad \text{and} \quad
        \pi_s \after \zeta_s = \asrt_s.
\end{equation*}
In fact, for every comprehension~$\pi$ of~$s$,
    there is a quotient~$\xi$ of~$s^\perp$
    with~$\xi \after \pi = \id$ and~$\pi \after \xi = \asrt_s$
    \emph{and} conversely for every quotient~$\xi$ of~$s^\perp$
    there exists a comprehension~$\pi$ of~$s$
    with~$\xi \after \pi = \id$ and~$\pi \after \xi = \asrt_s$.
\begin{point}{Proof}%
Pick quotient~$\xi$ and comprehension~$\pi$
    with~$\pi \after \xi = \asrt_s$.
By point 1:
\begin{equation*}
   \pi \after \xi \ =\  \asrt_s \ =\  \asrt_s\after\asrt_s \ =\  \pi \after \xi \after \pi \after \xi.
\end{equation*}
Thus~$\xi \after \pi = \id$.
We compute~$s = 1 \after \asrt_s = 1 \after \xi$
and so
\begin{alignat*}{2}
    \IM \pi &\ = \ 
    \IM \pi \after \xi \after \pi &\qquad& \text{as $\xi \after \pi=\id$}\\
                  &\ = \ \IM \asrt_s \after \pi &&\text{by dfn.~$\xi$ and~$\pi$}\\
                  &\ = \ (\asrt_s)_{\diamond}(\IM \pi)&& \text{by dfn.~$(\ )_\diamond$} \\
                  & \ = \ (\asrt_s)^{\diamond}(\IM \pi)&&
        \text{by $\diamond$-s.a.~$\asrt_s$}\\
        &\ = \ \ceil{(\IM \pi) \after \pi \after \xi} && \text{by dfn.~$(\ )^\diamond$} \\
&\ = \ \ceil{1 \after \xi} \\
    & \ = \ s.
\end{alignat*}
Thus~$\pi$ is a comprehension of~$s$
and~$\xi$ is a quotient of~$s^\perp$.
We have proven the first part.

For the second part,
let~$\pi'$ be any (other) comprehension of~$s$.
Then~$\pi' = \pi \after \alpha$ for some iso~$\alpha$.
Define~$\xi' = \alpha^{-1} \after \xi$.
It is easy to see~$\pi' \after \xi' = \asrt_s$
and~$\xi' \after \pi' = \id$.
The other statement is proven in a similar way. \qed
\end{point}
\begin{point}[zeta-s-convention]{Notation}%
In a~$\&$-effectus
    together with chosen comprehension~$\pi_s$ for~$s$,
    we will write~$\zeta_s$
    for the unique quotient for~$s^\perp$
    satisfying~$\zeta_s \after \pi_s = \id$
    and~$\pi_s \after \zeta_s = \asrt_s$.
We call this~$\zeta_s$
    the \Define{corresponding quotient} of~$\pi_s$
    and vice versa~$\pi_s$ the \Define{corresponding comprehension}
    of~$\zeta_s$.
\end{point}
\end{point}
\begin{point}[upm-closed]{Proposition}%
In an $\&$-effectus
    both comprehensions and pure maps are closed under composition.
\begin{point}{Proof}%
We will first prove that comprehensions are closed under composition.
Assume~$\pi_1 \colon X \to Y$
    and~$\pi_2 \colon Y \to Z$
    are comprehensions with~$s = \IM \pi_1$
    and~$t = \IM \pi_2$.
We will show~$\pi_2 \after \pi_1$
    is a comprehension for~$\IM \pi_2 \after \pi_1$.
To this end, let~$f\colon V\to Z$ be any map
with~$(\IM \pi_2 \after \pi_1)^\perp \after f = 0$.
As~$\IM \pi_2 \after \pi_1 \leq \IM \pi_2 = t$
    we get~$t^\perp \after f = 0$,
    so~$f = \pi_2 \after g_2$ for a unique~$g_2\colon V \to Y$.
Let~$\zeta_2$ be a quotient for~$t^\perp$
such that~$\zeta_2 \after \pi_2$,
which exists by \sref{prop-corr-zeta-pi}.
Then~$s \after \zeta_2 \after \pi_2 \after \pi_1
            = s \after \pi_1 = 1$
            so~$s \after \zeta_2 \geq \IM \pi_2 \after \pi_1$.
Consequently
\begin{equation*}
    s \after g_2 \ =\  s \after \zeta_2 \after \pi_2 \after g_2
        \ =\  s \after \zeta_2 \after f
        \ \geq\   (\IM \pi_2 \after \pi_1) \after f \ =\  1 \after f
                \ =\  1 \after g_2.
\end{equation*}
Hence there exists a unique~$g_1\colon V \to X$
    with~$\pi_1 \after g_1 = g_2$
    and so~$\pi_2 \after \pi_1 \after g_1 = f$.
By monicity of~$\pi_2 \after \pi_1$,
    this~$g_1$ is unique and so~$\pi_2 \after \pi_1$
    is indeed a comprehension.
\begin{point}%
Now we will prove that pure maps are closed under composition.
Assume~$g\colon X \to Y$ and~$f\colon Y \to Z$ are pure maps.
Say~$f = \pi_1 \after \xi_1$
    and~$g = \pi_2 \after \xi_2$
    for some comprehensions~$\pi_1$, $\pi_2$
        and quotients~$\xi_1$, $\xi_2$.
By definition of $\&$-effectus
    there is a comprehension~$\pi'$ and quotient~$\xi'$
    such that~$\xi_1 \after \pi_2 = \pi' \after \xi'$.
By the previous point~$\pi_1 \after \pi'$
    is a comprehension
    and~$\xi' \after \xi_2$ is a quotient by \sref{quotients-composition}.
Thus
$f \after g 
=\pi_1 \after \pi' \after \xi' \after \xi_2$
is pure. \qed
\end{point}
\end{point}
\end{point}
\begin{point}[andthen-square-rule]{Exercise}%
Show that in a~$\&$-effectus,
    we have~$\asrt_p \after \asrt_p = \asrt_{\andthen{p}{p}}$.
\end{point}
\begin{point}[asrt-absorp-rule]{Exercise}%
    Show that in a~$\&$-effectus,
    we have
    \begin{align*}
        \IM f \leq s \quad&\iff\quad  \asrt_s \after f = f \\
        1 \after f \leq t \quad&\iff\quad  f \after \asrt_t = f
    \end{align*}
for any sharp predicates~$s$ and~$t$.
\end{point}
\begin{point}{Definition}%
Let~$C$ be a~$\&$-effectus.
In \sref{upm-closed} we saw pure maps are closed under composition
Write~$\Define{\Pure C}$ for the subcategory
    of pure map.
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[zeta-asrt-quot]{Lemma}%
    In a~$\&$-effectus,
    $\zeta_{\ceil{p}} \after \asrt_p$
    is a quotient for~$p^\perp$.
\begin{point}{Proof}%
Recall~$\IM \asrt_p = \ceil{1 \after \asrt_p} = \ceil{p}$ and so
\begin{equation*}
\IM \zeta_{\ceil{p}} \after \asrt_p
\ =\  (\zeta_{\ceil{p}})_\diamond( \ceil{p})
\ =\  \IM \zeta_{\ceil{p}} \after \pi_{\ceil{p}}
\ =\  \IM \id \ =\  1,
\end{equation*}
where~$\pi_{\ceil{p}}$ is the comprehension corresponding to~$\zeta_{\ceil{p}}$.
By~\sref{upm-closed}~$\zeta_{\ceil{p}} \after \asrt_p = \pi \after \xi$
    for some comprehension~$\pi$ and quotient~$\xi$.
Putting it together:
$1 = \IM \zeta_{\ceil{p}} \after \asrt_p = \IM \pi \after \xi \leq \IM \pi$,
so~$\IM \pi = 1$ and thus~$\pi$ is an isomorphism,
hence~$\zeta_{\ceil{p}}\after \asrt_p$
is a quotient for the orthocomplement of~$\ceil{p} \after \asrt_p = p$. \qed
\end{point}
\end{point}
\begin{point}[standard-form-map]{Proposition}%
Every map~$f$
in a~$\&$-effectus
factors as
\begin{equation}\label{eq-standard-form-map}
        f \ =\ \pi_{\IM f} \after g \after \zeta_{\ceil{1 \after f}} \after \asrt_{1 \after f} 
    \end{equation}
    for a unique total and faithful map~$g$.
Furthermore the following holds.
\begin{enumerate}
\item
If~$f$ is pure, then~$g$ is an isomorphism.
\item
If~$f$ is pure and~$\IM f = 1$, then~$f$ is a quotient.
\item
If~$f$ is pure and~$1 \after f = 1$, then~$f$ is a comprehension.
\end{enumerate}
\begin{point}{Proof}%
By the universal property of~$\pi_{\IM f}$,
    there is a unique~$g'$ with~$f = \pi_{\IM f} \after g'$.
To show~$g'$ is faithful, assume~$p\after g' = 0$
    for some predicate~$p$.
Then~$0 = p \after g' = p \after \zeta_{\IM f} \after \pi_{\IM f} \after g'
                = p \after \zeta_{\IM f} \after f$
    and so~$p \after \zeta_{\IM f} \leq \IMperp f$,
    hence~$p = p \after \zeta_{\IM f} \after \pi_{\IM f}
                \leq (\IMperp f )\after \pi_{\IM f} = 0$, which
                shows~$g'$ is indeed faithful.

Note~$1 \after g' = 1 \after \pi_{\IM f} \after g' = 1 \after f$.
By~\sref{quotient-total} and~\sref{zeta-asrt-quot}
    there is a unique total~$g$ with~$g' = g \after \zeta_{\ceil{1 \after f}} \after \asrt_{1 \after f}$.
Clearly~\eqref{eq-standard-form-map} holds
and~$g$ is the unique map
    for which \eqref{eq-standard-form-map} holds
    as  comprehensions are mono and quotients are epi.
    As~$1 = \IM g' = \IM g \after \zeta_{\ceil{1 \after f}}
            \after \asrt_{1 \after f} \leq \IM g$,
            we see~$\IM g = 1$ and so~$g$ is faithful.

To prove point 1, assume~$f$ is pure.
That is: $f = \pi \after \xi$ for some comprehension~$\pi$
        and quotient~$\xi$.
As~$1 \after \pi=1$ and~$\IM \xi = 1$,
    we see~$\IM \pi = \IM f$ and~$1 \after \xi = 1\after f$.
Thus~$\pi = \pi_{\IM f} \after \alpha$
    and~$\xi = \beta \after \zeta_{\ceil{1 \after f}}
                \after \asrt_{1 \after f}$
        for some isomorphisms~$\alpha$ and~$\beta$.
Thus~$f = \pi_{\IM f} \after \alpha \after \beta
                \after \zeta_{\ceil{1 \after f}}
                \after \asrt_{1 \after f}$
        and so by uniqueness of~$g$,
        we see~$g = \alpha \after \beta$ is an isomorphism.

To prove point 2, additionally assume~$\IM f= 1$.
Then~$\pi_{\IM f}$ is an iso and so
using the previous, we see~$f$ is indeed a quotient.
Point 3 is just as easy. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}[andthen-effect-divisoid]{Proposition}%
If~$C$ is an~$\&$-effectus,
    then~$(\Scal C)^{\mathrm{op}}$ is an effect divisoid,
    see~\sref{dfn-effect-divisoid}.
\begin{point}{Proof}%
Let~$\lambda,\mu$ be scalars with~$\lambda \leq \mu$.
Recall that the scalar~$1=\id$
    and so~$\mu = 1 \after \asrt_\mu = \asrt_\mu$.
By~\sref{zeta-asrt-quot},
    there is a unique~$\lambda'$
    with~$\lambda' \after \zeta_{\ceil{\mu}} \after \mu = \lambda$.
Define~$\rfrac{\lambda}{\mu} = \lambda'  \after \zeta_{\ceil{\mu}}$.

For the moment, assume~$\lambda = \mu$.
Then~$\lambda' \after \zeta_{\ceil{\mu}} \after \mu
            = \mu = 1 \after \zeta_{\ceil{\mu}} \after \mu$
            as~$\IM \mu = \IM \asrt_{\mu} = \ceil{\mu}$.
        By epicity of~$\zeta_{\ceil{\mu}} \after \mu$,
            we see~$\lambda' = 1$, hence~$\rfrac{\mu}{\mu}=\ceil{\mu}$.
As we have~$\mu \leq \ceil{\mu}$ and~$\ceil{\ceil{\mu}} = \ceil{\mu}$,
    we see axioms 2 and 3 hold.

We return to the general case to prove axiom 1.
Clearly~$\rfrac{\lambda}{\mu} = \lambda' \after \zeta_{\ceil{\mu}}
            \leq 1 \after \zeta_{\ceil{\mu}} = \ceil{\mu} 
            = \rfrac{\mu}{\mu}$
    and~$\mu \odot_{\mathrm{op}} \rfrac{\lambda}{\mu}
= \lambda'  \after \zeta_{\ceil{\mu}} \after \mu = \lambda$
as required.
Assume~$\sigma$ is any
    (other) scalar with~$\mu \odot_{\mathrm{op}} \sigma = \lambda$
    and~$\sigma \leq \rfrac{\mu}{\mu} \equiv \ceil{\mu}$.
Then~$\sigma = \sigma' \after \zeta_{\ceil{\mu}}$
    for a unique~$\sigma'$.
As~$
\lambda'  \after \zeta_{\ceil{\mu}} \after \mu = \lambda
= \sigma' \after \zeta_{\ceil{\mu}} \after \mu$
we must have~$\lambda' = \sigma'$, whence~$\rfrac{\lambda}{\mu}=\sigma$. \qed
\end{point}
\end{point}
\begin{point}[perp-sharp-is-orth]{Lemma}%
In a~$\&$-effectus, if~$s \perp t$
    for sharp~$s,t$, then~$\andthen{s}{t} = 0 = \andthen{t}{s}$.
\begin{point}{Proof}%
Write~$r \equiv (s \ovee t)^\perp$.
    As~$1 = s \ovee t \ovee r$ and~$\andthen{s}{s}=s$, we have
\begin{equation*}
    s \ = \ 
    \andthen{s}{1} \ = \ 
    \andthen{s}{s} \ovee \andthen{s}{t} \ovee \andthen{s}{r} \ = \ 
    s \ovee \andthen{s}{t} \ovee \andthen{s}{r}
\end{equation*}
and so~$\andthen{s}{t} \leq \andthen{s}{t} \ovee \andthen{s}{r} = 0$. \qed
\end{point}
\end{point}
\begin{point}[simple-andthen-absorption]{Exercise}%
Show that in an~$\&$-effectus, we have
\begin{equation*}
p \ \leq\  s \quad \iff \quad \andthen{s}{p} \ =\  p
\end{equation*}
for sharp~$s$ and any predicate~$p$.
\end{point}
\begin{point}[sum-sharp-sharp]{Proposition}%
In a~$\&$-effectus, $s \ovee t$
    is sharp, if~$s$ and~$t$ are sharp.
\begin{point}{Proof}%
We will first prove that $s \wedge t = 0$.
Pick any~$p$ with~$p \leq s,t$.
Then by \sref{simple-andthen-absorption}
    and \sref{perp-sharp-is-orth},
     we see~$ p = \andthen{s}{p} \leq \andthen{s}{t} = 0$.
Hence~$s \vee t = s \ovee t$ by~\sref{ea-modularity-prop},
    but~$s \vee t$ is sharp by \sref{lattice-compr}. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
We will show that the sharp predicates on an object in an~$\&$-effectus
    form an orthomodular lattice.
\end{point}
\begin{point}{Lemma}%
In a~$\&$-effectus,
    if~$s\leq t$ for sharp~$s,t$,
    then~$s \after \pi_t$ is sharp.
\begin{point}{Proof}%
By~\sref{simple-andthen-absorption}
    we have~$\andthen{t}{s} = s$.
Hence~$s \after \pi_t \after \zeta_t \after \pi_s
                = (\andthen{t}{s}) \after \pi_s
                = s \after \pi_s = 1$.
Thus~$\zeta_t \after \pi_s$ is total.
To prove~$s \after \pi_t$ is sharp,
    we will show~$\IM \zeta_t \after \pi_s = s \after \pi_t$.
We just saw~$s \after \pi_t \after \zeta_t \after \pi_s = 1$.
Assume~$r \after \zeta_t \after \pi_s = 1$.
Then~$r \after \zeta_t \geq s$
and so~$r = r \after \zeta_t \after \pi_t \geq s \after \pi_t$,
as desired. \qed
\end{point}
\end{point}
\begin{point}[box-diamond-compr-andthen]{Corollary}%
In a~$\&$-effectus: $s \after \pi_t = (\pi_t)^\BOX(s) = (\pi_t)^\diamond(s)$
    for sharp~$s,t$ with~$s \leq t$.
\end{point}
\begin{point}{Theorem}%
In a~$\&$-effectus,
    the poset~$\SPred X$ of sharp predicates on~$X$,
    is an orthomodular lattice.
\begin{point}{Proof}%
In \sref{diamond-ortholattice} we saw
    that~$\SPred X$ is an ortholattice.
Assume~$s \leq  t$ for some~$s,t \in \SPred X$.
We have to show~$s \vee (s^\perp \wedge t) = t$.
Indeed
\begin{alignat*}{2}
s \vee (s^\perp \wedge t) 
&\  =\  (s \wedge t) \vee (s^\perp \wedge t) &\qquad& \text{as $s \leq t$}\\
&\  =\ 
        ((\pi_t)_\diamond \after \pi_t^\BOX)
        (s) \vee
        ((\pi_t)_\diamond \after \pi_t^\BOX)
        (s^\perp)
        &\qquad& \text{by \sref{spred-infimum}}\\
&\  =\ 
        (\pi_t)_\diamond ( \pi_t^\BOX(s) \vee 
                            \pi_t^\BOX(s^\perp))
                            &\qquad& \text{by \sref{order-adj-basics}} \\
&\  =\ 
        (\pi_t)_\diamond ( \pi_t^\diamond(s) \vee 
                            \pi_t^\diamond(s)^\perp)
                            &\qquad& \text{by \sref{box-diamond-compr-andthen}}\\
&\  =\ 
                            (\pi_t)_\diamond (1)
                            &\qquad& \text{by \sref{spred-ortholattice}} \\
& \ =\  \IM \pi_t \ = \ t && \text{by \sref{img-of-compr}}.
\end{alignat*}
We have shown~$\SPred X$ is an orthomodular lattice. \qed
\end{point}
\end{point}
\begin{point}{Corollary}%
In a $\&$-effectus~$C$
the assignment~$X\mapsto \SPred X$, ~$f \mapsto (f_\diamond,f^\BOX)$
    yields a functor from~$C$
    to~$\mathsf{OMLatGal}$,
    the category of orthomodular lattices
    with galois connection between them,
    as defined in~\cite{jacobs2009orthomodular}.
\end{point}
\end{parsec}

\section{$\dagger$-effectus}
\begin{parsec}%
\begin{point}{Definition}%
A \Define{$\dagger$-category} (pronounced: dagger category)
is category~$C$ together with an involutive identity-on-objects
    functor~$(\ )^\dagger \colon C \to \op{C}$;
    that is, for all objects~$X$ and maps~$f,g$ in~$C$
\begin{multicols}{2}
\begin{enumerate}
    \item $(f \after g)^\dagger = g^\dagger \after f^\dagger$
    \item $\id^\dagger = \id$
    \item $f^{\dagger\dagger} = f$ \emph{and}
    \item $X^\dagger = X$.
\end{enumerate}
\end{multicols}
\noindent
Cf.~\cite{burgin1970categories,selinger2007dagger,heunenphd}.
In any~$\dagger$-category we may define the following.
\begin{enumerate}
\item
    An endomap~$f$ is called \Define{$\dagger$-self-adjoint}
    if~$f^\dagger = f$.
\item
    An endomap~$f$ is \Define{$\dagger$-positive}
    if~$f = g^\dagger \after g$ for some other map~$g$.
\item
    An isomorphism~$\alpha$ is called~\Define{unitary}
        whenever~$\alpha^{-1} = \alpha^\dagger$.
\end{enumerate}
\end{point}
\begin{point}{Example}%
The category~$\mathsf{Hilb}$
    of Hilbert spaces with bouned linear maps
    is a~$\dagger$-category
    with the familiar adjoint as~$\dagger$.
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}{Definition}%
We call a~$\&$-effectus~$C$,
    a~\Define{$\dagger$-effectus} provided
\begin{enumerate}
\item
    $\Pure C$ is a  $\dagger$-category
     satisfying~$\asrt_p^\dagger = \asrt_p$
        and~$f$ is $\diamond$-adjoint to~$f^\dagger$;
\item
    for every~$\dagger$-positive~$f$,
        there is a unique~$\dagger$-positive~$g$
        with~$g \after g = f$ \emph{and}
\item
    $\diamond$-positive maps are $\dagger$-positive.
\end{enumerate}
\end{point}
\begin{point}[dagger-theorem]{Theorem}%
    A $\&$-effectus
        is a~$\dagger$-effectus if and only if
\begin{enumerate}
\item
for every predicate~$p$, there is a unique predicate~$q$
    with~$\andthen{q}{q} = p$;
\item
    $\asrt^2_{\andthen{p}{q}}
        = \asrt_p \after \asrt^2_q \after \asrt_p$
     for all predicates~$p,q$ \emph{and}
\item
    a quotient for a sharp predicate (e.g.~$\zeta_s$)
    is a sharp map, see \sref{sharp-map}.
\end{enumerate}
\begin{point}{Proof}%
Necessity will be proven in
    \sref{dagger-thm-necessity}
        and sufficiency in \sref{dagger-thm-sufficiency}. \qed
\end{point}
\begin{point}%
Especially the sufficiency requires quite some preparation.
For convenience, call~$C$ a \Define{$\dagger'$-effectus}
    if~$C$ is a~$\&$-effectus
    satisfying axioms 1, 2 and 3 from the Theorem above.
\end{point}
\begin{point}{Note}%
    In an~$\&$-effectus
    with separating predicates
    (see \sref{dfn-mandso}),
    the second axiom of a~$\dagger'$-effectus is equivalent
    to
\begin{equation*}
    \andthen{(\andthen{p}{q})^2}{r}
    \ =\  \andthen{p}{(\andthen{q^2}{(\andthen{p}{r})})}
\end{equation*}
    for all predicates~$p,q,r$.
This is essentially the \emph{fundamental formula
    of quadratic Jordan algebras} \cite[\S 4.2]{mccrimmon2006taste}
    (with~$U_x y \equiv \andthen{x^2}{y}$).
\end{point}
\end{point}
\end{parsec}


\begin{parsec}%
\begin{point}[diamond-is-dagger-positive]{Lemma}%
In a~$\dagger$-effectus,
    a map is~$\dagger$-positive if and only if it is~$\diamond$-positive.
\begin{point}{Proof}%
Assume~$f$ is~$\dagger$-positive.
By assumption 2, there is a (unique) $\dagger$-positive
    $g$ with~$f = g \after g$.
By~$\dagger$-positivity of~$g$,
    there is an~$h$ with~$g = h^\dagger \after h$.
Using the fact~$h$ is~$\diamond$-adjoint
    to~$h^\dagger$, we see~$g$ is~$\diamond$-self-adjoint:
\begin{equation*}
    g^\diamond
    \ =\  (h^\dagger \after h)^\diamond
    \ =\  h^\diamond \after (h^\dagger)^\diamond 
    \ =\  (h^\dagger)_\diamond \after h_\diamond 
    \ =\  (h^\dagger\after h)_\diamond
    \ =\  g_\diamond.
\end{equation*}
Thus~$f$ is the square of the~$\diamond$-self-adjoint map $g$,
    hence~$f$ is~$\diamond$-positive. \qed
\end{point}
\end{point}

\begin{point}[dagger-eff-square-root]{Lemma}%
Predicates in a~$\dagger$-effectus have a unique square root:
    for every predicate~$p$,
    there is a unique predicate~$q$
    with~$\andthen{q}{q}=p$.
\begin{point}{Proof}%
Let~$p\colon X \to 1$ be any predicate.
By assumption 3,
    the~$\diamond$-positive map~$\asrt_p$
        is also~$\dagger$-positive.
So by assumption 2,
    there is (a unique)~$\dagger$-positive map~$f$
    with~$f \after f = \asrt_p$.
Define~$q = 1 \after f$.
By \sref{diamond-is-dagger-positive}
    $f$ is~$\diamond$-positive
    and so by uniqueness of~$\diamond$-positive maps,
    we get~$f = \asrt_{1\after f} \equiv \asrt_q$.
We compute
\begin{equation*}
    \andthen{q}{q}
        \ =\    
        q \after \asrt_q \ \equiv \ 
        1 \after f \after \asrt_{1 \after f} \ = \ 
        1 \after f \after f \ = \ 1 \after \asrt_p \ = \ p,
\end{equation*}
which shows~$p$ has as square root~$q$.

To show uniqueness, assume~$p = \andthen{r}{r}$ for some (other)
    predicate~$r$.
Note
\begin{equation*}
    \asrt_p
        \ = \ \asrt_{\andthen{r}{r}}
        \ \overset{\smash{\sref{andthen-square-rule}}}{=} \ \asrt_r \after \asrt_r.
\end{equation*}
As~$\asrt_r$ is~$\diamond$-positive,
    it is also~$\dagger$-positive by the third axiom.
    So by the second axiom~$\asrt_r = \asrt_q$.
Thus~$r = q$, which shows uniqueness of the square root.
\qed
\end{point}
\end{point}
\begin{point}[asrt-iso]{Proposition}%
In a~$\&$-effectus with square roots
    (e.g.~$\dagger$- or~$\dagger'$-effectus) we have
\begin{equation*}
    \asrt_p \after \alpha
        \ =\  \alpha \after \asrt_{p\after \alpha}
\end{equation*}
for every isomorphism~$\alpha$.
\begin{point}{Proof}%
There is some~$q$ with~$\andthen{q}{q}=p$.
The map~$\alpha^{-1} \after \asrt_q \after \alpha$
    is~$\diamond$-self-adjoint:
\begin{alignat*}{2}
    (\alpha^{-1} \after \asrt_q \after \alpha)_\diamond
    &\ = \ \alpha^{-1}_\diamond \after (\asrt_q)_\diamond \after \alpha_\diamond \\
    &\ \overset{\mathclap{\sref{iso-diamond-adjoint}}}{=} \ \alpha^\diamond \after (\asrt_q)^\diamond \after (\alpha^{-1})^\diamond\\
    &\ = \ (\alpha^{-1} \after \asrt_q \after \alpha)^\diamond.
\end{alignat*}
Thus~$
\alpha^{-1} \after \asrt_q \after \alpha \after
\alpha^{-1} \after \asrt_q \after \alpha
= \alpha^{-1} \after \asrt_p \after \alpha
$ is~$\diamond$-positive.  By uniqueness of~$\diamond$-positive maps,
we get~$\alpha^{-1} \after \asrt_p \after \alpha
    = \asrt_{1 \after \alpha^{-1}\after\asrt_p \after \alpha}
    = \asrt_{p \after \alpha} $.
Postcomposing~$\alpha$, we find~$\asrt_p\after\alpha = 
        \alpha \after \asrt_{p \after \alpha}$, as desired. \qed
\end{point}
\end{point}
\begin{point}[dagger-of-zeta]{Proposition}%
In a $\dagger$-effectus:~$\zeta_s^\dagger = \pi_s$
(recall convention \sref{zeta-s-convention} for~$\pi_s$ and~$\zeta_s$).
\begin{point}{Proof}%
As~$\pi_s$ is~$\diamond$-adjoint to~$\pi_s^\dagger$,
we have
\begin{equation*}
\IM \pi_s^\dagger
 \ = \  (\pi^\dagger_s)_\diamond(1) \ =\ 
 (\pi_s)^\diamond(1) \ = \  \ceil{1 \after \pi_s}
 \ =\  1
\end{equation*}
and similarly~$\ceil{1 \after \pi_s^\dagger} = \IM \pi_s = s$.
As~$1 \after \pi_s^\dagger \leq \ceil{1 \after \pi_s^\dagger} = s$,
    there is some pure~$h$ with~$\pi_s^\dagger = h \after \zeta_s$.
By \sref{standard-form-map},
    there is also some pure and faithful~$g$
    with~$\zeta_s^\dagger = \pi_s \after g$.
Using~$\zeta_s \after \pi_s = \id$ twice we find
\begin{equation}\label{eq-dagger-zeta-pi-conn}
    \id \ =\  \id^\dagger
    \ = \ \pi_s^\dagger \after \zeta_s^\dagger
    \ = \ h \after \zeta_s \after \pi_s \after g 
    \ = \ h \after g.
\end{equation}
Now~$1= 1 \after h \after g \leq 1 \after g$ and so~$g$ is total.
Clearly~$\zeta_s^\dagger\after\zeta_s$ is~$\dagger$-positive,
    hence~$\diamond$-positive and so by uniqueness of~$\diamond$-positive maps:
\begin{equation*}
\zeta_s^\dagger \after \zeta_s
    \ = \ \asrt_{1 \after \zeta_s^\dagger \after \zeta_s}
    \ =\  \asrt_{1 \after \pi_s \after g\after \zeta_s}
    \ =\  \asrt_s
    \ =\  \pi_s \after \zeta_s.
\end{equation*}
So by epicity of~$\zeta_s$, we find~$\zeta_s^\dagger = \pi_s$, as desired.\qed
\end{point}
\end{point}

\begin{point}[dagger-of-iso]{Corollary}%
    In a~$\dagger$-effectus,
        $\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$.
    Also~$\alpha^\dagger = \alpha^{-1}$
        for any iso~$\alpha$.
\end{point}

\begin{point}[zeta-through-asrt]{Exercise}%
Show that in a~$\&$-effectus
        where every predicate has a square root
        and where~$\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$
        (e.g.~a~$\dagger$-effectus)
        we have
    $\asrt_p \after \zeta_s \ = \ \zeta_s \after \asrt_{p \after \zeta_s}$.
    (Hint: mimic the proof of \sref{asrt-iso}.)
\end{point}

\begin{point}[dagger-thm-necessity]{Theorem}%
    A~$\dagger$-effectus is a~$\dagger'$-effectus.
\begin{point}{Proof}%
Assume~$C$ is a~$\dagger$-effectus.
Axiom 1 is already proven in \sref{dagger-eff-square-root}.
\begin{point}[pqqp-from-dagger]{Ax.~2}%
Let~$p,q$ be predicates.
To start, note~$1 \after \asrt_q\after  \asrt_p = \andthen{p}{q}$ and
\begin{equation*}
    \IM \asrt_q \after \asrt_p \ =\ 
        (\asrt_q)_\diamond(p) \ = \ 
        (\asrt_q)^\diamond(p) \ = \ 
        \ceil{\andthen{q}{p}}.
\end{equation*}
So using \sref{standard-form-map}
    we know
\begin{equation*}
    \asrt_q \after \asrt_p \ =\ 
    \pi_{\ceil{\andthen{q}{p}}}
    \after \alpha \after \zeta_{\ceil{\andthen{p}{q}}} \after \asrt_{\andthen{p}{q}}
\end{equation*}
for some iso~$\alpha$.
Applying the dagger to both sides
we get, using \sref{dagger-of-zeta} and \sref{dagger-of-iso}:
\begin{align*}
    \asrt_p \after \asrt_q &\ =\ 
    (\asrt_q \after \asrt_p)^\dagger \\
    & \ =\  \asrt_{\andthen{p}{q}}
    \after \zeta^\dagger_{\ceil{\andthen{p}{q}}}
    \after \alpha^\dagger \after
    \pi^\dagger_{\ceil{\andthen{q}{p}}} \\
    & \ = \ 
    \asrt_{\andthen{p}{q}}
    \after \pi_{\ceil{\andthen{p}{q}}}
    \after \alpha^{-1} \after
    \zeta_{\ceil{\andthen{q}{p}}}.
\end{align*}
Combining both:
\begin{align*}
    & \asrt_p \after \asrt_q^2 \after \asrt_p \\
    &\qquad = \ \asrt_{\andthen{p}{q}}
    \after \pi_{\ceil{\andthen{p}{q}}}
    \after \alpha^{-1} \after
    \zeta_{\ceil{\andthen{q}{p}}}
    \after \pi_{\ceil{\andthen{q}{p}}}
    \after \alpha \after \zeta_{\ceil{\andthen{p}{q}}} \after \asrt_{\andthen{p}{q}} \\
    &\qquad = \ \asrt_{\andthen{p}{q}}
    \after \pi_{\ceil{\andthen{p}{q}}}
    \after \zeta_{\ceil{\andthen{p}{q}}} \after \asrt_{\andthen{p}{q}} \\
    &\qquad = \ \asrt_{\andthen{p}{q}}
    \after \asrt_{\ceil{\andthen{p}{q}}}
    \after \asrt_{\andthen{p}{q}} \\
    &\qquad \overset{\smash{\mathclap{\sref{asrt-absorp-rule}}}}{=} \ 
    \asrt_{\andthen{p}{q}}^2,
\end{align*}
as desired.
\end{point}
\begin{point}{Ax.~3}%
Pick any sharp predicates~$s,t$.
We want to show~$t \after \zeta_s$ is sharp.
To this end, we will show~$t \after \zeta_s$
    is the image of~$\pi_s \after \pi_t$.
Clearly~$t \after \zeta_s \after \pi_s \after \pi_t = 1$.
Let~$p$ be any (other) sharp predicate with~$p \after \pi_s \after \pi_t = 1$.
Then~$p \after \pi_s \geq \IM \pi_t = t$.
So~$  p^\perp \after \pi_s \leq t^\perp$
and hence~$\ceil{p^\perp \after \pi_s} \leq t^\perp$.
As~$\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$ by \sref{dagger-of-iso},
we get~$t \after \zeta_s \leq \ceil{t \after \zeta_s} \leq p$,
    which shows~$t \after \zeta_s$
    is the image of~$\pi_s \after \pi_t$
    and consequently sharp. \qed
\end{point}
\end{point}
\end{point}

    
\end{parsec}

\begin{parsec}%
\begin{point}%
Let~$f$ be a pure map in a~$\dagger'$-effectus.
We will work towards the definition of~$f^\dagger$.
By \sref{standard-form-map} we
know there is an iso~$\alpha$ with
\begin{equation*}
f  \ =\   \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1\after f}}
            \after \asrt_{1 \after f}.
\end{equation*}
In a~$\dagger$-effectus
    we have~$\asrt_p^\dagger = \asrt_p$,
    $\zeta_s^\dagger = \pi_s$,
    $\alpha^\dagger = \alpha^{-1}$
    and~$\pi_s^\dagger = \zeta_s$ 
    (for corresponding~$\zeta_s$ and~$\pi_s$)
    ---
    so we are forced to define~
\begin{equation}\label{dagger-definition}
    f^\dagger
        \ =\  \asrt_{1 \after f} \after
    \pi_{\ceil{1\after f}} \after
    \alpha^{-1} \after
    \zeta_{\IM f},
\end{equation}
    where~$\zeta_{\IM f}$
    is the unique corresponding
        quotient of~$\pi_{\IM f}$
        and~$\pi_{\ceil{1 \after f}}$
        the unique corresponding comprehension of
        and~$\zeta_{\ceil{1 \after f}}$,
        see \sref{zeta-s-convention}.
Before we declare~\eqref{dagger-definition} a definition,
 we have to check whether it is independant
    of choice of~$\pi$ (and corresponding $\zeta$).
    So suppose~$ f  =  \pi' \after \alpha' \after \zeta'
        \after \asrt_{1 \after f}$
        for some (other) iso~$\alpha'$, comprehension~$\pi'$ of~$\IM f$
        and quotient~$\zeta'$ of~$\smash{\ceil{1 \after f}^\perp}$.
There are isos~$\beta$ and~$\gamma$
    such that~$\pi' = \pi_{\IM f} \after \beta$
    and~$\zeta' = \gamma \after \zeta_{\ceil{1 \after f}}$.
We will take a moment to relate~$\alpha$ and~$\alpha'$:
as~$\pi_{\IM f}$ is mono
    and~$\zeta_{1 \after f}\after\asrt_{1 \after f}$
    is epic,
    we have~$\beta\after\alpha'\after\gamma = \alpha$
    and so~$(\alpha')^{-1}= \gamma \after\alpha^{-1}\after\beta$.
To continue,
it is easy to see~$\beta^{-1} \after \zeta_{\IM f}$
    is the unique corresponding quotient to~$\pi'$
    and~$\pi_{\ceil{1 \after f}}\after \gamma^{-1}$
    is the unique corresponding comprehension to~$\zeta'$.
So with this choice of quotient and comprehension,
    we are forced to define
\begin{align*}
    f^\dagger 
    &\ = \ \asrt_{1 \after f}\after \pi_{\ceil{1 \after f}}
    \after \gamma^{-1} \after {\alpha'}^{-1}
                \after \beta^{-1}\after \zeta_{\IM f} \\
    &\ = \ \asrt_{1 \after f}\after \pi_{\ceil{1 \after f}}
                \after \gamma^{-1} \after \gamma \after \alpha^{-1} \after \beta 
                \after \beta^{-1}\after \zeta_{\IM f} \\
    &\ = \ \asrt_{1 \after f}\after \pi_{\ceil{1 \after f}}
                \after \alpha^{-1} \after \zeta_{\IM f},
\end{align*}
which is indeed consistent with~\eqref{dagger-definition}.
So we are justified to declare:
\end{point}
\begin{point}[dagger-definition2]{Definition}%
In a~$\dagger'$-effectus, for a pure map~$f$, define
\begin{equation*}
    \Define{f^\dagger}
        \ =\  \asrt_{1 \after f} \after
    \pi_{\ceil{1\after f}} \after
    \alpha^{-1} \after
    \zeta_{\IM f},
\end{equation*}
where~$\alpha$ is the unique iso such that
$f  =  \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1\after f}}
            \after \asrt_{1 \after f}$.
\end{point}
\begin{point}[dagger-prime-basics]{Exercise}%
Show that in a~$\dagger'$-effectus,
    we have
\begin{align*}
    \asrt_p^\dagger &= \asrt_p &
    \pi_s^\dagger &= \zeta_s &
    \zeta_s^\dagger &= \pi_s &
    \alpha^\dagger &= \alpha^{-1}
\end{align*}
for a quotient~$\zeta_s$ corresponding to~$\pi_s$
and iso~$\alpha$.
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
To compute~$f^{\dagger\dagger}$,
    we need to put~$f^\dagger$
    in the standard form of~\sref{standard-form-map}.
To do this, we need to pull~$\asrt_p$ from one side to the other.
In this section we will work towards a general result for this.
\end{point}
\begin{point}[quotcompr-diamond-adjoint]{Lemma}%
In a~$\dagger'$-effectus,
$\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$.
\begin{point}{Proof}%
    Pick any sharp~$t,u$.
We have to
    show~$t \after \zeta_s \leq u^\perp$
    if and only if~$u \after \pi_s \leq t^\perp$.
So assume~$t \after \zeta_s \leq u^\perp$.
Then~$t =  t\after \zeta_s \after \pi_s  \leq  u^\perp \after \pi_s
                 =  (u \after \pi_s)^\perp$
    so~$u \after \pi_s \leq t^\perp$.
For the converse, assume~$u \after \pi_s \leq t^\perp$.
Then~$u \after \asrt_s = u \after \pi_s \after \zeta_s \leq t^\perp \after \zeta_s$.
From this,
    the
    $\diamond$-self-adjointness of~$\asrt_s$
    and the fact that~$t^\perp \after \zeta_s$ is sharp,
    we find~$(t^\perp \after \zeta_s)^\perp \after \pi_s \after \zeta_s \leq
        u^\perp$
    and so
\begin{alignat*}{2}
    t \after \zeta_s
    &\ =\  (t^\perp \after \id)^\perp \after \zeta_s \\
    &\ =\  (t^\perp \after \zeta_s \after \pi_s)^\perp \after \zeta_s \\
    &\ =\  (t^\perp \after \zeta_s)^\perp \after \pi_s \after \zeta_s \\
    &\ \leq \ u^\perp,
\end{alignat*}
as desired. \qed
\end{point}
\end{point}
\begin{point}[dfn-pristine]{Definition}%
In a~$\&$-effectus, a map~$f$ is \Define{pristine}
        if it is pure and~$1\after f$ is sharp.
\end{point}
\begin{point}[standard-form-pristine]{Exercise}%
Show that in a~$\&$-effectus, every pristine map~$h$ is of the form
        \begin{equation*}
            h \ =\ \pi_{\IM h} \after \alpha \after \zeta_{1 \after h}
        \end{equation*}
        for some iso~$\alpha$.
\end{point}
\begin{point}[pristine-asrt]{Proposition}%
In a~$\dagger'$-effectus,
    with pristine map~$h$, we have
\begin{equation*}
    \asrt_p \after h
        \ =\  h \after \asrt_{p \after h}
\end{equation*}
for any predicate~$p$ with~$p \leq \IM h$.
\begin{point}{Proof}%
For brevity,
write~$t = 1 \after h$
    and~$s = \IM h$.
By~\sref{standard-form-pristine}
    there is some iso~$\alpha$
    such that~$h = \pi_s \after \alpha \after \zeta_t$.
    Note~$\IM \asrt_p = \ceil{p } \leq \ceil{s} = s$
    and so~$\asrt_p = \asrt_{s} \after \asrt_p$
    by the first rule of \sref{asrt-absorp-rule}.
By the second rule of \sref{asrt-absorp-rule}
    and~$1 \after p = p \leq s$,
    we see~$p = p \after \asrt_{s}$.
Thus
\begin{alignat*}{2}
    \asrt_p \after \pi_{s}
    &\ =\  \asrt_{s} \after \asrt_{p \after \asrt_{s}} \after \pi_{s} \\
    &\ =\  \pi_{s} \after \zeta_{s} \after
    \asrt_{p \after \pi_{s} \after \zeta_{s}} \after \pi_{s} \\
    &\ =\  \pi_{s}  \after
    \asrt_{p \after \pi_{s}} \after \zeta_{s} \after \pi_{s} 
    &\qquad& \text{by \sref{zeta-through-asrt}
                    and \sref{quotcompr-diamond-adjoint} }\\
    &\ =\  \pi_{s}  \after
    \asrt_{p \after \pi_{s}}.
\end{alignat*}
Putting everything together
\begin{alignat*}{2}
   \asrt_p \after h
   & \ =\  \asrt_p \after \pi_s \after \alpha \after \zeta_t \\
   & \ =\  \pi_s \after \asrt_{p\after\pi_s} \after \alpha \after \zeta_t  \\
   & \ =\  \pi_s \after \alpha \after \asrt_{p\after\pi_s \after \alpha} \after \zeta_t 
   &\qquad&\text{by \sref{asrt-iso}}\\
   & \ =\  \pi_s \after \alpha \after \zeta_t \after \asrt_{p\after\pi_s \after \alpha \after \zeta_t} 
    &\qquad& \text{by \sref{zeta-through-asrt}
                    and \sref{quotcompr-diamond-adjoint} }\\
   & \ = \ h \after \asrt_{p \after h},
\end{alignat*}
as desired.\qed
\end{point}
\end{point}
\begin{point}[asrt-pristine-reverse]{Exercise}%
Working in a~$\dagger'$-effectus, show in order
\begin{enumerate}
    \item if~$h \equiv \pi_{\IM h} \after \alpha \after \zeta_{1 \after h}$
            is some pristine map,
            then~$h^\dagger = \pi_{1 \after h} \after \alpha^{-1} \after \zeta_{\IM h}$;
    \item $h^{\dagger\dagger} = h$ for any pristine~$h$;
    \item $h^\dagger \after h = \asrt_{1 \after h}$ for any pristine map~$h$;
    \item $p \after h^\dagger \leq \IM h$ for any predicate~$p$ \emph{and}
    \item
        if~$p \leq 1 \after h$,
        then~$\asrt_{p\after h^\dagger} \after h = h \after \asrt_p$.
\end{enumerate}
\end{point}
\begin{point}[prist-asrt-decomp]{Proposition}%
In a~$\dagger'$-effectus,
        for every pure map~$f$,
    there exists a unique pristine map~$h$
    with~$1 \after h = \ceil{1 \after f}$
    and~$f = h \after \asrt_{1 \after f}$.
    Furthermore~$f^\dagger = \asrt_{1 \after f}\after h^\dagger$.
\begin{point}{Proof}%
By~\sref{standard-form-map}
 we know~$f = \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1 \after f}}
        \after \asrt_{1 \after f}$
        for some iso~$\alpha$.
Define~$h = \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1 \after f}}$.
Clearly~$1 \after h = \ceil{1 \after f}$
    and $f = h \after \asrt_{1 \after f}$.
    Also
    \begin{alignat*}{2}
        f^\dagger &\ \equiv\ 
        \asrt_{1 \after f}
            \after \pi_{\ceil{1 \after f}}
            \after \alpha^{-1}
            \after \zeta_{\IM f} \\
        &\ = \ 
        \asrt_{1 \after f}
        \after \asrt_{\ceil{1 \after f}}
            \after \pi_{\ceil{1 \after f}}
            \after \alpha^{-1} 
            \after \zeta_{\IM f} 
            &\qquad&\text{by \sref{asrt-absorp-rule}}
            \\
        &\ \equiv \ 
        \asrt_{1 \after f}
        \after h^\dagger.
\end{alignat*}
Only uniqueness remains.
Assume~$f = h' \after \asrt_{1 \after f}$
    for some (other) pristine
    map~$h'$ with~$\ceil{1 \after h'} = \ceil{1 \after f}$.
By \sref{standard-form-map} and \sref{asrt-absorp-rule},
    there is an iso~$\alpha'$
    with~$h' = \pi_{\IM h} \after \alpha' \after \zeta_{\ceil{1 \after f}}$.
As~$\zeta_{\ceil{1 \after f}} \after \asrt_{1 \after f}$
    is a quotient (by \sref{zeta-asrt-quot}),
    quotients are faithful and~$f = h' \after \asrt_{1 \after f}$,
    we see~$\IM h' = \IM f$
    and so~$\alpha = \alpha'$ by \sref{standard-form-map}.\qed
\end{point}
\end{point}
\begin{point}[dagger-idempotent]{Proposition}%
    In a~$\dagger'$-effectus, we have~$f^{\dagger\dagger}=f$
        for any pure map~$f$.
\begin{point}{Proof}%
By~\sref{prist-asrt-decomp}
    we have~$f = h \after \asrt_{1\after f}$
    and~$f^\dagger = \asrt_{1 \after f} \after h^\dagger$
    for some pristine~$h$
    with~$1 \after h = \ceil{1 \after f}$.
Clearly~$1 \after f \leq \ceil{1 \after f} = 1 \after h = \IM h^\dagger$,
    so by \sref{pristine-asrt}
    we get~$f^\dagger = \asrt_{1 \after f} \after h^\dagger
              = h^\dagger \after \asrt_{1 \after f \after h^\dagger}$.
Consequently
\begin{equation*}
    f^{\dagger\dagger}
    \ =\  \asrt_{1 \after f\after h^\dagger} \after h^{\dagger\dagger}
    \ \overset{\sref{asrt-pristine-reverse}}{=}\  \asrt_{1 \after f\after h^\dagger} \after h
    \ \overset{\sref{asrt-pristine-reverse}}{=}\  h\after \asrt_{1 \after f}
    \ = \ f,
\end{equation*}
as desired. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
Now we tackle the most tedious part
    of \sref{dagger-theorem}:
    we will show~$(f \after g)^\dagger = g^\dagger \after f^\dagger$
    in a~$\dagger'$-effectus.
To avoid too much repetition, let us fix the setting.
\end{point}%
\begin{point}[dagger-setting]{Setting}%
Let~$f,g$ be two composable pure maps in a~$\dagger'$-effectus.
For brevity, write~$p = 1 \after f$, $q = 1 \after g$,
    $s = \IM f$ and $t = \IM g$.
Let~$\varphi$ and~$\psi$
be the unique isomorphisms (see \sref{standard-form-map}) such that
\begin{equation*}
    f \ =\  \pi_s \after \varphi \after \zeta_{\ceil{p}} \after \asrt_p 
    \qquad \text{and} \qquad
    g \ =\  \pi_t \after \psi \after \zeta_{\ceil{q}} \after \asrt_q.
\end{equation*}
Define~$
    h = \pi_s \after \varphi \after \zeta_{\ceil{p}}$
    and~$k = \pi_t \after \psi \after \zeta_{\ceil{q}}$.
To compute~$(f\after g)^\dagger$,
    we have to put~$f\after g$
    in the standard form
    of~\sref{standard-form-map}.
We will do this step-by-step,
    first we put~$\zeta_{\ceil{p}} \after \asrt_p \after \pi_t$
        in standard form.
\begin{align*}
1 \after \zeta_{\ceil{p}} \after \asrt_p \after \pi_t
&\ =\  \ceil{p} \after \asrt_p \after \pi_t
    \ \overset{\sref{asrt-absorp-rule}}{=}\  p \after \pi_t\\
    \IM \zeta_{\ceil{p}}  \after \asrt_p \after \pi_t &\ = \ 
(\zeta_{\ceil{p}}  \after \asrt_p)_\diamond(t)
\ \overset{\sref{quotcompr-diamond-adjoint}}{=} \ \ceil{t \after \asrt_p \after \pi_{\ceil{p}}}.
\end{align*}
Thus there is a unique isomorphism~$\chi$ with
\begin{equation}\label{dagger-iso-chi}
    \zeta_{\ceil{p}} \after \asrt_p \after \pi_t
    \ = \ \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after \chi \after \zeta_{\ceil{p \after \pi_t}} \after \asrt_{p \after \pi_t}.
\end{equation}
Next, we consider~$\asrt_{p \after k}
                        \after \asrt_q$, clearly
\begin{equation*}
    1 \after \asrt_{p \after k}
\after \asrt_q 
\ =\ p \after k
\after \asrt_q \ = \ p \after g.
\end{equation*}
Concerning the image, first
    note~$p \after k = p \after \pi_t \after \psi \after \zeta_{\ceil{q}}
    \leq 1 \after \zeta_{\ceil{q}} = \ceil{q}$
        and so we must have~$\IM \asrt_{p \after k} \leq \ceil{q}$, which implies
\begin{equation*}
\IM \asrt_{p \after k}
\after \asrt_q
\ = \ (\asrt_{p \after k})_\diamond(q)
\ =\  \ceil{\ceil{q} \after \asrt_{p \after k}}
\ =\  \ceil{p \after k}.
\end{equation*}
So there is a unique isomorphism~$\omega$ such that
\begin{equation}\label{dagger-iso-omega}
\asrt_{p \after k} \after \asrt_q
    \ =\   \pi_{\lceil p \after k \rceil}
    \after \omega \after \zeta_{\ceil{p \after g}} \after \asrt_{p \after g}.
\end{equation}
Next, we consider~$
\zeta_{\ceil{p \after \pi_t}} \after \psi \after
                \zeta_{\ceil{q}}$.
Note~$\psi \after \zeta_{\ceil{q}}$
    is a quotient for a sharp predicate,
    hence sharp and so~$\ceil{p \after \pi_t} \after \psi \after \zeta_{\ceil{q}}
                =\lceil p \after \pi_t \after \psi
                \after \zeta_{\ceil{q}}\rceil = \lceil p \after k \rceil$
                by \sref{sharp-ceil}.
As quotients are closed under composition
(\sref{quotients-composition}),
    there is an iso~$\beta$
    with
    \begin{equation}\label{dagger-iso-beta}
    \zeta_{\ceil{p \after \pi_t}} \after \psi \after \zeta_{\ceil{q}}
    \ = \ \beta \after \zeta_{\ceil{p \after k}}.
\end{equation}
Finally, we deal with~$
\pi_s \after \varphi \after 
\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil}
$.
By \sref{upm-closed} this is again a comprehension.
We compute
\begin{align*}
    \IM
\pi_s \after \varphi \after 
\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil}
& \ = \ 
(\pi_s \after \varphi \after 
\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil})_\diamond(1)
\\
& \ \overset{\smash{\mathclap{\sref{quotcompr-diamond-adjoint}}}}{=}\ 
\zeta_s^\diamond ( \varphi_\diamond (
\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil)) \\
& \ =\ 
\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil
\after \varphi^{-1} \after \zeta_s \\
& \ \overset{\smash{\mathclap{\sref{sharp-ceil}}}}{=}\ 
\lceil t \after \asrt_p \after \pi_{\ceil{p}}
\after \varphi^{-1} \after \zeta_s \rceil \\
& \ =\ 
\lceil t \after f^\dagger\rceil
\end{align*}
and so there must be a unique iso~$\alpha$ with
\begin{equation}\label{dagger-iso-alpha}
    \pi_s \after \varphi \after \pi_{\lceil t \after \asrt_p \after
    \pi_{\ceil{p}} \rceil} = \pi_{\ceil{t \after f^\dagger}} \after \alpha.
\end{equation}
\end{point}
\begin{point}{Lemma}%
In setting \sref{dagger-setting}, we have
    $f \after g  =  \pi_{\ceil{t \after f^\dagger}}
        \after \alpha \after \chi \after \beta \after \omega
        \after \zeta_{\ceil{p \after g}} \after
        \asrt_{p \after g}$.
\begin{point}{Proof}%
It's a long, but easy verification,
    either with a diagram
\begin{equation*}
    \xymatrix@C+3pc {
        \bullet \ar[rr]^g
        \ar[rd]|{\asrt_q}
        \ar[ddd]_{\rotatebox{90}{$\scriptstyle\omega\after\zeta_{\ceil{p \after g}} \after \asrt_{p \after g}$}}
        && \bullet \ar[rr]^f
            \ar[rd]|{\zeta_{\ceil{p}}\after \asrt_p}
        && \bullet
            \\ \ar@{}[rd]|{\text{\eqref{dagger-iso-omega}}}
            & \bullet
                \ar[r]^{\psi \after \zeta_{\ceil{q}}}
                \ar[d]|{\asrt_{p \after k}}
                \ar@{}[rd]|{\text{\sref{pristine-asrt}}}
 & \bullet
            \ar[u]^{\pi_t}
            \ar[d]|{\asrt_{p \after \pi_t}}
            & \bullet \ar[ru]_{\pi_s\after\varphi}
            \ar@{}[rd]|{\text{\eqref{dagger-iso-alpha}}}
            \\& \bullet \ar[r]^{\psi \after \zeta_{\ceil{q}}}
                        \ar[d]|{\zeta_{\ceil{p \after k}}}
                \ar@{}[rd]|{\text{\eqref{dagger-iso-beta}}}
            &\bullet \ar[d]|{\zeta_{\ceil{p \after \pi_t}}}
                        \ar@{}[ru]|{\text{\eqref{dagger-iso-chi}}}
                        &&
            \\ \bullet \ar@{=}[r]
            \ar[ru]^{\pi_{\ceil{p \after k}}}
            &\bullet \ar[r]_\beta
            &\bullet \ar[rr]_\chi
            &&\bullet \ar[uuu]_{\rotatebox{90}{$\scriptstyle\pi_{\ceil{t \after f^\dagger}} \after \alpha$}}
                        \ar[luu]|{\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}}
        }
\end{equation*}
or with equational reasoning
\begin{align*}
   f \after g
    & \ = \ \pi_s \after \varphi \after \zeta_{\ceil{p}}
        \after \asrt_p \after \pi_t \after \psi \after \zeta_{\ceil{q}}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-chi}}}}{=} \ 
        \pi_s \after \varphi \after
        \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \chi \after \zeta_{\ceil{p \after \pi_t}}
        \after \asrt_{p \after \pi_t}
    \after \psi \after 
        \zeta_{\ceil{q}}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\sref{pristine-asrt}}}}{=} \ 
        \pi_s \after \varphi \after
        \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \chi \after \zeta_{\ceil{p \after \pi_t}}
        \after \psi \after \zeta_{\ceil{q}}
        \after \asrt_{p \after k}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-beta}}}}{=} \ 
        \pi_s \after \varphi \after
        \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \chi
        \after \beta \after \zeta_{\ceil{p \after k}}
        \after \asrt_{p \after k}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-alpha}}}}{=} \ 
        \pi_{\ceil{t \after f^\dagger}}\after\alpha
        \after \chi
        \after \beta \after \zeta_{\ceil{p \after k}}
        \after \asrt_{p \after k}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-omega}}}}{=} \ 
        \pi_{\ceil{t \after f^\dagger}}\after\alpha
        \after \chi
        \after \beta \after \zeta_{\ceil{p \after k}}
        \after \pi_{\ceil{p \after k}} \after \omega
            \after \zeta_{\ceil{p \after g}}
            \after \asrt_{p \after g} \\
    & \ = \ 
        \pi_{\ceil{t \after f^\dagger}}\after\alpha
        \after \chi
        \after \beta \after
        \omega
            \after \zeta_{\ceil{p \after g}}
            \after \asrt_{p \after g},
\end{align*}
whichever the Reader might prefer. \qed
\end{point}
\end{point}
\begin{point}[dagger-of-fg]{Corollary}%
    $(f \after g)^\dagger = \asrt_{p \after g}
                \after \pi_{\ceil{p \after g}}
                \after \omega^{-1}
                \after \beta^{-1}
                \after \chi^{-1}
                \after \alpha^{-1}
                \after \zeta_{\ceil{t \after f^\dagger}} $ .
\begin{point}%
To show~$(f \after g)^\dagger = g^\dagger \after f^\dagger$,
    it is sufficient to proof that
    the `daggered' version
    of each of the subdiagrams
        \eqref{dagger-iso-alpha},
        \eqref{dagger-iso-beta},
        \eqref{dagger-iso-chi},
        \eqref{dagger-iso-omega} and
        \sref{pristine-asrt} of the above diagram holds.
We start with the simple ones.
\end{point}
\end{point}
\begin{point}[dagger-iso-beta2]{Lemma}%
In setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-beta} holds --- that is:
    \begin{equation*}
        \pi_{\ceil{p \after k}} \after \beta^{-1}
            \ =\  \pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}.
    \end{equation*}
\begin{point}{Proof}%
The map~$
\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}} \after \beta$
is a comprehension for~$\ceil{p \after k}$ --- indeed
\begin{align*}
    (\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}\after\beta)_\diamond(1)
    &\ = \ 
    (\zeta^\diamond_{\ceil{q}} \after \psi^\diamond) (\ceil{p \after \pi_t})\\
    &\ = \ \ceil{p \after \pi_t} \after \zeta_{\ceil{q}} \after \psi \\
    &\ = \ \ceil{p \after \pi_t \after \zeta_{\ceil{q}} \after \psi} \\
    &\ = \ \ceil{p \after k}.
\end{align*}
Furthermore
\begin{align*}
    &\zeta_{\ceil{p \after k}} \after
    \pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
    \after \beta \\
    & \qquad \ \overset{\mathclap{\eqref{dagger-iso-beta}}}{=}\  
    \beta^{-1}\after \zeta_{\ceil{p \after \pi_t}}
    \after \psi \after \zeta_{\ceil{q}}
    \after \pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
    \after \beta \\
    & \qquad \ = \ \id.
\end{align*}
So~$
\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
\after \beta
$ is the unique comprehension corresponding to~$\zeta_{\ceil{p \after k}}$ --- that is:~$
\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
\after \beta \ = \ \pi_{\ceil{p \after k}} $,
as desired. \qed
\end{point}
\end{point}
\begin{point}[dagger-iso-alpha2]{Exercise}%
Show that in the setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-alpha} holds --- i.e.
    \begin{equation*}
        \alpha^{-1} \after \zeta_{\ceil{t \after f^\dagger}}
        \ =\   \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \varphi^{-1} \after \zeta_s.
    \end{equation*}
(Hint: mimic the proof of~\sref{dagger-iso-beta2}.)
\end{point}
\begin{point}[dagger-iso-zeta2]{Exercise}%
Show that in the setting \sref{dagger-setting},
we have
\begin{equation*}
    \pi_{\ceil{q}} \after \psi^{-1} \after \asrt_{p \after \pi_t}
    \ = \ \asrt_{p \after k} \after \pi_{\ceil{q}} \after \psi^{-1}.
\end{equation*}
(This is the daggered version of the subdiagram
marked~\sref{pristine-asrt}.)
\end{point}
\begin{point}[dagger-iso-mu]{Proposition}%
If in a~$\dagger'$-effectus,
$\nu$ is the unique iso (cf.~\sref{pqqp-from-dagger}) such that
\begin{equation*}
    \asrt_a \after \asrt_b\  =\  \pi_{\ceil{\andthen{a}{b}}} 
    \after \nu \after \zeta_{\ceil{\andthen{b}{a}}} \after \asrt_{\andthen{b}{a}},
\end{equation*}
then~$\asrt_b \after \asrt_a\  =\  \asrt_{\andthen{b}{a}}
        \after \pi_{\ceil{\andthen{b}{a}}} 
        \after \nu^{-1} \after \zeta_{\ceil{\andthen{a}{b}}}$.
\begin{point}{Proof}%
Let~$\mu$ be the unique iso with~$
\asrt_b \after \asrt_a\  =\  
        \pi_{\ceil{\andthen{b}{a}}} 
        \after \mu \after \zeta_{\ceil{\andthen{a}{b}}}
                \after \asrt_{{\andthen{a}{b}}}$.
We will see~$\mu = \nu^{-1}$.
For brevity, write
\begin{align*}
    \overline{\andthen{a}{b}} &\ = \ (\andthen{a}{b}) \after \pi_{\ceil{\andthen{a}{b}}} &
\overline{\andthen{b}{a}} &\ = \ (\andthen{b}{a}) \after \pi_{\ceil{\andthen{b}{a}}}
\end{align*}
By \sref{asrt-pristine-reverse} and~\sref{asrt-absorp-rule}, we have
\begin{equation*}
    \pi_{\ceil{\andthen{a}{b}}} \after
\asrt_{\overline{\andthen{a}{b}}} \after
 \zeta_{\ceil{\andthen{a}{b}}}
    \ = \ 
    \pi_{\ceil{\andthen{a}{b}}} \after
 \zeta_{\ceil{\andthen{a}{b}}} \after
\asrt_{\andthen{a}{b}}
    \ = \ 
\asrt_{\andthen{a}{b}}.
\end{equation*}
Now the second axiom of a~$\dagger'$-effectus comes into play
\begin{align*}
    &\pi_{\ceil{\andthen{a}{b}}} \after
    \asrt^2_{\overline{\andthen{a}{b}}} \after \zeta_{\ceil{\andthen{a}{b}}} \\
    &\qquad \ = \ 
    \pi_{\ceil{\andthen{a}{b}}} \after
\asrt_{\overline{\andthen{a}{b}}} \after
 \zeta_{\ceil{\andthen{a}{b}}} \after
\pi_{\ceil{\andthen{a}{b}}} \after
\asrt_{\overline{\andthen{a}{b}}}
\after \zeta_{\ceil{\andthen{a}{b}}} \\
    &\qquad \ = \ 
\asrt_{\andthen{a}{b}}^2
\\
    &\qquad \ = \ 
\asrt_{a} \after
\asrt^2_{b}\after
\asrt_{a}
\\
    &\qquad \ = \ 
\pi_{\ceil{\andthen{a}{b}}} \after
    \nu \after
    \asrt_{\overline{\andthen{b}{a}}} \after
    \zeta_{\ceil{\andthen{b}{a}}} \after
\pi_{\ceil{\andthen{b}{a}}} \after
    \mu \after
    \asrt_{\overline{\andthen{a}{b}}} \after
    \zeta_{\ceil{\andthen{a}{b}}} 
\\
    &\qquad \ = \ 
\pi_{\ceil{\andthen{a}{b}}} \after
    \nu \after
    \asrt_{\overline{\andthen{b}{a}}} \after
    \mu \after
    \asrt_{\overline{\andthen{a}{b}}} \after
    \zeta_{\ceil{\andthen{a}{b}}}.
\end{align*}
Thus as quotients are epis and comprehensions are monos:
\begin{equation} \label{dagger-second-axiom-intermediate}
\asrt^2_{\overline{\andthen{a}{b}}}
         \ = \ \nu \after \asrt_{\overline{\andthen{b}{a}}}
            \after \mu \after \asrt_{\overline{\andthen{a}{b}}}.
\end{equation}
We want to show~$\asrt_{\overline{\andthen{a}{b}}}$ is an epi.
First note
\begin{equation*}
    \ceil{\overline{\andthen{a}{b}}}\after\zeta_{\ceil{\andthen{a}{b}}}
    \ \overset{\sref{sharp-ceil}}{=} \ 
    \ceil{\overline{\andthen{a}{b}}\after\zeta_{\ceil{\andthen{a}{b}}}}
    \ \overset{\sref{asrt-absorp-rule}}{=} \ 
    \ceil{\andthen{a}{b}} \ = \ 1 \after \zeta_{\ceil{\andthen{a}{b}}}
\end{equation*}
and so~$\IM \asrt_{\overline{\andthen{a}{b}}}
= \ceil{\overline{\andthen{a}{b}}} = 1 $,
    which tells us~$\asrt_{\overline{\andthen{a}{b}}}$
    is a quotient and therefore an epi.
    So, from \eqref{dagger-second-axiom-intermediate} we get
    $ \asrt_{\overline{\andthen{a}{b}}}
     =  \nu \after \asrt_{\overline{\andthen{b}{a}}} \after \mu$ and so
\begin{equation}\label{dagger-seqprod-inversion}
    \overline{\andthen{a}{b}}
    \ = \ 1 \after \asrt_{\overline{\andthen{a}{b}}}
    \ = \ 1 \after \nu \after \asrt_{\overline{\andthen{b}{a}}} \after \mu
    \ = \ \overline{\andthen{b}{a}} \after \mu.
\end{equation}
Using this equation again in the previous, we find
\begin{equation*}
    \nu \after \mu \after \asrt_{\overline{\andthen{a}{b}}}
            \ = \ 
    \nu \after \mu \after \asrt_{\overline{\andthen{b}{a}}\after \mu}
            \ = \ 
    \nu \after \asrt_{\overline{\andthen{b}{a}}} \after \mu
            \ = \ \asrt_{\overline{\andthen{a}{b}}}.
\end{equation*}
Thus~$\nu \after \mu = \id$ and so~$\mu = \nu^{-1}$.
Write~$l = \pi_{\ceil{\andthen{b}{a}}} \after \nu^{-1}
                        \after \zeta_{\ceil{\andthen{a}{b}}}$. Then
\begin{alignat*}{2}
    (\andthen{a}{b}) \after l^\dagger & \ = \ 
    (\andthen{a}{b})
        \after \pi_{\ceil{\andthen{a}{b}}} 
        \after \nu
        \after \zeta_{\ceil{\andthen{b}{a}}}  
        &\qquad& \text{by \sref{asrt-pristine-reverse}}\\
        & \ = \ 
        \overline{\andthen{a}{b}}
        \after \nu
        \after \zeta_{\ceil{\andthen{b}{a}}}  \\
        & \ = \ 
        \overline{\andthen{b}{a}}
        \after \zeta_{\ceil{\andthen{b}{a}}}  
        &&\text{by \eqref{dagger-seqprod-inversion} and~$\mu = \nu^{-1}$}\\
        & \ = \ 
        \andthen{b}{a}.
\end{alignat*}
And so, keeping in mind~$\andthen{a}{b} \leq \ceil{\andthen{a}{b}}
    =  1 \after l$,
we have
\begin{alignat*}{2}
    \asrt_b \after \asrt_a &\ = \ 
        l \after \asrt_{\andthen{a}{b}} \\
        & \ = \ 
        \asrt_{(\andthen{a}{b}) \after l^\dagger} \after l 
    &\qquad&\text{by \sref{asrt-pristine-reverse}} \\
        &\ = \ 
        \asrt_{\andthen{b}{a}} \after l \\
        &\ = \ 
        \asrt_{\andthen{b}{a}}
        \after \pi_{\ceil{\andthen{b}{a}}} 
        \after \nu^{-1} \after \zeta_{\ceil{\andthen{a}{b}}},
\end{alignat*}
as promised. \qed
\end{point}
\end{point}
\begin{point}[dagger-iso-omega2]{Corollary}
In setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-omega} holds --- that is:
    \begin{equation*}
\asrt_q \after
\asrt_{p \after k}
    \ =\ 
    \asrt_{p \after g} \after
    \pi_{\ceil{p \after g}} \after
    \omega^{-1} \after
    \zeta_{\lceil p \after k \rceil}.
    \end{equation*}
\end{point}
\begin{point}[dagger-iso-chi2]{Lemma}%
In setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-chi} holds --- that is:
    \begin{equation*}
    \zeta_t \after
    \asrt_p \after
    \pi_{\ceil{p}}
    \ = \ 
    \asrt_{p \after \pi_t} \after
    \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil}.
    \end{equation*}
\begin{point}{Proof}%
The heavy lifting has been done in \sref{dagger-iso-mu} already. To start, note
    \begin{align*}
\asrt_p \after \asrt_t
& \ \overset{\mathclap{\smash{\sref{asrt-absorp-rule}}}}{=}
    \ \asrt_{\ceil{p}} \after \asrt_p  \after \asrt_t \\
    & \ = \ \pi_{\ceil{p}} \after \zeta_{\ceil{p}} \after \asrt_p \after
                    \pi_t \after \zeta_t \\
                    & \ \overset{\mathclap{\smash{\eqref{dagger-iso-chi}}}}{=} \ 
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \chi \after \zeta_{\ceil{p \after \pi_t}} \after
        \asrt_{p \after \pi_t} \after
        \zeta_t \\
                    & \ \overset{\mathclap{\smash{\sref{pristine-asrt}}}}{=} \ 
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \chi \after \zeta_{\ceil{p \after \pi_t}} \after
        \zeta_t \after
        \asrt_{p \after \pi_t\after \zeta_t} \\
                    & \  = \ 
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \chi \after
        \zeta_{\ceil{p \after \pi_t}} \after
        \zeta_t \after
        \asrt_{\andthen{t}{p}} \\
                    & \  = \ 
        \pi_{\ceil{\andthen{p}{t}}} \after \alpha_2 \after
        \chi \after \beta_2 \after
        \zeta_{\ceil{\andthen{t}{p}}} \after
        \asrt_{\andthen{t}{p}},
    \end{align*}
where~$\alpha_2$ and~$\beta_2$ are the unique isomorphisms such that
\begin{align*}
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} &\ = \ 
            \pi_{\ceil{\andthen{p}{t}}} \after \alpha_2 &
        \zeta_{\ceil{p \after \pi_t}} \after
        \zeta_t
        &\ = \ 
        \beta_2 \after \zeta_{\ceil{\andthen{t}{p}}}.
\end{align*}
With the same reasoning as in \sref{dagger-iso-alpha2}
        and~\sref{dagger-iso-beta2}, we see
\begin{align*}
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \zeta_{\ceil{p}}
        &\ = \ 
        \alpha_2^{-1} \after
            \zeta_{\ceil{\andthen{p}{t}}}
            &
        \pi_t \after
        \pi_{\ceil{p \after \pi_t}}
        &\ = \ 
        \pi_{\ceil{\andthen{t}{p}}}
        \after \beta_2^{-1}.
\end{align*}
Now we can apply \sref{dagger-iso-mu}:
\begin{align*}
    \zeta_t \after \asrt_p \after \pi_{\ceil{p}} 
    &\ \overset{\smash{\mathclap{\sref{asrt-absorp-rule}}}}{=} \ 
    \zeta_t \after \asrt_t \after
    \asrt_p \after
    \pi_{\ceil{p}}
    \\
    &\ \overset{\smash{\mathclap{\sref{dagger-iso-mu}}}}{=} \ 
    \zeta_t \after \asrt_{\andthen{t}{p}} \after
    \pi_{\ceil{\andthen{t}{p}}} \after
    \beta_2^{-1} \after
    \chi^{-1} \after
    \alpha_2^{-1} \after
    \zeta_{\ceil{\andthen{p}{t}}} \after
    \pi_{\ceil{p}}
    \\
    &\ = \ 
    \zeta_t \after \asrt_{\andthen{t}{p}} \after
        \pi_t \after
        \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \zeta_{\ceil{p}} \after
    \pi_{\ceil{p}}
    \\
    &\ = \ 
    \zeta_t \after \asrt_{p \after \pi_t \after \zeta_t} \after
        \pi_t \after
        \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil}
    \\
    &\ = \ 
    \asrt_{p \after \pi_t} \after 
        \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil},
\end{align*}
as desired. \qed
\end{point}
\end{point}
\begin{point}[dagger-is-functor]{Proposition}%
In a~$\dagger'$-effectus~$(f \after g)^\dagger = g^\dagger \after f^\dagger$
    holds.
\begin{point}{Proof}%
We work in setting~\sref{dagger-setting}.
The equality~$(f\after g)^\dagger = g^\dagger \after f^\dagger$
follows from~\sref{dagger-of-fg} and the commutativity
of the following diagram
\begin{equation*}
    \xymatrix@C+3pc {
        \bullet \ar@{<-}[rr]^{g^\dagger}
        \ar@{<-}[rd]|{\asrt_q}
        \ar@{<-}[ddd]_{\rotatebox{90}{$\scriptstyle
            \asrt_{p \after g}
            \pi_{\ceil{p \after g}} \after
            \omega^{-1}
        $}}
        && \bullet \ar@{<-}[rr]^{f^\dagger}
            \ar@{<-}[rd]|{ \asrt_p \after \zeta_{\ceil{p}} }
        && \bullet
            \\ \ar@{}[rd]|{\text{\sref{dagger-iso-omega2}}}
            & \bullet
            \ar@{<-}[r]^{ \pi_{\ceil{q}} \after \psi^{-1} }
            \ar@{<-}[d]|{\asrt_{p \after k}}
                \ar@{}[rd]|{\text{\sref{dagger-iso-zeta2}}}
 & \bullet
                \ar@{<-}[u]^{\zeta_t}
                \ar@{<-}[d]|{\asrt_{p \after \pi_t}}
                & \bullet \ar@{<-}[ru]_{\varphi^{-1} \after \zeta_s}
            \ar@{}[rd]|{\text{\sref{dagger-iso-alpha2}}}
            \\& \bullet \ar@{<-}[r]^{\pi_{\ceil{q}} \after \psi^{-1}}
            \ar@{<-}[d]|{\pi_{\ceil{p \after k}}}
                \ar@{}[rd]|{\text{\sref{dagger-iso-beta2}}}
                &\bullet \ar@{<-}[d]|{\pi_{\ceil{p \after \pi_t}}}
                        \ar@{}[ru]|{\text{\sref{dagger-iso-chi2}}}
                        &&
            \\ \bullet \ar@{=}[r]
            \ar@{<-}[ru]^{\zeta_{\ceil{p \after k}}}
            &\bullet \ar@{<-}[r]_{\beta^{-1}}
            &\bullet \ar@{<-}[rr]_{\chi^{-1}}
            &&\bullet \ar@{<-}[uuu]_{\rotatebox{90}{$\scriptstyle
    \alpha^{-1}\after \zeta_{\ceil{t \after f^\dagger}}$}}
    \ar@{<-}[luu]|{ \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}} }
\end{equation*}
or alternatively by
\begin{align*}
    g^\dagger \after f^\dagger
        & \ = \ 
            \asrt_q \after
            \pi_{\ceil{q}} \after
            \psi^{-1} \after
            \zeta_t \after
            \asrt_p \after
            \pi_{\ceil{p}} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-chi2}}}}{=} \ 
            \asrt_q \after
            \pi_{\ceil{q}} \after
            \psi^{-1} \after
    \asrt_{p \after \pi_t} \after
    \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-zeta2}}}}{=} \ 
            \asrt_q \after
    \asrt_{p \after k} \after
    \pi_{\ceil{q}} \after
    \psi^{-1} \after
    \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-beta2}}}}{=} \ 
            \asrt_q \after
    \asrt_{p \after k} \after
        \pi_{\ceil{p \after k}} \after 
        \beta^{-1} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-alpha2}}}}{=} \ 
            \asrt_q \after
    \asrt_{p \after k} \after
        \pi_{\ceil{p \after k}} \after 
        \beta^{-1} \after
    \chi^{-1} \after
        \alpha^{-1} \after
        \zeta_{\ceil{t \after f^\dagger}}
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-omega2}}}}{=} \ 
    \asrt_{p \after g} \after
    \pi_{\ceil{p \after g}} \after
    \omega^{-1} \after
    \zeta_{\lceil p \after k \rceil} \after
        \pi_{\ceil{p \after k}} \after 
        \beta^{-1} \after
    \chi^{-1} \after
        \alpha^{-1} \after
        \zeta_{\ceil{t \after f^\dagger}}
        \\
        & \ = \ 
    \asrt_{p \after g} \after
    \pi_{\ceil{p \after g}} \after
    \omega^{-1} \after
        \beta^{-1} \after
    \chi^{-1} \after
        \alpha^{-1} \after
        \zeta_{\ceil{t \after f^\dagger}}
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-of-fg}}}}{=} \ 
        (f \after g)^\dagger,
\end{align*}
whichever the Reader might prefer. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}%
\begin{point}%
We are ready to finish the proof of \sref{dagger-theorem}.
\end{point}
\begin{point}[dagger-thm-sufficiency]{Theorem}%
    A~$\dagger'$-effectus is a~$\dagger$-effectus
        with~$\dagger$
            as defined in \sref{dagger-definition2}.
\begin{point}{Proof}%
Let~$C$ be a~$\dagger'$-effectus.
\begin{point}{Ax.~1}%
By~\sref{dagger-is-functor}, \sref{dagger-idempotent}
    and~\sref{dagger-prime-basics}
    the~$\dagger$ defined in~\sref{dagger-definition2}
    turns~$\Pure C$ into a~$\dagger$-category.
Also by~\sref{dagger-prime-basics},
    we have~$\asrt_p^\dagger = \asrt_p$
    for any predicate~$p$.
Pick any pure~$f$.
We have to show~$f$ is~$\diamond$-adjoint to~$f^\dagger$.
By~\sref{standard-form-map}
    we have~$f =
    \pi_{\IM f} \after \varphi \after \zeta_{\ceil{1 \after f}}
        \after \asrt_{1 \after f}$
        for some iso~$\alpha$.
We compute
\begin{align*}
   f_\diamond 
   & \ = \ 
   (\pi_{\IM f})_\diamond \after \varphi_\diamond \after (\zeta_{\ceil{1 \after f}})_\diamond
   \after (\asrt_{1 \after f})^\diamond \\
   & \ \overset{\mathclap{\smash{\sref{quotcompr-diamond-adjoint}}}}{=} \ 
   (\zeta_{\IM f})^\diamond \after \varphi_\diamond \after (\pi_{\ceil{1 \after f}})^\diamond
   \after (\asrt_{1 \after f})^\diamond \\
   & \ \overset{\mathclap{\smash{\sref{iso-diamond-adjoint}}}}{=} \ 
   (\zeta_{\IM f})^\diamond \after (\varphi^{-1})^\diamond \after (\pi_{\ceil{1 \after f}})^\diamond
   \after (\asrt_{1 \after f})^\diamond \\
   & \ = \ 
   (\asrt_{1 \after f} \after
   \pi_{\ceil{1 \after f}} \after
   {\varphi^{-1}} \after
   \zeta_{\IM f})^\diamond
   \\
   & \ = \ 
   (f^\dagger)^\diamond,
\end{align*}
so~$f$ is indeed~$\diamond$-adjoint to~$f^\dagger$.
\end{point}
\begin{point}{Ax.~2}%
Let~$f$ be a~$\dagger$-positive map.
That is: $f = h^\dagger \after h$ for some pure map~$h$.
By~\sref{standard-form-map}
    we have~$h =
    \pi_{\IM h} \after \alpha \after \zeta_{\ceil{1 \after h}}
                    \after \asrt_{1 \after h}
                    $
                    for some iso~$\alpha$.
            We compute
\begin{align*}
    f &\ = \ h^\dagger \after h \\
    &\ = \ 
    \asrt_{1 \after h} \after \pi_{\ceil{1 \after  h}} \after \alpha^{-1} \after \zeta_{\IM h} \after
    \pi_{\IM h} \after \alpha \after \zeta_{\ceil{1 \after h}}
                    \after \asrt_{1 \after h}
                    \\
    &\ = \ 
    \asrt_{1 \after h} \after \asrt_{\ceil{1 \after  h}}
                    \after \asrt_{1 \after h}
                    \\
                    &\ \overset{\smash{\mathclap{\sref{asrt-absorp-rule}}}}{=} \ 
    \asrt_{1 \after h} \after \asrt_{1 \after h}.
\end{align*}
Form this it follows that $\dagger$-positive maps are~$\diamond$-positive.
Let~$q$ be the predicate such that~$\andthen{q}{q} = 1 \after h$.
Then
\begin{equation*}
\asrt_{q}^\dagger \after \asrt_{q}  
    \ =\  \asrt_q\after \asrt_q
    \ \overset{\sref{andthen-square-rule}}{=}\  
    \asrt_{\andthen{q}{q}}
    \  =\  \asrt_{1 \after h}.
\end{equation*}
Thus~$\asrt_{1 \after h}$ is a~$\dagger$-positive
    with~$\asrt_{1 \after h} \after \asrt_{1 \after h} = f$.
We have to show~$\asrt_{1 \after h}$
    is the unique map with this property.
Let~$g$ be any (other)~$\dagger$-positive map with~$g \after g = f$.
Recall both~$g$ and~$f$ are~$\diamond$-positive, hence
\begin{equation*}
    \asrt_{1 \after f} \ =\  f\ =\ g \after g \ = \ \asrt_{1 \after g}
            \after \asrt_{1 \after g}
            \ \overset{\smash{\sref{andthen-square-rule}}}{=}\  
            \asrt_{\andthen{(1 \after g)}{(1 \after g)}}.
\end{equation*}
So~$\andthen{(1 \after g)}{(1\after g)} = 1\after f =
            \andthen{(1 \after h)}{(1 \after h)}$.
Hence~$1\after g = 1 \after h$ by uniqueness of the square root.
So~$g = \asrt_{1 \after g} = \asrt_{1 \after h} = h$, as desired.
\end{point}
\begin{point}{Ax.~3}%
Let~$\asrt_p$ be any~$\diamond$-positive map.
Write~$q$ for the unique predicate with~$\andthen{q}{q}=p$.
Then
\begin{equation*}
    \asrt_p
     \ = \ \asrt_{\andthen{q}{q}}
            \ \overset{\smash{\sref{andthen-square-rule}}}{=}\ 
     \asrt_q \after \asrt_q  \ =\ 
     \asrt_q^\dagger \after \asrt_q ,
\end{equation*}
so~$\asrt_p$ is~$\dagger$-positive, as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}

\section{Comparisons}
\subsection{Dagger kernel categories}
\begin{parsec}%
\begin{point}%
To finish, we relate the structures in a~$\dagger$-effectus
    with existing structures in the literature.
Just like we try to axiomatize~$\op\vN$,
    Heunen in the third chapter of his Ph.D-thesis attempted
    to axiomatize~$\mathsf{Hilb}$,
    the category of Hilbert spaces with bounded operators.
Heunen came very close:
    he proves that a~$\dagger$-category obeying
    certain additional axioms must embed into~$\mathsf{Hilb}$.
    \cite[3.7.18]{heunenphd}
We will discover that some of his axioms for~$\mathsf{Hilb}$
    hold in~$\Pure(C)$ for a~$\dagger$-effectus~$C$
    and other do not in general.
(We do not cover all his axioms.)
\end{point}
\begin{point}{Definition}%
Let~$C$ be a~$\dagger$-category.
We say that an arrow~$f$
    is \Define{$\dagger$-mono}
    iff~$f^\dagger \after f = f$
    and dually~$f$ is \Define{$\dagger$-epi}
    iff~$f\after f^\dagger = f$.
An arrow~$f$ is a \Define{$\dagger$-partial isometry}
    if~$f = m \after e$
    for some~$\dagger$-mono~$m$
    and~$\dagger$-epi~$e$.

A~\Define{$\dagger$-kernel} of~$f$
is a~$\dagger$-mono equalizer of~$f$ with~$0$.
A~\Define{$\dagger$-kernel category} is a~$\dagger$-category
    with zero object and where each arrow has a~$\dagger$-kernel.
\cite[3.2.20]{heunenphd}
\end{point}
\begin{point}{Proposition}%
In~$\Pure(C)$ for some~$\dagger$-effectus~$C$,
    the following holds.
\begin{enumerate}
\item
    $f$ is $\dagger$-mono iff $f$ is a comprehension. \\
    Dually:
    $f$ is $\dagger$-epi iff $f$ is a quotient of a sharp predicate.
\item
    The $\dagger$-partial isometries are exactly the pristine maps, see \sref{dfn-pristine}.
\end{enumerate}
Furthermore: $\Pure C$ is a $\dagger$-kernel category:
    the~$\dagger$-kernel of~$f$ is given by~$\pi_{(1 \after f)^\perp}$.
\begin{point}{Proof}%
Let~$f$ be any~$\dagger$-mono
pure map, say~$f \equiv \pi_s \after \alpha \after \zeta_{\ceil{p}}
        \after \asrt_p$
        for some iso~$\alpha$, $s \equiv \IM f$ and~$p \equiv 1 \after f$.
As we saw before (using \sref{asrt-absorp-rule}),
    we see~$\id = f^\dagger \after f = \asrt_{p^2}$.
Thus~$\andthen{p}{p} = p^2 =  1 = \andthen{1}{1}$
    and so by uniqueness of the square root
    we get~$p = 1$.
Hence~$f$ is a comprehension.

Duallizing, we see~$\dagger$-epis are exactly quotients of sharp predicates.
Now it is clear that the~$\dagger$-partial isometries
are exactly the pristine maps.
\begin{point}%
By the previous~$\pi_{(1 \after f)^\perp}$ is~$\dagger$-mono.
To see it is the~$\dagger$-kernel of~$f$,
we have to show it is the equalizer of~$f$ with~$0$.
Clearly~$(1 \after f )^\perp \after \pi_{(1 \after f)^\perp} = 1$
and so~$1 \after f \after \pi_{(1 \after f)^\perp} = 0$,
whence~$f \after \pi_{(1 \after f)^\perp} = 0$.
Assume~$f \after g = 0$ for some (other) pure map~$g$.
Then~$1 \after f \after g = 0$,
    so~$1 \after f \leq \IMperp g$,
    hence~$(1 \after f)^\perp \geq \IM g$,
    so~$g = \pi_{(1 \after f)^\perp} \after g'$
    for a unique~$g'$. \qed
\end{point}
\end{point}
\end{point}
\begin{point}{Exercise}%
Let~$C$ be a~$\dagger$-effectus.
In this exercise, we will show that
    in general $\Pure C$
    does not have finite coproducts.
In particular, $\Pure C$ does not have~$\dagger$-biproducts,
    see~\cite[3.2.15]{heunenphd}.
Consider~$C \equiv \op\vN$.
Reasoning towards contradiction,
    assume~$(\Pure \op\vN)^{\mathrm{op}}$
    has a product~$\ \C \xleftarrow{\pi_1} \scrA \xrightarrow{\pi_2} \C$
    of~$\C $ and~$\C$.
Use \TODO{}
    to prove there is an
    isomorphism~$\varphi\colon  \scrB(\scrH) \oplus \scrC \cong \scrA$
    with~$\pi_1 \after \varphi = \left<x,\,(\cdot\,)x\right>$
    and~$\pi_2 \after \varphi = \left<y,(\,\cdot\,)y\right>$
    for some von Neumann algebra~$\scrC$,
    Hilbert space~$\scrH$ and $x,y \in \scrH$.
    First show~$\scrC$ is trivial.
    Then prove~$\dim \scrH \leq 2$.
    Almost there: show~$\dim \scrH \geq 2$.
    Derive a contradiction.
\end{point}
\begin{point}{Exercise}%
In this exercise we will show that~$\Pure(\op\vN)$ does not have
    all coequalizers.  It is helpful to first consider
    two concrete coequalizers in~$\mathsf{Hilb}$ and~$\op\vN$.
(These coequalizers capture unordered pairs of qubits.)

Write~$\sigma\colon \C^2 \otimes \C^2 \to \C^2 \otimes \C^2$
    for the unitary
    fixed by~$\sigma \ket{ij} = \ket{ji}$.
The equalizer of~$\sigma$ with~$\id$ exists in~$\mathsf{Hilb}$
    and is given by~$e_{\mathscr{S}}$, the inclusion
    of the subspace~$\mathscr{S}$
    spanned by~$\{\ket{00}, \ket{11}, \ket{01}+\ket{10}\}$
    into~$\C^2\otimes \C^2$.
    ($\mathscr{S}$ is called the symmetric tensor of~$\C^2$ with itself.)
    The coequalizer of~$\sigma$ with~$\id$ is simply~$e_{\mathscr{S}}^\dagger$.
    There is also an equalizer of~$\ad_{\sigma}\colon M_4 \to M_4$ with~$\id$
    in~$\vN$, but curiously enough, it is given
    by~$e \colon M_3 \oplus \C \to M_4$,
    where~$e(a,\lambda) =
            \ad_{e^\dagger_{\mathscr{S}}}(a) +
            \ad_{e^\dagger_{\mathscr{A}}}(\lambda)$
     and~$\scrA$ is the subspace spanned by~$\ket{01} - \ket{10}$.
     For the proof and similar results, see \cite{bags}.

Assume~$\xi \colon \scrC \to M_4$
    is some filter (i.e.~quotient in the opposite category)
    with~$\ad_\sigma \after \xi = \xi$.
Show that for each~$x \in \ceil{\xi(1)} \C^4$
    we must have~$x \in \scrA$ or~$x \in \scrS$.
    (First show it for~$x \in \xi(1) \C^4$
    and then apply a pseudoinverse, see \sref{dfn-pseudoinverse}.)
Prove from this, that either~$\ceil{\xi(1)} \leq e_{\scrA}e^\dagger_{\scrA} $
    or~$\ceil{\xi(1)} \leq e_{\scrS}e^\dagger_{\scrS} $
        and that
        consequently~$\xi$ cannot be an equalizer of~$\ad_\sigma$ and~$\id$
    in~$\op{\Pure(\op\vN)}$.
Conclude~$\Pure(\op\vN)$ does not have all coequalizers.
\end{point}
\begin{point}%
To summarize:
    the category~$\Pure(C)$
    of a~$\dagger$-effectus~$C$
    is a~$\dagger$-category,
    has~$\dagger$-kernels
    and each~$\dagger$-mono is a~$\dagger$-kernel,
    but in general it does not have~$\dagger$-biproducts or
        $\dagger$-equalizers,
        which shows it is not, in general,
        a pre-Hilbert category as in \cite[3.7.1]{heunenphd}.
\end{point}
\end{parsec}

\subsection{Sequential product}
\begin{parsec}%
\begin{point}%
The sequential product --- the
    operation~$\andthen{a}{b} \equiv \sqrt{a}b\sqrt{a}$
    on the effects of a von Neumann algebra
    --- has been studied before.
In \cite{gudder2001sequential,gheondea2004sequential}
    Gudder and coauthors establish some basic algebraic properties of~$\&$
    on~$\scrB(\scrH)$.
Most of them are surprisingly hard to prove ---
    for instance, the proof that~$\andthen{a}{b}=\andthen{b}{a}$
    implies~$ab = ba$, requires
    the Fuglede--Rosenblum--Putnam Theorem.
\begin{point}%
Then, in \cite{gudder2008characterization},
    Gudder and Latr\'emoli\`ere (G\&L)
    characterize~$\&$ on~$\scrB(\scrH)$ as the unique operation satisfying
\begin{multicols}{2}
\begin{enumerate}
    \item $\TR [ (\andthen{a}{\varrho}) b] = \TR [\varrho
                    (\andthen{a}{b})]$
    \item $\andthen{a}{1} = \andthen{1}{a} = a$
    \item $ \andthen{a}{(\andthen{a}{b})} =
            \andthen{(\andthen{a}{a})}{b} =
            \andthen{a^2}{b}$
        \item $a \mapsto \andthen{a}{b}$ is strongly continuous
\end{enumerate}    
\end{multicols}
\noindent
Recall that we characterized~$\asrt_a \colon b \mapsto \andthen{a}{b}$
    as the unique~$\diamond$-positive map with~$\andthen{a}{1} = a$.
How do these characterization compare?
G\&L's first axiom plays a very similar role
        as the~$\diamond$-self adjointness of~$\diamond$-positive maps for us.
Their third axiom is somewhat related to~$\diamond$-positivity.
Their fourth axiom seems unrelated to our characterization
    and conversely the purity of our~$\diamond$-positive maps
    has no counterpart in their axioms.
\end{point}
\begin{point}%
A few years earlier, Gudder and Greechie started
    \cite{gudder2001sequential}
    the abstract study of some of the algebraic properties of the
    sequential product on arbitrary effect algebras,
    which has been picked up by several other authors.
    \cite{li2011sequential,gudder2005open,shen2009not,gudder2005uniqueness,jun2009remarks,weihua2009uniqueness,tkadlec2008atomic,jia2010entropy,arias2004almost}
\end{point}
\end{point}
\begin{point}{Definition}%
A \Define{sequential effect algebra} (SEA)
    is an effect algebra~$E$ together
    with a binary operation~$\&$
    satisfying
\begin{enumerate}
    \item[(S1)] if~$a \perp b$,
        then~$\andthen{c}{a} \perp \andthen{c}{b}$
        and~$(\andthen{c}{a}) \ovee (\andthen{c}{b})
                = \andthen{c}{(a \ovee b)}$;
    \item[(S2)] $\andthen{1}{a} =a$;
    \item[(S3)] if~$\andthen{a}{b} = 0$,
            then~$\andthen{a}{b} = \andthen{b}{a}$;
    \item[(S4)]
        if~$\andthen{a}{b} = \andthen{b}{a}$,
        then~$\andthen{a}{b^\perp} = \andthen{b^\perp}{a}$
        and~$\andthen{(\andthen{a}{b})}{c}
            = \andthen{a}{(\andthen{b}{c})} $ \emph{and}
    \item[(S5)]
        if~$\andthen{c}{a} = \andthen{a}{c}$,
        $\andthen{c}{b} = \andthen{b}{c}$ and~$a \perp b$,\\
        then~$\andthen{c}{(\andthen{a}{b})}
                = \andthen{(\andthen{a}{b})}{c}$
                and~$\andthen{c}{(a \ovee b)} = \andthen{(a \ovee b)}{c}$.
\end{enumerate}
\end{point}
\begin{point}{Examples}%
The effect algebra~$[0,1]_\scrA$
    of effects on a von Neumann algebra~$\scrA$
    is a sequential effect algebra with~$\andthen{a}{b} = \sqrt{a}b\sqrt{a}$.
Any commutative effect monoid is a sequential effect algebra
    with~$\andthen{a}{b} = a \odot b$.
\end{point}
\begin{point}{Proposition}%
In a~$\dagger$-effectus,
    the set of predicates~$\Pred X$ on any object~$X$
    with~$\andthen{p}{q} = q \after \asrt_p$
    satisfies axioms (S1), (S2) and (S3) of a SEA.
\begin{point}{Proof}%
The proofs of (S1) and (S2) are obvious.
To show~(S3), assume~$\andthen{p}{q} = 0$
    for some predicates~$p,q$.
    Then~$1 \after \asrt_q \after \asrt_p  = \andthen{p}{q}= 0$
and so~$\asrt_q \after \asrt_p = 0 = \asrt_0$.
Applying the dagger, we find
$0 = \asrt_0^\dagger = \asrt_p^\dagger \after \asrt_q^\dagger
                = \asrt_p \after \asrt_q$.
    Thus~$\andthen{q}{p} = 0 = \andthen{p}{q}$, as desired. \qed
\end{point}
\end{point}
\end{parsec}

\subsection{Homological categories}
\begin{parsec}%
\begin{point}%
Next we compare our effectuses
    to Grandis' homological categories \cite{grandis},
    which generalize abelian categories
    used in homological algebra.
First, we need a lemma.
\end{point}
\begin{point}[homology-lemma]{Lemma}%
Suppose~$s,t$ are any sharp predicates on the same object in a~$\dagger$-effectus.
    If~$s^\perp \leq t$,
    then~$\andthen{s}{t}$ is sharp.
\begin{point}{Proof}%
By \sref{sum-sharp-sharp},
it is sufficient to show
    $\andthen{s}{t^\perp}$ is sharp
as~$(\andthen{s}{t})^\perp = \andthen{s}{t^\perp} \ovee s^\perp$.
Note~$s^\perp \perp t^\perp$,
so by \sref{perp-sharp-is-orth},
    we find~$\andthen{t^\perp}{s^\perp} = 0$,
    hence~$\andthen{t^\perp}{s} = t^\perp$ is sharp.
By the same reasoning as in the final
    part of the proof of \sref{dagger-iso-mu},
    there exists a (unique) pristine map~$l$
    with~$\asrt_s \after \asrt_{t^\perp}
        = l\after \asrt_{\andthen{t^\perp}{s}}$,
        $l \after l^\dagger = \asrt_{\ceil{\andthen{t^\perp}{s}}}$
        and $l^\dagger \after l = \asrt_{\ceil{\andthen{s}{t^\perp}}}$.
It follows~$l \after \asrt_{\andthen{t^\perp}{s}} \after l^\dagger
    = \asrt_{\andthen{s}{t^\perp}}$ and so
\begin{align*}
    \asrt_{\andthen{s}{t^\perp}}^2
    & \ = \ l \after \asrt_{\andthen{t^\perp}{s}} \after
            l^\dagger \after l \after 
            \asrt_{\andthen{t^\perp}{s}} \after l^\dagger \\
    & \ = \ 
    l \after \asrt_{\andthen{t^\perp}{s}} \after
            \asrt_{\ceil{\andthen{s}{t^\perp}}} \after
            \asrt_{\andthen{t^\perp}{s}} \after l^\dagger \\
    & \ \overset{\mathclap{\sref{asrt-absorp-rule}}}{=} \ 
    l \after \asrt_{\andthen{t^\perp}{s}} \after
            \asrt_{\andthen{t^\perp}{s}} \after l^\dagger \\
    & \ \overset{\mathclap{\sref{sharp-prop}}}{=} \ 
    l \after \asrt_{\andthen{t^\perp}{s}} \after
            l^\dagger \\
    & \ = \ 
     \asrt_{\andthen{s}{t^\perp}},
\end{align*}
    which shows~$\andthen{s}{t^\perp}$ is sharp. \qed
\end{point}
\end{point}
\begin{point}{Definition}%
A category~$C$ is a \Define{pointed semiexact category} \cite[\S1.1]{grandis}
    if~$C$ has a zero object and all kernels and cokernels.
In a pointed semiexact category:
\begin{enumerate}
\item
We put a partial order on kernels in the usual way:
we write~$\Define{n \leq m}$
for kernels~$n\colon A \to X$ and~$m \colon B \to X$,
    if there is an~$f\colon A \to B$
    with~$n = m \after f$.
If both~$n \leq m$ and~$m \leq n$,
    then we write~$n \approx m$.
We denote the poset of kernels on~$A$ modulo~$\approx$
        by~$\Define{\Nsb A}$. (\textbf{N}ormal \textbf{s}ubo\textbf{b}jects,
            \cite[\S1.5]{grandis}.)
\item
For every map~$f$
    there is a unique map~$g$
        with~$f = (\ker \cok f ) \after g \after (\cok \ker f)$.
    If this~$g$ is an iso, then~$f$ is called \Define{exact}.
\end{enumerate}
A pointed semiexact category~$C$
    is a \Define{pointed homological category} if
\begin{enumerate}
    \item kernels are closed under composition;
    \item cokernels are closed under composition \emph{and}
    \item \emph{(homology axiom)}
        for any kernel~$m\colon M \to A$
        and cokernel~$q\colon A \to Q$
        with~$\ker q \leq m$,
        the composition~$q \after m$ is exact.
\end{enumerate}
\end{point}
\begin{point}{Theorem}%
Any~$\dagger$-effectus (in partial form) is a (pointed) homological category:
\begin{enumerate}
    \item 
        a map is a kernel iff it is a comprehension;
    \item
        a map is a cokernel iff it is a quotient of a sharp predicate \emph{and}
    \item
        a map is exact iff it is pristine.
\end{enumerate}
\begin{point}{Proof}%
Let~$C$ be a~$\dagger$-effectus.
By~\sref{effectus-kernels} and \sref{effectus-cokernels},
    we know~$C$ has all kernels and cokernels:
    a kernel of~$f$ is exactly a comprehension of~$(1 \after f)^\perp$
    and a cokernel of~$f$ is exactly a quotient of~$\IM f$.
By~\sref{upm-closed},
    comprehensions are closed under composition,
    and so kernels are closed under composition as well.
As for the cokernels,
    assume~$\zeta_1, \zeta_2$ are two composable cokernels.
Both~$\zeta_1$ and~$\zeta_2$ are quotients of a sharp predicate.
By \sref{quotients-composition} the composition  $\zeta_1 \after \zeta_2$
    is a quotient as well.
The map~$\zeta_2$ is sharp by \sref{quotients-composition}
    and so the predicate~$1 \after \zeta_1 \after \zeta_2$ is sharp.
Hence~$\zeta_1 \after \zeta_2$ is a cokernel too.
Unfolding definitions, it is easy to see exact maps correspond precisely
    to pristine maps.
\begin{point}{Homology axiom}%
We have to show~$q \after m$
    is exact for any cokernel~$q$ and kernel~$m$ with~$\ker q \leq m$.
As~$q \after m$ is pure,
    it is sufficient to show~$1 \after q \after m$ is sharp.
By \sref{compr-is-full},
the assumption~$\ker q \leq m$
    is equivalent to~$(1 \after q)^\perp \equiv \IM \ker q \leq \IM m$
    and so~$\IMperp m \leq 1 \after q$.
Our lemma \sref{homology-lemma}
    shows~$\andthen{(\IM m)}{(1 \after q)}
    \equiv 1 \after q \after m \after m^\dagger$ is sharp
    and so
\begin{align*}
    \ceil{1 \after q \after m}
    &\ = \ \ceil{1 \after q \after m} \after m^\dagger \after m 
        &\quad&\text{as comprehensions are~$\dagger$-mono}\\
    &\ = \ \ceil{1 \after q \after m \after m^\dagger} \after m 
        &&\text{as $m^\dagger$ is sharp} \\
    &\ = \ 1 \after q  \after  m \after m^\dagger \after m  \\
    &\ = \ 1 \after q  \after  m,
\end{align*}
which show~$q \after m$ is sharp, as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
In any homological category, a generalization
    of the famous \emph{Snake Lemma} holds.
Before we can discuss it, we need some more homological category theory.
\end{point}
\begin{point}{Definition}%
Let a (pointed) semiexact category be given.
\begin{enumerate}
\item
    We say the diagram~$A \xrightarrow{f} B \xrightarrow{g} C$
        is \Define{exact at} $B$,
        if~$\ker \cok (f) \approx \ker (g)$.
We say~$A_1 \xrightarrow{f_1} A_2 \to \cdots
            \to A_{n}$
            is a \Define{(long) exact sequence}
            if it is exact at~$A_2, \ldots, A_{n-1}$.
\item
The poset~$\Nsb A$ of kernels modulo~$\approx$
        is a bounded lattice with minimum~$0$ and maximum~$1\equiv \id$.
        \cite[\S1.5]{grandis}
\item
For any~$f\colon A \to B$,
    define~$f_*\colon \Nsb A \leftrightarrows \Nsb B \colon f^*$
        by~$\Define{f_*} (k) = \ker \cok (f \after k)$
        and~$\Define{f^*}(k) = \ker ((\cok k) \after f)$.
\item
We say~$f$ is \Define{left-modular at} $k$
    if~$f^* (f_* (k)) = k \vee f^*(0)$
        and $f$ is \Define{right-modular at} $k$
        if~$f_*(f^* (k)) = k \wedge f_*(1)$.
We call~$f$ simply \Define{left-modular} (resp.~right-modular)
    if it is left-modular (resp.~left-modular) at every~$k$.
We say~$f$ is \Define{modular}
    if it is both left- and right-modular.
\end{enumerate}
\end{point}
\begin{point}{Example}%
In a~$\dagger$-effectus, the previous concepts are related
to our familiar notions as follows.
\begin{enumerate}
\item
    A diagram~$A \xrightarrow{f} B \xrightarrow{g} C$
        is exact at $B$
        if and only if~$\IMperp f = \ceil{1 \after f}$.
\item
    The lattice~$\Nsb A$ is isomorphic to the lattice~$\SPred A$
        via~$k \mapsto \IM k$.
\item
    For any~$f$, we
        have~$\IM f_*(k) = f_\diamond (\IM k)$
        and~$\IM f^*(k) = f^\BOX (\IM k)$.
\item
    A map~$f$ is left-modular at~$k$
            iff~$f^\BOX (f_\diamond ( \IM k)) = 
                (\IM k) \vee \ceil{1 \after f}$
        and right-modular at~$k$
            iff~$f_\diamond (f^\BOX ( \IM k)) = 
                (\IM k) \wedge \IM f$.
\end{enumerate}
\begin{point}{Notation}%
As~$\Nsb A$ and~$\SPred A$ are isomorphic,
    we will abbriavte~``$f$ is left-modular at~$\pi_s$''
    by~``$f$ is left-modular at~$s$''
    and similarly for right-modularity.
\end{point}
\end{point}
\begin{point}[diamondboxlemma]{Lemma}%
In a~$\dagger$-effectus,
    we have~$\pi^\BOX \after \pi_\diamond = \id$
    and~$\zeta_\diamond \after \zeta^\BOX = \id$
    for any comprehension~$\pi$
    and sharp quotient~$\zeta$.
\begin{point}{Proof}%
We start with~$\pi$.  The trick is to use~$\pi^\dagger$ is sharp:
    $\pi^\BOX \after \pi_\diamond (s) =
    \pi^\BOX \after (\pi^\dagger)^\diamond (s) =
    \lceil \lceil s \after \pi^\dagger \rceil^\perp \after \pi\rceil^\perp =
    \lceil(s \after \pi^\dagger)^\perp \after \pi\rceil^\perp =
    \lceil(s \after \pi^\dagger \after \pi)^\perp\rceil^\perp =
    \lceil s ^\perp\rceil^\perp = s $.
As for the other equality:
    $\zeta_\diamond \after \zeta^\BOX (s)
        = (\zeta^\dagger)^\diamond \after \zeta^\BOX (s)
        = \lceil\lceil s^\perp \after  \zeta \rceil^\perp \after \zeta^\dagger\rceil
        = \lceil(\lceil s^\perp \after  \zeta \rceil \after \zeta^\dagger)^\perp\rceil
        = \lceil(\lceil s^\perp\rceil \after \zeta \after \zeta^\dagger)^\perp\rceil
        = \lceil \lceil s^\perp\rceil^\perp \rceil = s $. \qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}%
\begin{point}%
In any homological category,
    a generalization of the famous \emph{Snake Lemma} holds.
    \cite[\S3.4]{grandis}.
The following is a translation of (a part of) Grandis' Snake Lemma
    into~$\dagger$-effectus jargon.
We include a proof as it highlights how
    the reasoning in a homological category is subtly different:
    maps~$l^\BOX$ appear, where we would have expected~$l^\diamond$.
\end{point}
\begin{point}{Snake Lemma}%
Suppose we have a commuting
    diagram in~$\dagger$-effectus as follows.
\begin{equation*}
    \xymatrix{
        &A \ar[d]^{a} \ar[r]^f
    &B \ar[d]^{b} \ar[r]^g
    &C \ar[d]^{c} \ar[r]^0
    &0
    \\0 \ar[r]^{0}
    &A' \ar[r]^{h}
    &B' \ar[r]^{k}
    &C'
}
\end{equation*}
Furthermore, assume
\begin{enumerate}
    \item the diagram has exact rows;
    \item  $b$ is left-modular over~$\IM f$;
    \item $b$ is right-modular over~$\IM h$;
    \item $f$ is right-modular over~$\ceil{1 \after b}^\perp$ \emph{and}
    \item $k$ is left-modular over~$\IM b$.
\end{enumerate}
These additional assumptions are equivalent to the following conditions.
    \begin{multicols}{2}
    \begin{enumerate}
    \item
        $b^\BOX \after b_\diamond (\IM f) = \ceil{1 \after b}^\perp \vee \IM f$,
    \item
        $b_\diamond \after b^\BOX (\IM h)
                = (\IM h) \wedge \IM b$,
    \item
        $k^\BOX \after k_\diamond (\IM b) = (\IM h) \vee \IM b$,
    \item
        %$f_\diamond \after f^\BOX (\ceil{1 \after b}^\perp)
        $f_\diamond \after f^\BOX \after b^\BOX(0)
                = \ceil{1 \after b}^\perp \wedge \IM f$,
    \item
        $\IMperp f = \ceil{1\after g}$,
    \item
        $\IMperp h = \ceil{1\after k}$,
    \item
        $g$ is a sharp quotient \emph{and}
    \item
        $h$ is a comprehension.
    \end{enumerate}
\end{multicols}\noindent
\emph{Completing the diagram},
write~$a_\pi, b_\pi, c_\pi$ for kernels of~$a$, $b$ and~$c$, respectively;
$a_\zeta$, $b_\zeta$, $c_\zeta$ for the cokernels
    \emph{and}~$\overline{f},\overline{g},\overline{h}, \overline{k}$
    for the induced maps between the kernels and cokernels.
It is easy to see
\begin{align*}
   \overline{f} &= b_\pi^\dagger \after f \after a_\pi
     &   \overline{g} &= c_\pi^\dagger \after g \after b_\pi
     &   \overline{h} &= b_\zeta \after h \after a_\zeta^\dagger
     &   \overline{k} &= c_\zeta \after k \after b_\zeta^\dagger.
\end{align*}
Then: there is a map~$d \colon \ker c \to \cok a$
        that turns\footnote{%
            Beware: we use~$\ker a$ (and~$\cok$) inconsistently ---
         earlier in the text~$\ker f$ refers
            to a kernel map --- here it
            refers to a kernel object instead.}
\begin{equation}\label{thesnake}
    \xymatrix{
        \ker a \ar[r]^{\overline{f}}
        &\ker b \ar[r]^{\overline{g}}
        &\ker c \ar[r]^{d}
        &\cok a \ar[r]^{\overline{h}}
        &\cok b \ar[r]^{\overline{k}}
        &\cok c 
    }
\end{equation}
into a (long) exact sequence. This reveals the snake:
\begin{equation*}
\begin{tikzpicture}[
        every edge/.append style={font=\scriptsize}
        ]
    \matrix[matrix of math nodes,
            column sep={45pt,between origins},
            row sep={45pt,between origins},
            nodes={asymmetrical rectangle}] (s) {
        & |[name=ka]| \ker a
        & |[name=kb]| \ker b
        & |[name=kc]| \ker c \\
        & |[name=A]| A
        & |[name=B]| B
        & |[name=C]| C 
        & |[name=01]| 0\\
         |[name=02]| 0
        & |[name=A']| A'
        & |[name=B']| B'
        & |[name=C']| C' \\
        & |[name=ca]| \cok a
        & |[name=cb]| \cok b
        & |[name=cc]| \cok c \\
    };
\draw[->]
    (ka) edge node[auto] {$a_\pi$} (A)
    (kb) edge node[auto] {$b_\pi$} (B)
    (kc) edge node[auto] {$c_\pi$} (C)
    (A') edge node[auto] {$a_\zeta$} (ca)
    (B') edge node[auto] {$b_\zeta$} (cb)
    (C') edge node[auto] {$c_\zeta$} (cc)
    (C) edge node[auto] {$0$} (01)
    (02) edge node[auto] {$0$} (A')
    (A) edge node[auto] {$f$} (B)
    (B) edge node[auto] {$g$} (C)
    (A') edge node[auto] {$h$} (B')
    (B') edge node[auto] {$k$} (C')
    (A) edge node[auto] {$a$} (A')
    (B) edge node[auto] {$b$} (B')
    (C) edge node[auto] {$c$} (C')
;
\draw[->,darkgreen] 
    (ka) edge node[auto,text=black] {$\overline{f}$} (kb)
    (kb) edge node[auto,text=black] {$\overline{g}$} (kc)
    (ca) edge node[auto,below,text=black] {$\overline{h}$} (cb)
    (cb) edge node[auto,below,text=black] {$\overline{k}$} (cc)
;
\draw[->,darkgreen,rounded corners]
    (kc) 
        -| node[auto,text=black,pos=.7,font=\scriptsize]{$d$}
            ($(01.east)+(.5,0)$)
        |- ($(B)!.35!(B')$)
        -| ($(02.west)+(-.5,0)$)
        |- (ca);
;
\end{tikzpicture}
\end{equation*}
\begin{point}{Proof}%
Before we start, we give an overview of the proof.
We will first show
    there are comprehensions~$m,h'$
        and sharp quotients~$g',v$
        such that the left and right faces of the following cube commute.
\begin{equation*}
\xymatrix{
    & B \ar[rr]^b \ar@{->>}[dd]^g
    && B' \ar@{->>}[dd]^v
    \\ Z \ar@{^{(}->}[ru]^m \ar@{->>}[dd]_{g'}
    && A' \ar@{^{(}->}[ru]^h \ar@{->>}[dd]_{a_\zeta}
\\& C
&& Q
    \\ \ker c \ar@{^{(}->}[ru]_{c_\pi} \ar[rr]_{d}
    && \cok a \ar@{^{(}->}[ru]_{h'}
}
\end{equation*}
(These two faces are, what Grandis calls, subquotients.)
Then we will prove using exactness of the rows
    that there is a unique lifting of~$b$
    to~$b'\colon Z \to A'$ along the comprehensions~$m,h$.
In turn, $d$ is defined as the unique lifting of~$b'$
    along the sharp quotients~$h', a_\zeta$.
($d$ is the map regularly induced by~$b$ along the two subquotients.)
Before demonstrating the exactness of the snake,
    we need some non-trivial identities for~$d_\diamond$ and~$d^\BOX$.
(These also follow from Grandis' calculus of direct and inverse images
    along an induced morphism.)
\begin{point}%
Define~$v \equiv \xi_{h_\diamond(\IM a)}$. 
As~$(v \after h)^\diamond(1) = h^\diamond ( h_\diamond(\IM a)) = \IM a
        = 1\after a_\zeta$,
        there must be a total pure map~$h'$
        such that~$v \after h = h' \after a_\zeta$.
Note~$\ceil{1 \after v}^\perp = h_\diamond(\IM a) \leq h_\diamond(1) = \IM h$.
So by the homology axiom, we know~$v \after h$ is pristine
    and so~$h'$ must be a comprehension.
Moving to the other side,
    define~$m \equiv \pi_{g^\BOX(\ceil{1\after c}^\perp)}$.
Reasoning in a similar way,
    we see there is a unique sharp quotient~$g'$
    with~$g \after m = c_\pi \after g'$.
\end{point}
\begin{point}%
To show~$b$ lifts along~$m$ and~$h$,
    it suffices (by the universal property of comprehension)
    to show~$(b \after m)_\diamond(1)
        \equiv \IM b\after m \leq \IM h
                    \equiv h_\diamond(1)$.
\begin{alignat*}{2}
b_\diamond \after m_\diamond (1)
    &\ =\  b_\diamond \after g^\BOX \after c^\BOX (0) &\qquad& \text{by dfn.~$m$}\\
    &\ = \ b_\diamond \after b^\BOX \after k^\BOX (0) \\
    &\ = \ b_\diamond \after b^\BOX \after h_\diamond (1) && \text{by exactness at~$B'$} \\
    &\ \leq \  h_\diamond (1) && \text{as $b_\diamond \dashv b^\BOX$}.
\end{alignat*}
So there is a unique~$b'\colon Z \to A'$ with~$h \after b' = b \after m$.
Before we continue,
    we note~$b' = h^\dagger \after b \after m$
    (as ~$h^\dagger \after h= \id$)
    and so surprisingly:
\begin{equation}\label{snakeceilbprime}
    m^\BOX \after b^\BOX \after h_\BOX \ = \ 
    b'^\BOX \ \overset{\mathclap{\sref{diamondboxlemma}}}{=} \   b'^\BOX \after h^\BOX \after h_\diamond
            \ =\    m^\BOX \after b^\BOX \after h_\diamond.
\end{equation}
Next, to show~$b'$ lifts along~$g'$ and~$a_\zeta$,
    it is sufficient to prove~$b'^\BOX \after a_\zeta^\BOX(0)
        = \ceil{1\after b' \after a_\zeta}^\perp
                \geq \ceil{1 \after g'}^\perp
                = g'^\BOX (0)$.
\begin{alignat*}{2}
    b'^\BOX \after a_\zeta^\BOX(0)
        & \ = \ b'^\BOX \after a_\diamond (1)
                &\qquad& \text{by dfn.~$a_\zeta$} \\
        & \ = \ m^\BOX \after b^\BOX \after h_\diamond \after a_\diamond (1)
                && \text{by \eqref{snakeceilbprime}} \\
        & \ = \ m^\BOX \after b^\BOX \after b_\diamond \after f_\diamond (1) \\
        & \ \geq \ m^\BOX \after f_\diamond (1) 
                && \text{as $b_\diamond \dashv b^\BOX$}\\
        & \ =\ m^\BOX \after g_\BOX (0) 
                && \text{by exactness at $B$}\\
        & \ = \ g'^\BOX \after {c_\pi}_\BOX (0) 
                && \text{by dfn.~$g'$}\\
        & \ \geq \ g'^\BOX (0).
\end{alignat*}
Thus there is a unique~$d\colon \ker c \to \cok a$
    with~$d \after g' = a_\zeta \after b'$.
More concretely, using~$g' \after g'^\dagger = \id$,
    we see
    $ d  =  a_\zeta \after h^\dagger \after b \after m \after 
                g'^\dagger$.
\end{point}
\begin{point}%
Our next goal is to show
\begin{align*}
    d_\diamond &\ =\ 
            (a_\zeta)_\diamond \after h^\BOX \after
                b_\diamond \after m_\diamond \after g'^\BOX
            \ = \ h'^\BOX \after v_\diamond \after
                b_\diamond \after m_\diamond \after g'^\BOX 
                \numberthis\label{snakedidents}
                \\
            &\ = \ (a_\zeta)_\diamond \after h^\BOX \after
                b_\diamond\after g^\BOX \after (c_\pi)_\diamond
            \ = \ h'^\BOX \after v_\diamond \after
                b_\diamond\after g^\BOX \after (c_\pi)_\diamond.
\end{align*}
As a first step,
    note~$\IM m = g^\BOX \after c_\diamond (1) \geq
        g^\BOX\after (c_\pi)_\diamond(s)$
    and so
\begin{alignat*}{2}
    g^\BOX\after (c_\pi)_\diamond(s)
       & \ =\ 
    g^\BOX\after (c_\pi)_\diamond(s) \wedge  (\IM m) \\
    &\ = \ m_\diamond \after m^\BOX \after 
    g^\BOX\after (c_\pi)_\diamond(s)
    &\qquad&\text{by \sref{spred-infimum}} \\
    &\ = \ m_\diamond \after g'^\BOX \after
    c_\pi^\BOX\after (c_\pi)_\diamond(s) &&\text{by dfn.~$g'$}\\
    &\ = \ m_\diamond \after g'^\BOX(s)
    &&\text{by \sref{diamondboxlemma}}.
\end{alignat*}
and so we only have to show the first two equalities of \eqref{snakedidents}.
The first is easy:
\begin{alignat*}{2}
    d_\diamond
    &\ = \ d_\diamond \after g'_\diamond \after g'^\BOX 
    &\qquad&\text{by \sref{diamondboxlemma}}\\
    & \ = \ (a_\zeta)_\diamond \after b'_\diamond \after g'^\BOX 
                &&\text{by dfn.~$d$}\\
    & \ = \ (a_\zeta)_\diamond \after
                    h^\BOX \after h_\diamond \after 
    b'_\diamond \after g'^\BOX
    &&\text{by \sref{diamondboxlemma}}\\
    &\ = \ (a_\zeta)_\diamond \after
                    h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX &&\text{by dfn.~$b'$}.
\end{alignat*}
The second is trickier.  We need some preparation.
    Recall~$v^\BOX(0) \leq h_\diamond(1)$
    and so
\begin{equation}\label{snakehdiamondone}
    h_\diamond(1) \ = \ 
    v^\BOX(0)  \vee h_\diamond(1) \ \overset{\mathclap{\sref{spred-sup}}}{=} \ 
    v^\BOX \after v_\diamond \after h_\diamond(1) \ = \ 
    v^\BOX \after h'_\diamond (1).
\end{equation}
As~$h_\diamond \after a^\BOX_\zeta$ is injective,
    the last equality follows from
\begin{alignat*}{2}
    &h_\diamond \after a_\zeta^\BOX \after (a_\zeta)_\diamond \after
                    h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX  (s)\\
    &\qquad \ =\ 
    h_\diamond ( h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX  (s) \vee a_\zeta^\BOX(0)) 
        &\qquad&\text{by \sref{spred-sup}}\\
    &\qquad \ =\ 
    h_\diamond \after  h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX  (s) \vee h_\diamond \after a_\zeta^\BOX(0)
        &\qquad&\text{as~$h_\diamond \dashv h^\BOX$}\\
    &\qquad \ =\ 
    h_\diamond \after  h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX  (s) \vee v^\BOX(0)
        &\qquad&\text{by dfns.~$v$,$a_\zeta$}\\
    &\qquad \ =\ 
    ( b_\diamond \after
    m_\diamond \after g'^\BOX  (s) \wedge h_\diamond(1)) \vee v^\BOX(0)
        &\qquad&\text{by \sref{spred-infimum}}\\
    &\qquad \ =\ 
    b_\diamond \after
    m_\diamond \after g'^\BOX  (s)  \vee v^\BOX(0)
        &\qquad&\text{as $b_\diamond \after m_\diamond (1) \leq h_\diamond(1)$}\\
    &\qquad \ =\ 
    (b_\diamond \after
    m_\diamond \after g'^\BOX  (s)  \vee v^\BOX(0)
    ) \wedge h_\diamond(1)
        &\qquad&\text{as $v^\BOX(0) \leq h_\diamond(1)$}\\
    &\qquad \ =\ 
    v^\BOX \after v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  (s)  \wedge h_\diamond(1)
        &\qquad&\text{by \sref{spred-sup}} \\
    &\qquad \ =\ 
    v^\BOX \after v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  (s)  \wedge v^\BOX \after h'_\diamond(1)
        &\qquad&\text{by \eqref{snakehdiamondone} } \\
    &\qquad \ =\ 
    v^\BOX (v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  (s)  \wedge  h'_\diamond(1))
        &\qquad&\text{as~$v^\BOX \vdash v_\diamond$} \\
    &\qquad \ =\ 
    v^\BOX \after h'_\diamond
    \after h'^\BOX \after  v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  (s)
        &\qquad&\text{by \sref{spred-infimum}}\\
    &\qquad \ =\ 
    h_\diamond \after a_\zeta^\BOX \after
    h'^\BOX \after  v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  (s),
\end{alignat*}
where~$
    h_\diamond \after a_\zeta^\BOX \after =
    v^\BOX \after h'_\diamond$
    is proven in the same way as $g^\BOX \after (c_\pi)_\diamond =
                                    m_\diamond \after g'^\BOX$.
\end{point}
\begin{point}%
We are ready to show exactness of \eqref{thesnake}.
We will first derive exactness in~$\cok a$
    from the right-modularity of~$b$ over~$\IM h$.
\begin{alignat*}{2}%
    d_\diamond(1) &
    \ = \  (a_\zeta)_\diamond \after h^\BOX \after b_\diamond
            \after g^\BOX \after (c_\pi)_\diamond(1)
            &\qquad&\text{by \eqref{snakedidents}} \\
    & \ = \ (a_\zeta)_\diamond \after h^\BOX \after 
                b_\diamond \after g^\BOX \after c^\BOX(0) 
                &&\text{by dfn.~$c_\pi$}\\
    & \ = \ (a_\zeta)_\diamond \after h^\BOX \after 
    b_\diamond \after b^\BOX \after k^\BOX(0) \\
    & \ = \ (a_\zeta)_\diamond \after h^\BOX \after 
    b_\diamond \after b^\BOX \after h_\diamond(1) 
    &\qquad&\text{by exactness in~$B'$}\\
    & \ = \ (a_\zeta)_\diamond \after h^\BOX (
    b_\diamond(1) \wedge h_\diamond(1))
        &&\text{by right-modularity}\\
    & \ = \ (a_\zeta)_\diamond \after h^\BOX \after 
    h_\diamond \after h^\BOX \after b_\diamond(1)
    &&\text{by \sref{spred-infimum}} \\
    & \ = \ (a_\zeta)_\diamond \after h^\BOX
    \after b_\diamond(1)
    &&\text{as $h^\BOX \vdash h_\diamond$}\\
    & \ = \ (a_\zeta)_\diamond \after h^\BOX
    \after b_\zeta^\BOX(0)
    &&\text{by dfn.~$b_\zeta$} \\
    & \ = \ (a_\zeta)_\diamond \after a_\zeta^\BOX
    \after \smash{\overline{h}^\BOX} (0)
    &&\text{by dfn.~$\overline{h}$}\\
    & \ = \ \smash{\overline{h}^\BOX} (0)
    &&\text{by \sref{diamondboxlemma}.}
\end{alignat*}
    By a dual argument
    one derives exactness of~$\eqref{thesnake}$
        in~$\ker c$ from the left-modularity
        of~$b$ over~$\IM f$.
\end{point}
\begin{point}%
    To show exactness of
    $\eqref{thesnake}$ in~$\cok b$,
    we will use left-modularity of~$k$ in~$\IM b$:
\begin{alignat*}{2}
    \overline{h}_\diamond(1) 
        & \ = \ \overline{h}_\diamond \after (a_\zeta)_\diamond
                \after a_\zeta^\BOX(1)
                &\qquad&\text{by \sref{diamondboxlemma}} \\
        & \ = \ \overline{h}_\diamond \after (a_\zeta)_\diamond(1)
                &&\text{as $a_\zeta^\BOX \dashv (a_\zeta)_\diamond$}\\
        & \ = \ (b_\zeta)_\diamond \after h_\diamond(1)
                &&\text{by dfn.~$\overline{h}$}\\
        & \ = \ (b_\zeta)_\diamond \after
                b^\BOX_\zeta \after (b_\zeta)_\diamond \after
        h_\diamond(1)
                &&\text{as~$(b_\zeta)_\diamond \dashv b^\BOX_\zeta$}\\
        & \ = \ (b_\zeta)_\diamond (
                    h_\diamond(1) \vee b_\zeta^\BOX(0))
                &&\text{by \sref{spred-sup}}\\
        & \ = \ (b_\zeta)_\diamond (
                    h_\diamond(1) \vee b_\diamond(1))
                &&\text{by dfn.~$b_\zeta$}\\
        & \ = \ (b_\zeta)_\diamond (
                    k^\BOX(0) \vee b_\diamond(1))
                &&\text{exactness in~$B'$}\\
        & \ = \ (b_\zeta)_\diamond \after
                    k^\BOX \after k_\diamond \after b_\diamond(1)
                &&\text{by left-modularity}\\
        & \ = \ (b_\zeta)_\diamond \after
                    k^\BOX \after c_\diamond \after g_\diamond(1) \\
        & \ = \ (b_\zeta)_\diamond \after
                    k^\BOX \after c_\diamond (1) 
                    && \text{as quotients are faithful}\\
        & \ = \ (b_\zeta)_\diamond \after
                    k^\BOX \after c_\zeta^\BOX  (0) 
                    && \text{by dfn.~$c_\zeta$}\\
        & \ = \ (b_\zeta)_\diamond \after
                    b_\zeta^\BOX \after \smash{\overline{k}^\BOX}  (0) 
                    && \text{by dfn.~$\overline{k}$}\\
        & \ = \ \smash{\overline{k}^\BOX}  (0) 
                    && \text{by \sref{diamondboxlemma}}.
\end{alignat*}
    Finally, the exactness of~\eqref{thesnake}
        in~$\ker b$ is shown with a dual argument
        using the right-modularity of~$f$ over~$\ceil{1\after b}^\perp$. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}


    %  operational, wilce: \cite{barnum2013symmetry}
    % vicary frob cstar: \cite{vicary2011categorical}
    % meas without sums \cite{coecke2006quantum}
    % cpstar \cite{coecke2016categories}
    % dagger compact closed \cite{selinger2007dagger}
    % dagger split sel \cite{heunen2013completely}

    % bohrification \cite{heunen2012bohrification}
\end{document}

% vim: ft=tex.latex
